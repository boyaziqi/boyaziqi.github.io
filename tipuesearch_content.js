var tipuesearch = {"pages":[{"title":"Redis系列之","text":"前述 本篇先讲解Redis主从同步原理及流程，然后讲解Sentinel工作机制。最后，基于Docker部署Redis主从和验证Sentinel模式。相关实现已经放到我的GitHub博客源， Docker搭建Redis主从和Sentinel Redis主从同步原理 1，增量同步 主从服务器同步的是执行的指令流。当主服务器收到指令时，会将指令写到buffer（buffer大小固定，可配置更改），然后异步将执行指令同步到从服务器。 当buffer空间不足时，新收到指令会导致旧数据覆盖，这时会触发快照同步。 2，快照同步 Redis主服务会生成快照文件dump.rdb，当从服务首次连接到主服务器上或主服务重启时，主服务将dump.rdb文件传送给从服务器，从服务清空旧数据，然后利用dump.rdb文件 恢复最新的数据，恢复完成后，再和主服务器行增量同步保持数据一致。 3，主从同步流程 （1）从服务根据配置的ip和port连接到主服务，如果主服务设置了口令需要提供相应口令。 （2）从服务和主服务成功匹配后，先进行一次快照同步。在主服务生成快照并同步到从服务之前，新访问主服务的命令会被放到主服务的buffer。 （3）快照同步完成后，主从服务进行增量同步。从服务会维护一个数据offset，并与主服务保持同步。 （4）主从服务会按一定频率给对方发送heartbeat，用于检测对方是不是正常在线。如果网络断开然后恢复，会自动重连，并通过offset判断是否需要快照同步。 （5）从服务不处理过期key。当某个key过期时，主服务会模拟一个DEL指令发送给从服务器。 Sentinel模式简介 Redis主从服务采取读写分离，主服务负责写，从服务负责读。当主服务宕机时，Redis主从并不会从新选择主服务，这将导致整个主从服务无法正常工作。官方推荐的 主从同步高可用方案是Sentinel，它会监控和复制服务状态，当主服务宕机后，会根据选举算法从后端从服务选择新的主服务。Sentinel本身也有单点瓶颈的问题，因此也需要集群。 工作机制 Sentinel会运行三个定时任务（监控，通知，故障迁移）。当Redis主服务宕机后，会根据一定的机制选择一个领导Sentinel来执行故障迁移。主服务选择出来并配置成功后，领导Sentinel 通过 slaveof ip port 让其他从服务同步新的主服务。原来的主服务如果重新加入，则会成为新主服务的从服务。 如何确认一个服务已经故障 当一个Sentinel ping不通一个服务节点时，并不会立即认为该服务节点故障（主观下线）。只有当所有Sentinel协商一致，才认为该服务节点故障（客观下线）。 领导选举机制 每个做出主观下线的Sentinel将向其它Sentinel发送命令，要求将自己设为领导Sentinel。 收到命令的Sentinel如果没有同意过其它Sentinel的领导请求命令，那就同意，否则拒绝。 如果该Sentinel发现自己票数超过Sentinel集合的一半且达到quorum，该Sentinel将成为领导Sentinel。 如果此过程有多个Sentinel成为领导Sentinel，那么将等待一段时间重新进行选举。 从服务节点选择机制 选择slave-priority（slave优先级）最高的slave节点，如果有返回，没有继续。 选择复制偏移量最大的slave节点（复制最完整），如果有返回，没有继续。 选择runId最小的slave节点。 测试 为了方便验证和部署Redis主从，我基于Docker-compose构建了验证环境，实现查看文章开头的信息。docker-compose.yml文件内容如下。 其中RedisA作为主服务节点，RedisB和RedisC作为从服务节点。 version : '3' services : redisA : image : redis restart : always ports : - \"6376:6379\" volumes : - ./config/redis1/:/usr/local/etc/redis/ - ./logs/redis1/:/var/log/redis/ command : redis-server /usr/local/etc/redis/redis.conf redisB : image : redis restart : always ports : - \"6377:6379\" volumes : - ./config/redis2/:/usr/local/etc/redis/ - ./logs/redis2/:/var/log/redis/ command : redis-server /usr/local/etc/redis/redis.conf redisC : image : redis restart : always ports : - \"6378:6379\" volumes : - ./config/redis3/:/usr/local/etc/redis/ - ./logs/redis3/:/var/log/redis/ command : redis-server /usr/local/etc/redis/redis.conf sentinelA : image : redis restart : always ports : - \"6381:6379\" volumes : - ./config/sentinel/:/usr/local/etc/redis/ - ./logs/sentinel1/:/var/log/redis/ command : redis-sentinel /usr/local/etc/redis/sentinel.conf sentinelB : image : redis restart : always ports : - \"6382:6379\" volumes : - ./config/sentinel/:/usr/local/etc/redis/ - ./logs/sentinel2/:/var/log/redis/ command : redis-sentinel /usr/local/etc/redis/sentinel.conf sentinelC : image : redis restart : always ports : - \"6383:6379\" volumes : - ./config/sentinel/:/usr/local/etc/redis/ - ./logs/sentinel3/:/var/log/redis/ command : redis-sentinel /usr/local/etc/redis/sentinel.conf 修改RedisB的配置文件 ./config/redis2/redis.conf ，加入如下配置指定主服务节点地址。RedisC配置相同。 slaveof redis-replication_redisA_1 6379 增加上面的配置后，在终端docker-compose.yml文件所在目录执行 docker-compose up 启动容器，这样一主两从的Redis主从服务就搭建好了。 可以在主服务节点set一个key验证从服务节点是否正常复制。 我们在终端执行命令 docker ps 查看容器运行情况，我机器上显示如下，每个人的CONTAINER ID不一样。 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ce0c4d42c6a0 redis \"docker-entrypoint.s…\" About a minute ago Up About a minute 0 .0.0.0:6376->6379/tcp redis-replication_redisA_1 d21706b6ee24 redis \"docker-entrypoint.s…\" About a minute ago Up About a minute 0 .0.0.0:6378->6379/tcp redis-replication_redisC_1 b515bb2db9b5 redis \"docker-entrypoint.s…\" About a minute ago Up About a minute 0 .0.0.0:6377->6379/tcp redis-replication_redisB_1 bb546bd4834c redis \"docker-entrypoint.s…\" About a minute ago Up About a minute 0 .0.0.0:6382->6379/tcp redis-replication_sentinelB_1 297d8af73a96 redis \"docker-entrypoint.s…\" About a minute ago Up About a minute 0 .0.0.0:6383->6379/tcp redis-replication_sentinelC_1 86883db74e7d redis \"docker-entrypoint.s…\" About a minute ago Up About a minute 0 .0.0.0:6381->6379/tcp redis-replication_sentinelA_1 在Sentinel配置文件 .config/sentinel/sentinel.conf 加入下面配置。 protected-mode no sentinel monitor redis-replication_redisA_1 192 .168.11.128 6379 2 重新启动容器，这时Sentinel服务会自动更新配置文件，增加一些必要配置信息，并且将主机名和端口用一个hash字符串表示。 执行下面命令停止主服务节点。 docker stop redis-replication_redisA_1 执行了上面的命令后，我们验证，RedisB已经成为新的主服务节点。如果尝试在RedisC写入，则会提示下面错误。 ( error ) READONLY You can ' t write against a read only replica. 执行下面的命令重启RedisA，可以看到现在它成为RedisB的从服务器。 docker restart redis-replication_redisA_1 ps: 如果客户端与旧主服务器分隔在一起，写入的数据在恢复后由于旧主会复制新主的数据会造成数据丢失。 后述 主从复制有了，也用Sentinel模式来保证高可用了。但是对于客户端来说，访问的时候如何调度呢？后面会探索Redis负载均衡调度的主要解决方案（针对集群或主从复制），然后抽空写一篇文章。","tags":"Redis","url":"redisxi-lie-zhi.html","loc":"redisxi-lie-zhi.html"},{"title":"Redis系列四","text":"前述 本篇先讲述Redis锁、信号量实现，最后讲解事务及Lua脚本。对于锁和信号量的具体实现，这里不讲，可以查看网上关于Redis分布式锁具体实现的博文。这里只谈谈相关实现思路，并指出相应实现会遇到的问题及解决思路。 分布式锁 Redis没有原生支持锁，需要自己实现。基本思路就是利用string。下面是一个简要步骤。 1，获取锁 执行下面命令获取锁 set lockname value EX 30 NX 上面的命令设置一个含过期时间字符串，过期时间自己定，它的作用是避免某个获取锁的客户端由于某些原因长期阻塞。 NX选项指定在字符串不存在的时候才能设置成功，用来判断是否获取到锁。 如果成功设置，则获取到锁，否则继续等待重新获取。 PS：value最好是个随机字符串，比如uuid，避免并发状态下误删其它客户端创建的锁。 2，释放锁 释放锁就是删除指定的key。由于del删除的时候可能是其他事务设置的锁，因此一定要检查value是否相等。并利用 WATCH 监听锁key，避免被其他事务修改。 3，改进 上面的删除不是原子性的，因此可以利用lua脚本来删除。lua脚本能很好的支持事务。 3，其他方式 Redis官方推荐RedLock算法实现，它可以避免上面的锁单节点的问题。很多主要语言都已经有开源的实现了，自己项目中直接用就行。参考 官网 和 RedLock锁 RedLock缺点就是只适用于N个独立的Redis节点，主从模式和集群模式并不适用。而且至少得三个节点。参考 Redis RedLock 完美的分布式锁么？ 其他参考资料： Redis分布式锁 ！思考 ，如果主从复制模式，A进程在master节点获取到锁，在锁信息还没同步到slave节点时，master节点挂掉，此时slave被提升为主节点，B进程从slave节点获取锁，就造成重复获取锁，这种问题怎么解决？ 对于上面问题，RedLock是无法解决的。因为RedLock锁不支持主从复制模式，而且依赖系统时间。思考了很久，我觉得Redis由客户端控制锁的方式是很难解决的，因为A进程和B进程之间并不知道彼此获取锁的情况。 如果master节点和slave节点数据强一致，只有数据同步完成才给客户端返回获取锁成功，那上面的问题就解决了。但是这种方式影响了Redis服务对命令的响应速度，和Redis的设计思想不匹配。而且，到目前为止官方也不支持数据强一致的主从复制和集群模式。 有人建议zookeeper实现分布式锁。我查阅了zookeeper相关资料，它对数据一致性的却支持的比较好，支持不同维度的数据一致性。关于zookeeper分布式锁，参考 zookeeper分布式锁 与 zookeeper功能 后面也会抽空研究下zookeeper，然后再针对zookeeper写相关系列的文章。 信号量 信号量是一种锁，用于限制资源访问的进程数。 1，基本构建 利用Redis zset数据结构存储持有信号量的进程，score为获取时间。假设我们允许5个进程获取信号量。获取信号量时，进程先把自己的标识和当前系统时间加入zset，检查自己的排序位置是不是小于最多允许的进程数（这里为5）。如果小于，则获取信号量成功，否则失败，删除插入的标识。 这里获取信号量时需要清除过期时间。 这种方式缺点很明显，每个进程指定的超时时间必须一致，否则无法清除超时的锁。 还有一个进程的信号量超时被其他进程释放，但是它自己并不知道，如果他的执行不是事务性的，中间可能被其他进程插入影响结果。 结论：客户端控制锁的问题，彼此之间交流是个问题。如果是Redis自己实现，它完全可以将锁和持有锁的进程映射存储，超时的时候强制回滚。 2，改进，提升公平 当获取信号量的进程位于不同网络主机上时，系统时间可能不一致。如A主机进程和B主机进程，加入A主机系统时间比B主机快，那么即使A首先插入自己的标识，B在没有操过这个时间插入也会偷走A成功获取信号量的机会。 为了提升公平，避免系统时间不一致的影响。可以为Redis实现一个计数器和一个拥有者zset，进程插入自己标识到拥有者zset，先获得计数器，再用计数器值作为score插入。（32位主机可能溢出，64位够用）。 3，刷新和消除竞争 刷新信号量的超时时间，利用上一节提到的分布式锁，消除资源计数器的竞争。 异步队列 1，先进先出队列 使用列表模仿，如果需要实现优先级，可以多个列表表示不同优先级。 2，延时队列 基于有序集合实现（sorted set）。基本思路是将任务作为zset的成员，任务执行时间点作为score。任务执行worker轮询zset，取出第一条数据并检测是否可以执行。 事务 multi、exec、watch、unwatch、discard。 Redis的事务没有回滚机制，某条语句执行错误，multi打包的事务就结束了。因此Redis事务原子性，一致性，持久性都不满足。由于Redis是单线程运行，事务可以保证隔离性。watch、unwatch命令实现类似乐观锁的机制。 Redis支持非事务流水线（pipeline)，会将多个命令一次性发送给Redis，然后等待所以命令结果再返回。pipeline降低了网络延迟消耗。默认pipeline对多个命令不开启事务，不过可以通过参数调整。 Lua脚本 由于Redis事务的缺陷，Redis提供了Lua脚本来保证原子性，但是脚本会阻塞其他客户端进程执行。 通过 EVAL 命令执行脚本。脚本中可以通过 Redis.call 和 Redis.pcall 调用Redis命令 一条简单的Redis脚本示例，传递参数应该由KEYS和ARGV指定。 eval \"return redis.call('set',KEYS[1], ARGV[1])\" 1 foo bar 后述 我们讲解了Redis分布式锁的实现思路和一些问题，并引出了zookeeper的替代方案。关于zookeeper，后期会深入研究并针对它写一系列文章。","tags":"Redis","url":"redisxi-lie-si.html","loc":"redisxi-lie-si.html"},{"title":"Redis系列三","text":"前述 本篇先讲解Redis持久化的两种方式：快照和AOF，然后讲解集群的工作原理和优缺点，最后谈谈分片的机制和应用。本篇内容主要是一些理论上的知识，至于其中一些应用和常见解决方案，后面会视情况单独写。 本篇大部分内容是我学习相关知识的笔记整理，所以并不能成为很好的入门阅读。当然，如果对相关概念已经有所了解，完全可以分散的读相应小节的内容。 部分概念和内容来源于官网和其他网络博文，文中都有链接，可以跟随链接做扩展或深入了解。 Redis持久化 Redis持久化有两种方式，快照（snapshotting）和只追加文件（AOF）。 快照持久化 客户端可以通过 save 命令手动触发快照备份，此时Redis会被阻塞，直到快照备份完成。除了 save 命令，还可以通过 bgsave 命令开启一个子进程在后台备份快照。 bgsave 备份快照时不阻塞Redis服务。但我们知道，克隆子进程是需要复制父进程的内存空间的。如果Redis里的数据很大，比如几十个G，克隆子进程就会花费很长时间，这段时间仍然会阻塞Redis服务。因此， bgsave 命令不一定比 save 命令快，需要视情况而定。 除了手动命令触发快照备份，还可以通过配置让Redis服务自动执行快照备份。下面是Redis服务快照备份相关命令。 save 60 10000 stop-writes-on-bgsave-error no rdbcompression yes dbfilename dump.rdb save配置指定触发快照备份规则，上面的配置表示当60秒之内有10000次写入，Redis服务就会自动触发 bgsave 命令执行快照备份。 由于快照是一定条件才触发，因此可能造成一段时间数据丢失。 AOF持久化 AOF文件类似MySQL数据库的bin-log日志，它会记录Redis服务即将执行的写命令，以此来跟踪数据发生的变化。 通过下面的配置选项启动AOF持久化。 appendonly yes appendsync always appendsync配置选型表示刷新缓冲区内容到磁盘的方式。缓冲区内容刷新到磁盘会造成Redis服务阻塞。appendsync有三个选项，always、everysec、no。always会对每个命令都刷新到磁盘才返回，这样Redis响应速度降低明显。everysec每秒刷新一次缓冲区到硬盘，因此可能丢失1秒的数据。no表示让操作系统决定什么时候刷新缓冲区内容到磁盘。因此，建议的配置选择是everysec。 AOF虽然只会丢失1秒的请求命令，但是它文件增长很快。Redis重启执行AOF恢复数据的时候，AOF很大的情况，还原时间会非常长。 为了防止AOF文件增长过大，可以通过auto-aof-rewrite-percentage和auto-aof-rewrite-min-size配置选项对AOF文件进行重写。客户端也可以发送 bgrewriteaof 命令触发重写。 bgrewriteaof 命令和 bgsave 命令类似，都会克隆一个子进程在后台进行，因此克隆子进程时会造成Redis服务阻塞。 Redis集群 Redis集群是分片的一种实现方式，提供在多个Redis节点间共享数据的程序集。关于分片，请参考下面的小节。 Redis集群实现了所有在非分布式Redis版本中处理单一key的命令。那些使用多个key的复杂操作，比如set里的unions和intersections操作，就没有实现。Redis集群不像单机版本的Redis那样支持多个数据库，集群只有数据库0，而且也不支持SELECT命令。 Redis集群数据一致性 由于Redis集群采取异步复制，所以不能保证强一致。 Redis造成命令丢失的另一种可能情况是集群出现网络分区，即一个master节点的网络不可达形成孤立的节点，此时写入的命令，在从新加入集群后，可能被新选出来的master节点数据覆盖。 Redis集群数据分片实现 Redis集群没有使用一致性hash, 而是引入了哈希槽的概念. Redis集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽。 关于Hash槽实现，参考 官方文档 Redis集群客户端查询方式 Redis客户端可以向集群的任何一个节点发起查询。如果命令是该节点可以处理的，则执行并返回结果。如果节点不能处理，它会分析处理，将查询重定向到能处理的集群节点上。Redis集群客户端重定向主要有两种模式：MOVED重定向和ASK重定向。 MOVED重定向和ASK重定向的区别： 如果是MOVED重定向，比如8号槽被MOVED重定向到A节点，客户端认为所有属于8号槽的key查询都在A节点，如果客户端缓存了映射关系，下次8号槽的数据查询，可以直接向A请求。ASK重定向，只是将某个具体的key查询重定向到一个节点，但是8号槽的其余key查询，可能还在A节点。 ASK重定向的用途是hash槽重分配时，比如A节点的8号hash槽转移到B节点，在没转移完成之前（数据是分部分转移的，避免一次转移造成阻塞时间太长），A节点和B节点之间就存在ASK重定向。 Redis集群客户端重定向方式，允许客户端不需要存储集群槽的映射关系，但是为了高效，当集群稳定后，客户端可以缓存集群映射关系，这样避免了过多重定向。 失效检测 Redis 集群失效检测是用来识别出大多数节点何时无法访问某一个主节点或从节点。当这个事件发生时，就提升一个从节点来做主节点；若如果无法提升从节点来做主节点的话，那么整个集群就置为错误状态并停止接收客户端的查询。 当一个节点在超过NODE_TIMEOUT时间后仍无法访问某个节点，那么它会用PFAIL（可能失效）来标识这个不可达的节点。这是某个节点对另一个节点的主观判断。 单独一个PFAIL标识只是每个节点的一些关于其他节点的本地信息。此时节点会和其它节点同步本地信息，如果大部分节点（通常需要超过一半）标识某个节点为PFAIL，被标识的节点就成为确认失效（FAIL标识）。FAIL标识会强制每个接收到这消息的节点把对应的节点标识为FAIL状态。 更多redis集群知识，参考 Redis集群规范 Redis分片 分片，就是将Redis数据分不到不同主机上，每个主机只拥有完整数据的一部分。 分片优势 通过利用多台计算机内存的和值，允许我们构造更大的数据库。 通过多核和多台计算机，允许我们扩展计算能力；通过多台计算机和网络适配器，允许我们扩展网络带宽。 分片缺点 涉及多个key的操作通常是不被支持的。举例来说，当两个set映射到不同的redis实例上时，你就不能对这两个set执行交集操作。 涉及多个key的redis事务不能使用。 当使用分区时，数据处理较为复杂，比如你需要处理多个rdb/aof文件，并且从多个实例和主机备份持久化文件。 增加或删除容量也比较复杂。 Redis支持的分片类型 1）范围分区 这种方式实现简单，直观，但是需要管理一个区间范围到实例的映射表。 2）哈希分区 这种方式高效，不需要管理映射表。但是可能数据比较分散或冲突。 分片的不同实现 客户端分片：客户端直接选择正确的节点来写入和读取指定键。 代理协助分片：我们的客户端发送请求到一个可以理解Redis协议的代理上，代理会根据配置好的分片模式，来转发我们的请求到正确的Redis实例，并返回响应给客户端。代理Twemproxy实现了代理协助分片。 查询路由：你可以发送你的查询到一个随机实例，这个实例会保证转发你的查询到正确的节点。Redis集群实现了类似功能，但它采用客户端重定向。 更多分片知识，参考官网和 Redis分片 后述 其他一些资料： Redis阻塞篇 Redis代理对比","tags":"Redis","url":"redisxi-lie-san.html","loc":"redisxi-lie-san.html"},{"title":"Redis系列二","text":"前述 本篇先讲讲Redis过期key的删除机制，然后讲解Redis内存淘汰机制，最后针对LRU和LFU讲解和简单对比。 过期key删除策略 惰性删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key。 定期删除：每隔一段时间，Redis对数据库进行检查，删除里面的过期key。 惰性删除 这种策略对CPU友好，但是可能导致内存浪费。如果一个已经过期的key永远不被访问，它所占用的内存也永远得不到释放。 定期删除 定期删除默认每秒10次检查一次过期key，可以通过 hz 配置选项控制检查频率。定期删除会做下面检测和清除步骤。 1）随机测试100个设置了过期时间的key。 2） 删除所有发现的已过期的key。 3） 若删除的key超过25个则重复步骤1。 这是一个基于概率的简单算法，基本的假设是抽出的样本能够代表整个key空间，redis持续清理过期的数据直至将要过期的key的百分比降到了25%以下。这也意味着在任何给定的时刻已经过期但仍占据着内存空间的key的量最多为每秒的写操作量除以4。 内存淘汰机制 除了上面一小节的过期key删除策略，Redis还提供了内存淘汰机制。当使用内存超过 maxmemory 限定时，触发内存淘汰机制。Redis提供了以下几种内存淘汰机制。 noeviction：当内存使用超出maxmemory限制时，客户端访问返回错误（大部分的写入命令，但是DEL命令例外）。 allkeys-lru: 对所有的key应用LRU淘汰机制。 volatile-lru: 仅对设置了过期时间的key应用LRU淘汰机制。 allkeys-random: 随机回收所有的key。 volatile-random: 随机回收设置了过期时间的key。 volatile-ttl: 只对设置了过期时间的key进行回收，但优先回收存活时间（TTL）较短的key。 Redis LRU实现 Redis使用的是近似LRU算法，它跟常规的LRU算法还不太一样。 近似LRU算法通过随机采样法淘汰数据，每次随机取出一定数量的key，从里面淘汰掉最近最少使用的key。可以通过maxmemory-samples配置随机采样的key数量，值越大，越接近真实LRU算法。默认值为5。 Redis的近似LRU算法，避免了对所有的key操作，减少了内存消耗，避免了扫描所有key的时间复杂度。 Redis LFU算法 LFU算法，全称Least Frequently Used。根据访问的频率淘汰访问相对不频繁的key。LFU避免了一个key很少被访问，而最近被访问一次而不被淘汰的问题。LRF算法是4.0新增的。 Redis LFU算法提供了下面两种策略： valatile-lfu：只对设置了过期时间的key应用LFU策略。 allkey-lfu：对所有key基于LFU回收内存。 Redis4.0对LFU增加了两个配置。 lfu-log-factor 10 lfu-decay-time 1 lfu-log-factor：可以调整计数器counter的增长速度，lfu-log-factor越大，counter增长的越慢。 lfu-decay-time：是一个以分钟为单位的数值，可以调整counter的减少速度。 Redis LFU工作机制 Redis会为每个key对象维护一个计数器counter和最近一次计数被减少时的时间（总共24bit，LRU的最近访问时间拆分为两部分分，高位的16bit为最近计数器被减少时的时间，低位的8bit为计数器counter）。 当一个key被访问需要增加计数器counter时，需要根据两个因子r、p比较，当 r < p 时，counter自增1，否则不增加。其中r因子为 0-1 之间的随机数，p因子由当前的counter值和配置项 lfu-log-factor 共同决定。 需要减少counter值时，并不是总减少1。Redis会计算key对象最近一次被减少时间相对于目前时间过去了多少个lfu-decay-time，即 (now - last_dect_time) / lfu-decay-time 的值，counter即减去算出来的值。 基于现在时间和最近一次操作时间的差值，解决了 一个key一段时间访问频繁，从而counter值增加，但是后期访问频率比较低甚至不访问，如果只是简单的累加counter，那这种情况则不能很好的被清除。 下面的Redis源码展示了counter计数器增加和减少的逻辑，详细代码讲解可以参考本章最后面的参考资料链接 Redis中的LFU算法 。 uint8_t LFULogIncr ( uint8_t counter ) { if ( counter == 255 ) return 255 ; double r = ( double ) rand () / RAND_MAX ; double baseval = counter - LFU_INIT_VAL ; if ( baseval < 0 ) baseval = 0 ; double p = 1.0 / ( baseval * server . lfu_log_factor + 1 ); if ( r < p ) counter ++ ; return counter ; } unsigned long LFUDecrAndReturn ( robj * o ) { unsigned long ldt = o -> lru >> 8 ; unsigned long counter = o -> lru & 255 ; unsigned long num_periods = server . lfu_decay_time ? LFUTimeElapsed ( ldt ) / server . lfu_decay_time : 0 ; if ( num_periods ) counter = ( num_periods > counter ) ? 0 : counter - num_periods ; return counter ; } 由于LFU需要根据counter排序，如果对所有的key操作，肯定会影响Redis的吞吐量。基于这个原因，可以参考LRU算法，给定一个固定的pool，随机选取一批key，再在被选中的key中应用LFU淘汰机制。 后述 参考资料： Redis官方文档： Using Redis as an LRU cache Redis的内存淘汰策略 Redis中的LFU算法 Redis系列其他文章： Redis Sentinel模式 Redis概述和数据类型","tags":"Redis","url":"redisxi-lie-er.html","loc":"redisxi-lie-er.html"},{"title":"Redis系列一","text":"前述 本篇讲述的内容主要是一些概念性的东西，彼此之间没有太多关联性，也不打算太深入，写的时候觉得是个知识点都会把它记录下来，后续会针对某些内容单独写篇文章，可以关注Redis系列的其它内容。 本篇的最后，泛概讲解了下Redis常见数据类型String，List， Hash，Set，ZSet的C语言结构。相关内容参考了 Redis设计与实现 Redis特点 是一个单线程应用。 是一个内存中的数据结构存储系统，支持丰富数据类型。 常用作缓存，可以持久化数据到硬盘。 支持简单的消息队列协议，可用作普通的消息队列中间件。 内置Lua脚本支持。 支持事务和LRU事件。 Pub/Sub（分发和订阅） Publisher（生产者）不将消息发送给特定的Consumer（消费者），而是发送到channel（频道）。订阅相应channel的Consumer都将收到消息，Publisher往channel分发消息，它不需要知道都有哪些Consumer订阅了消息。 GeoHash原理 下面是Pub/Sub最简单的使用。 首先客户端订阅了两个channel。分别是first，second。 127.0.0.1:6379[1]> SUBSCRIBE first second Reading messages... (press Ctrl-C to quit) 1) \"subscribe\" 2) \"first\" 3) (integer) 1 1) \"subscribe\" 2) \"second\" 3) (integer) 2 服务端Publisher分发消息 127.0.0.1:6379> PUBLISH first hello (integer) 1 127.0.0.1:6379> PUBLISH second \"hello redis\" (integer) 1 客户端将收到如下消息 1) \"message\" 2) \"first\" 3) \"hello\" 1) \"message\" 2) \"second\" 3) \"hello redis\" Pipelining模式 Pipelining即管道。使用Pipelining，我们可以一次向Redis发送多个命令请求，并一次获得请求结果。Pipelining有如下优点。 避免单个命令发送多次阻塞。Redis每一个命令请求，Client都会阻塞等待结果。Pipelining一次向Redis Server发送多个命令，减少了阻塞次数。 减少了网络RTT。Pipelining将请求和回复一次传输，减少了网络传输次数和总时间。 降低了Socket IO时间。对于Redis命令，请求和产生结果相对较快，而读写IO相对较慢。一次Pipelining请求只读写一次IO，这比多个命令分开请求减少了IO读写次数。 数据持久化 Redis提供快照RDB和AOF两种持久化方式。RDB持久化方式会在一个特定的间隔保存那个时间点的一个数据快照。AOF持久化方式则会记录服务器收到的每一个写操作。在服务启动时， 重新执行这些日志重建原来的数据。 RDB工作方式 Redis调用fork()，产生一个子进程。 子进程把数据写到一个临时的RDB文件。 当子进程写完新的RDB文件后，把旧的RDB文件替换掉。 RDB和AOF优缺点对比 参加 Redis持久化 和官网 Redis Persistence 内存优化 Redis string数据结构没有采用C预约的string，而是自己设计了数据结构，保持了字符串长度和预分配空间。由于预分配空间的存在，会造成内存浪费，因此不要频繁的使用字符串append操作。 共享内存。Redis存储整数时会共享内存。但是设置maxmemory和LRU时失效，应注意相关数据和设置的优化。 编码优化。当对象数量和体积比较小时，Redis会使用压缩列表或整数集合存储。使用OBJECT ENCODING key查看存结构。 控制key数量。过多的key会造成内存浪费，可以将多个key整合到hash类型里，并保证value不超过hash-max-ziplist-value限制，这样可以利用ziplist编码。 参考 Redis的内存优化 和官网 memory-optimization Redis内存优化 缓存更新策略 被动删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key 主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key 当前已用内存超过maxmemory限定时，触发主动清理策略 事务 Redis通过MULTI、DISCARD、EXEC和WATCH四个命令来实现事务功能。Redis事务并不保证严格的事务特性，当执行错误时，并不能回滚到之前的操作。下面是Redis事务和严格事务的特性对比。 原子性（Atomicity），Redis单个命令是原子性的，但是Redis事务并不保证原子性，因为执行发生错误它并不回滚。 一致性（Consistency），入队错误，执行错误保证一致性。 隔离性（Isolation），Redis是单线程，事务总是满足隔离性的。 持久性（Durability），持久性和是内存模式还是硬盘模式有关。内存模式重启数据丢失。 数据类型 1: string Redis的string类型未复用C，自定义类型SDS。类型定义如下。 struct sdshdr { int len ; // 长度 int free ; // 剩余可用空间 char buf []; // 保存字符串的数组 }; 使用SDS有如下优点。 保存了字符串长度，获取长度的时间复杂度为O(1)。 SDS的free可以减少字符串扩展和收索时的内存再分配次数，也可以用来避免数组溢出。 二进制安全，不靠'\\0'判断字符串是否结束，而是字符串长度。 2: list Redis list中每个节点是一个 listNode 结构，多个 listNode 组成一个双向链表。而list结构本身保存链表的长度，头尾指针，以及三个操作函数。 typedef struct listNode { struct listNode * prev ; struct listNode * next ; void * value ; // 节点值保存指针 } listNode ; typedef struct list { listNode * head ; listNode * tail ; unsigned long len ; void * ( * dup )( void * ptr ); // 节点复制函数 void ( * free )( void * ptr ); // 节点释放函数 int ( * match )( void * ptr , void * key ); // 节点对比函数 } list ; 基于list结构，读取list头尾节点元素的时间复杂度为O(1)，读取list长度的时间复杂度也是O(1)。 3: hash typedef struct dictht { dictEntry ** table ; // hash表数组 unsigned long size ; // 哈希表容量大小 unsigned long sizemask ; // 哈希表大小掩码，用于计算索引值 unsigned long used ; // 元素个数 }; typeof struct dictEntry { void * key ; // 键 union { // 值 void * val ; uint64_tu64 ; int64_ts64 ; } struct dictEntry * next ; }; 上面是Redis hash表的定义，每个hash表元素类型为 dictEntry ，如果hash值冲突，会用next指针指向下一个 dictEntry 节点（链地址法）。 Redis又在dictht的基础上，又抽象了一层字典dict。 typedef struct dictType { uint64_t ( * hashFunction )( const void * key ); void * ( * keyDup )( void * privdata , const void * key ); void * ( * valDup )( void * privdata , const void * obj ); int ( * keyCompare )( void * privdata , const void * key1 , const void * key2 ); void ( * keyDestructor )( void * privdata , void * key ); void ( * valDestructor )( void * privdata , void * obj ); } dictType ; typedef struct dict { dictType * type ; void * privdata ; dictht ht [ 2 ]; long rehashidx ; /* rehashing not in progress if rehashidx == -1 */ unsigned long iterators ; /* number of iterators currently running */ } dict ; type和privdata是针对不同类型键值对，为创建多态字典而设置的。type指向 dictType 的指针，而privdata则是传给那些类型特定函数的可选参数。 ht属性包含两个 dictht 元素的数组，其中ht[1]只用字rehash（hash重构）时才使用。 4: set 下面是整数集合的结构。如果集合包含的元素足够少，且所有成员都能表示为平台有符号范围之内的十进制整数，那么Redis会采用整数集合这种有序数组来存储集合。 typedef struct intset { uint32_t encoding ; //编码方式 uint32_t length ; // 集合包含的元素数量 int8_t contents []; //保存元素的数组 }; 上面的intset contents虽然定义成int8类型，但它实际存储类型根据encoding而定，可能是int16，int32，int64等。 对于原先所有元素都用int16表示的intset，如果新插入的元素需要int32或者int64表示，就需要对contents进行升级（重新分配更大的空间），然后将原有的元素复制到新分配的空间，再插入新元素，仍需保持intset的有序。 关于更多intset升级的内容，可以查看黄健宏的《Redis设计与实现》 升级 5: sorted set 有序集合的底层实现是跳跃表（skiplist），是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速查找访问节点的目的。 typedef struct zskiplistNode { //层 struct zskiplistLevel { //前进指针 struct zskiplistNode * forward ; //跨度 unsigned int span ; } level []; //后退指针, 用于从表尾向表头方向访问节点 struct zskiplistNode * backward ; //分值, 用于排序 double score ; //成员对象 robj * obj ; }; 跳跃表是链表的扩展，是一种快速查找结构。相比B树，红黑树等平衡二叉树，跳跃表实现简单。 下图是一个简单的跳跃表 相对于普通链表，跳跃表随机化给节点分层，增加前向指针，从而利用二分查找的优势。 跳表具有如下性质： (1) 由很多层结构组成 (2) 每一层都是一个有序的链表 (3) 最底层(Level 1)的链表包含所有元素 (4) 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。 (5) 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。 参考资料： 跳跃表原理 跳跃表 6: 压缩列表（ziplist） 在列表，散列，有序集合长度比较短或者体积比较小时，Redis可以选择用ziplist这种紧凑结构来存储这些类型。对于大小和体积，可以通过配置项修改。下面是list使用ziplist的默认配置项，hash和zset把开头的list更换也有对应的配置。 list-max-ziplist-entries 512 list-max-ziplist-value 512 ziplist的连锁更新 下面是压缩列表每个节点元素的构成结构。 | previous_entry_length | encoding | content | 其中previous_entry_length存储前一个元素的长度，encoding存储当前节点元素类型和长度，content存储当前节点元素内容。 对于previous_entry_length，当前一个元素长度小于254字节，需要1个字节来存储长度。当前一个元素长度大于等于254时，需要5字节来存储长度。 如上所述，Redis为了节省内存，previous_entry_length所占空间长度是根据前一个元素的长度变动的。因此，当插入一个长度大于254的元素时，就可能造成当前节点的previous_entry_length空间无法存储其长度，因此需要扩展，而这样的扩展，就可能造成下一个节点的扩展，这种现象叫ziplist的连锁更新。 连锁更新时间复杂度为O(N&#94;2) ，但是触碰的几率很低。 关于连锁更新更详细介绍，可以查看黄健宏的《Redis设计与实现》 连锁更新 上面的配置中，entries项指定在ziplist下允许包含的元素最大数量，value指定ziplist下每个节点的最大体积。如果超过这个限制，Redis会将ziplist存储转换为对应类型通常的存储结构。 参考资料： Redis原理 quiklist 在用 DEBUG OBJECT 查看list和hash的encoding时，我们看到有一种存储类型是quiklist。它是zipList和linkedList（双向链表）的混合体，它将linkedList按段切分，每一段使用zipList来紧凑存储，多个zipList之间使用双向指针串接起来。 下面是一个简单的quiklist示例图。 下面是quiklist的Redis C定义。 struct quicklist { quicklistNode * head ; quicklistNode * tail ; long count ; // 元素总数 int nodes ; // ziplist 节点的个数 int compressDepth ; // LZF 算法压缩深度 ... } struct quicklistNode { quicklistNode * prev ; quicklistNode * next ; ziplist * zl ; // 指向压缩列表 int32 size ; // ziplist 的字节总数 int16 count ; // ziplist 中的元素数量 int2 encoding ; // 存储形式2bit，原生字节数组还是LZF压缩存储 ... } 参考资料 quiklist 后述 本篇大体讲解了Redis一些常见概念和数据类型，Redis的其它系列会扩展和讲解其它知识点，下面是一些内容。 Redis Sentinel模式 Redis内存淘汰机制","tags":"Redis","url":"redisxi-lie-yi.html","loc":"redisxi-lie-yi.html"},{"title":"MySQL系列五","text":"前述 本篇标题是MySQL分布式事务，但MySQL分布式事务只是对相关理论的实现，所以会花很大篇幅介绍分布式相关理论、解决方案，最后再讲解MySQL对XA协议的实现。 分布式事务理论 什么是分布式事务呢？ 分布式事务是很多网络主机参与的事务，支持事务的事务管理器，资源管理器位于不同的网络节点上。 CAP定理 所谓CAP定理，是指在一个分布式系统中，无法同时满足一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance），最多只能满足其中两个。下面解释下这三个分布式指标。 一致性（Consistence）：对于分布式系统的任何节点做更新，其他节点应该同步更新，多个节点读取到的数据不应该存在差异。 可用性（Availability）：可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作，请求总是能够在有限的时间内返回结果，如果超过了这个时间范围，那么系统就被认为是不可用的。\"有限的时间内\"是在系统的运行指标，不同系统会有差别。\"返回结果\"是可用性的另一个重要指标，它要求系统完成对用户请求的处理后，返回一个正常的响应结果，要明确的反映出对请求处理的成功或失败。 分区容错性（Partition Tolerance）：当分布式系统各节点网络不可达成独立的部分时，每个独立部分就叫一个分区。分区容错性要求各节点不连通时，能独立的提供完整的功能。因此要求每个分区有其他分区的数据复制。 对于实际应用，分区容错性是需要保证的。提高分区容错性，要求将数据复制到多个节点。然后，数据复制到多个节点，就会存在数据一致性问题。如果强制写同步，就会造成客户端请求阻塞时间变长，可能导致有限时间不能返回结果，从而影响可用性。 综上，CAP是不可能同时满足的，实际应用都是CA和CP。当然，大部分生产环境，都更看中可用性，而弱化一致性。一致性可以通过消息通信、补偿等机制，达到最终一致便可。 BASE定理 正如上一小节所讲，实际应用大部分情况都是弱化一致性，达到最终一致性即可。最终一致性便是BASE定理，是CAP定理的延伸。下面看看BASE定理的三个指标。 基本可用：指分布式系统在出现故障的时候，允许损失部分可用性（例如响应时间、功能上的可用性）。 软状态：指允许分布式系统出现中间状态。如异步主从复制，允许数据同步的延时。 最终一致性：最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。 以上内容参考 CAP和BASE理论 分布式事务实现方案 2PC方案 2PC分两个阶段，第一阶段准备阶段，第二阶段提交和回滚。下面分别介绍下这两个阶段。 1）准备阶段 在准备阶段，事务管理器（下面称协调者）向所有资源管理器（下面称参与者）下发prepare指令，参与者收到指令后，锁定所需要的资源，并把undo和redo写入日志。 2）提交或回滚阶段 如果第一阶段所有参与者都像协调者确认成功，那么协调者会向所有参与者发送commit指定，事务提交。否则，只要第一个阶段有一个参与者没有确认成功，就发送rollback指令，事务回滚。 由于2PC没有超市机制，在准备阶段，如果其中一台参与者宕机，就会造成协调者一直阻塞等待，影响并发性能。而且并发性能，又性能最低的参与者决定。 3PC方案 3PC（三阶段协议方案）是对2PC的改进。它分CanCommit，PreCommit，DoCommit三个阶段。 1）CanCommit 协调者向所有参与者询问是否可以进行事务提交。 2）PreCommit 如果第一阶段所有参与者都能进行事务提交，协调者下发PreCommit指令。协调者锁定资源，等待下一步指令。如果第一阶段有一个或以上参与者不能进行事务提交，下达中断指令。 3）DoCommit 如果第二阶段所有参与者都确认成功，下达Docommit指令，事务提交。否则下达事务回滚指令。 三阶段提交对比两阶段，引入超时机制减少事务阻塞，解决单点故障。在第三阶段，一旦参与者无法接受到协调者信号时，等待超时之后，参与者默认执行 commit，释放资源。 三阶段任然不能解决数据一致性问题。若协调者发出回滚命令，但是由于网络问题，参与者在等待时间内都无法接收到，这时参与者默认提交事务，而其他事务进行了回滚，造成事务不一致。 TCC 2PC和3PC都是数据资源库资源层的实现方案，TCC则是业务层面的实现方案，是对BASE定理的很好解决方案。 TCC是Try、Confirm和Cancel三个单词的首字母，它们相当于编程语言的异常机制。尝试执行某些语句，成功则提交，失败则做一些清除工作。下面介绍三个情况。 TCC实现的一个方案就是维护本地消息列表，对每个事务记录日志，定期扫描日志，对失败的事务重新提交或撤销，以保证所有参与者数据最终一致。 参考资料： 分布式事务的图文详解 MQ事务消息 很好的实现方案是阿里开源的RocketMQ，这里不再介绍，可以查看相关资料。 参考资料： 分布式事务解决方案 MySQL分布式事务的实现 MySQL是资源管理器（参与者），因此它实现的是XA协议（2PC和3PC），MySQL有内部XA事务和外部XA事务。 内部XA事务 MySQL的各存储引擎是独立的，因此需要XA事务协调。对于二进制日志的操作，写需要XA事务。此时MySQL数据库服务器相当于协调者，而各存储引擎或二进制日志写线程作为参与者。 外部XA事务 这种情况MySQL作为一个完整的参与者组成分布式系统。MySQL对XA协议支持并不是很完整，因此更多的是通过其他解决方案，这里不再介绍。 后述 分布式系统的CAP问题，是计算机的难点问题。如何保证数据的一致性和可用性，更多的情况是采取弱一致性，基于本地消息补偿实现最终一致。阿里的RocketMQ也是一种很好的方案。","tags":"MySQL","url":"mysqlxi-lie-wu.html","loc":"mysqlxi-lie-wu.html"},{"title":"MySQL系列四","text":"前述 本篇前面讲解分区表，最好讲解主从复制的一些原理和架构思想。这里不打算讲主从复制的搭建。 分区表概述 分区表对用户来说仍然是一个独立的逻辑表，但是底层由多个物理子表组成。首先我们使用下面的语句创建一个分区表，来看看分区表的组成。对于分区表的创建类型，后面会讲。 CREATE TABLE user_partition ( id INT , name char ( 20 ), age int ) PARTITION BY RANGE ( age ) ( PARTITION u1 VALUES LESS THAN ( 6 ), PARTITION u2 VALUES LESS THAN ( 18 ), PARTITION u3 VALUES LESS THAN ( 30 ), PARTITION u4 VALUES LESS THAN ( 50 ), PARTITION u5 VALUES LESS THAN ( 65 ), PARTITION u6 VALUES LESS THAN ( 80 ), PARTITION u7 VALUES LESS THAN ( 100 ), PARTITION uother VALUES LESS THAN ( MAXVALUE ) ); 我在测试库 partition_db 创建了一个分区表 user_partition ，并根据年龄范围存储在8个子分区表中。用 show tables 看看建表情况，显示的情况和普通表一样，只有一个。这也说明了分区表对用户逻辑上只有一个。 mysql> show tables ; +------------------------+ | Tables_in_partition_db | +------------------------+ | my_range_datetime | | user_partition | +------------------------+ 2 rows in set ( 0 .01 sec ) 接下来我们看看底层存储情况，进入MySQL数据存储目录，在Linux系统上，默认是/var/lib/mysql，具体位置要根据你的配置。找到 partition_db 库目录，通过 ls -l | grep user 查看表文件情况。 -rw-rw---- 1 xufan staff 98304 3 19 19 :43 user_partition#P#u1.ibd -rw-rw---- 1 xufan staff 98304 3 19 19 :43 user_partition#P#u2.ibd -rw-rw---- 1 xufan staff 98304 3 19 19 :43 user_partition#P#u3.ibd -rw-rw---- 1 xufan staff 98304 3 19 19 :43 user_partition#P#u4.ibd -rw-rw---- 1 xufan staff 98304 3 19 19 :43 user_partition#P#u5.ibd -rw-rw---- 1 xufan staff 98304 3 19 19 :43 user_partition#P#u6.ibd -rw-rw---- 1 xufan staff 98304 3 19 19 :43 user_partition#P#u7.ibd -rw-rw---- 1 xufan staff 98304 3 19 19 :43 user_partition#P#uother.ibd -rw-rw---- 1 xufan staff 8614 3 19 19 :43 user_partition.frm -rw-rw---- 1 xufan staff 52 3 19 19 :43 user_partition.par 上面是我的机器上显示结果。可以看到，分区表底层存储对应的是多个分区子表，这里是8个，就是上面展示的以#分隔命名的标文件。 user_partition.frm 文件存储表结构， user_partition.par 存储分区信息。 由于分区表是对底层表的封装，所以索引等也是独立建立在分区表子表上，而没有全局索引。对分区表的请求，都会通过句柄对象，转换为对存储引擎接口的调用，最后落实到具体的分区子表上。 分区表的操作 1: 查看分区 mysql > SELECT PARTITION_NAME , TABLE_ROWS FROM INFORMATION_SCHEMA . PARTITIONS WHERE TABLE_NAME = 'user_partition' ; +----------------+------------+ | PARTITION_NAME | TABLE_ROWS | +----------------+------------+ | u1 | 0 | | u2 | 0 | | u3 | 0 | | u4 | 0 | | u5 | 0 | | u6 | 0 | | u7 | 0 | | uother | 0 | +----------------+------------+ 8 rows in set ( 0 . 01 sec ) 我们看到， user_partition 分区表有8个分区子表组成。 2: 增加和删除分区子表 ALTER TABLE user_partition ADD PARTITION ( PARTITION u6_1 VALUES LESS THAN ( 90 )); 执行上面的命令，会报错 MAXVALUE can only be used in last partition definition 。可以看到，增加分区只能递增的形式，新分区不能再包含已有分区的值。 用下面的命令先删除最后一个分区 ALTER TABLE `user_partition` DROP PARTITION uother ; 再执行上面的命令，现在报 VALUES LESS THAN value must be strictly increasing for each partitio ，这是因为上面所说的，新增加的子分区不能包含已有分区的值。 将增加分区的数值改改，如下，执行成功。 ALTER TABLE user_partition ADD PARTITION ( PARTITION u6_1 VALUES LESS THAN ( 120 )); 如果对于已经存在的一个表，且已经有数据，需要把它变成分区表，可执行下面的命令。 alter table user partition by range(age) ( PARTITION u1 VALUES LESS THAN (6), PARTITION u2 VALUES LESS THAN (18) ); 3: 分区表的使用 分区表的使用和普通表一样，直接插入就行，查询也是。 INSERT INTO user_partion ( name , age ) VALUES ( \"zhangsan\" , 30 ); INSERT INTO user_partion ( name , age ) VALUES ( \"wanger\" , 105 ); mysql > select * from user_partition ; +------+----------+------+ | id | name | age | +------+----------+------+ | NULL | zhangsan | 30 | | NULL | wanger | 105 | +------+----------+------+ 2 rows in set ( 0 . 00 sec ) 对应到底层，会先锁住分区表的所有底层表，再调用存储引擎接口操作对应的底层表。 分区表的创建类型 1: RANGE分区 基于属于一个给定连续区间的列值，把多行分配给分区。基于分区的列判断数值需是整型，如果不是需要用函数转换。如时间类型，可以用to_days函数转换为整型。 2: LIST分区 LIST分区和RANGE分区类似，区别在于LIST是枚举值列表的集合，RANGE是连续的区间值的集合。二者在语法方面非常的相似。 3: HASH分区 基于给定的分区个数，将数据分配到不同的分区，HASH分区只能针对整数进行HASH，对于非整形的字段只能通过表达式将其转换成整数。 3: KEY分区 KEY分区其实跟HASH分区差不多，不同点如下： KEY分区允许多列，而HASH分区只允许一列。 如果在有主键或者唯一键的情况下，key中分区列可不指定，默认为主键或者唯一键，如果没有，则必须显性指定列。 KEY分区对象必须为列，而不能是基于列的表达式。 KEY分区和HASH分区的算法不一样，PARTITION BY HASH (expr)，MOD取值的对象是expr返回的值，而PARTITION BY KEY (column_list)，基于的是列的MD5值。 更多分区类型详情，请参考 分区表基本类型 分区表如何跨存储 创建分区表时，可以分别通过 INDEX DIRECTORY 和 DATA DIRECTORY 指定分区子表数据文件和索引文件存储路径。如果路径是挂载的磁盘、RAID或者NFS，可以将数据保持到多个存储介质上。 分表和分区表 分表，是将一张大表拆分成多张逻辑表，用户层面看到多张表，而MySQL分区表用户层面只看到一张。对于分表，客户端应用可以根据id或其他一些条件判断读哪一张表，或者加一层代理。 分表实现比较灵活，现在有Merge存储引擎支持分表操作。 后述： 对分区表的使用有限，没有太多实战经验，因此这里就不谈使用场景等了，先把基础的知识记录下来，后面有更多的使用经验或心得，再来更新。","tags":"MySQL","url":"mysqlxi-lie-si.html","loc":"mysqlxi-lie-si.html"},{"title":"MySQL系列三","text":"前述 本篇先讲解MySQL索引的三种数据结构实现：B+Tree索引、Hash索引、Full-Text索引。然后讲解InnoDB 和MyISAM存储引擎B+Tree索引的差异。最后浅谈索引优化。 MySQL的索引是存储引擎层而不是服务器层实现的。所以，并没有统一的索引标准。 MySQL索引数据结构 1: B+Tree索引 上图是一个简单的B+Tree结构，它有如下特点： 1）节点分内部节点和叶子节点。各叶子节点到根节点的高度一致。 2）内部节点不存储数据，只存储key，数据只存储在叶子节点上。 3）内部节点的key都是按从小到大的顺序排列的。对于一个给定的key，它的左子树的key都小于它，右子树的key都大于或等于它。 4）每个叶子节点都有一个指针指向下一个节点，方便顺序遍历和范围查询。 更多B+Tree结构的知识，参考文章 B树和B+树的插入、删除图文详解 基于上述B+Tree的特点，B+Tree索引有如下优点： 1）内部节点不存储数据，可以容纳更多的索引项，可以定位更多的叶子节点，降低了树的高度，从而减少了索引查询的IO次数。通常数据库的索引B+Tree高度是2或者3。 2）由于叶子节点之间有指针，方便遍历和范围查询，而且结果排序。 2: Hash索引 Hash索引有以下特点： 1）快，对于一个确定的Key，查询时间复杂度为O(1)。 2）索引是离散的，因此不支持范围查询和排序。 3）由于需要完整的key计算Hash值，因此Hash索引不支持匹配查询，只支持 =，IN 等值查询。 4）数据量比较大时，产生冲突的概率变大，维护Hash索引的成本变高。 备注：Memory引擎默认索引即为Hash索引，InnoDB引擎提供自适应Hash索引。 3: Full-Text索引 对于一个给定的key，如果希望匹配过滤查询，可以使用LIKE模糊匹配。但是由于B+Tree索引最左匹配的原则，类似%key%的查询，B+Tree索引将失效，因此此时需要全文索引。 MyISAM 和 InnoDB 存储引擎均支持全文索引，只在文本类型如char，varchar，text上可以应用全文索引。 InnoDB B+Tree索引的分类 1: 主键索引 在创建表的时候通过PRIMARY KEY指定。如果创建表时未指定主键，会选择一个非空的唯一索引作为主键，如果没有这样的索引，MySQL会创建一个数字id作为主键。每个表只能有一个主键。 InnoDB的主键是一种聚簇索引，它的叶子节点存储了key和对应的数据。关于聚簇索引，后面关于InnoDB和MYISAM B+Tree索引机制的差异会详细谈及。 2: 唯一索引 唯一索引相对主键索引，允许为空，且每个表能存在多个唯一索引。 3: 普通索引 普通索引相对于主键索引，叶子节点存储的是key和对应的主键id值，因此如果未索引覆盖，可能产生回表查询。下面先解释下索引覆盖和回表。 1）回表 上图是下面 user 表的主键索引和普通索引name的回表现象。 如果需要查询的是 SELECT id, name, sex FROM user WHERE name=\"zhangsan\" 。此时由于sex列并不在普通索引name的key里面，因此需要再通过主键查询拿到具体的数据。这种两次查询的现象就叫回表。 MySQL有自己的查询优化器，当检查到查询字段太多，比如 SELECT * FROM table WHERE name=\"zhangsan\" ，优化器会选择直接通过主键索引查询，从而避免产生回表。可以通过 EXPLAIN 指令查看某一条SQL语句走的是哪一个索引。 CREATE TABLE user ( id int primary key , name varchar ( 20 ), sex varchar ( 5 ), index ( name ) ) engine = innodb ; 2）索引覆盖 对于上面的查询，如果只查询id和name字段，那么普通索引name的key就能提供所需的字段，不需要再回表查询，这就是索引覆盖。为了查询sex时也能索引覆盖，我们可以建一个name和sex字段的多列索引。 参考资料: 回表 MYSQL-B+TREE索引原理 InnoDB和MyISAM索引差异 下图是MyISAM引擎的索引图，图片来自网络，侵权请告知删除。 可以看到，MyISAM引擎的索引也是一种B+Tree数据结构，不过叶子节点存储的是key和行记录指针。这种叶子节点不储存行数据的索引称为非聚集索引，相对应的，InnoDB引擎的主键索引就是聚集索引，它的叶子节点存储key和行数据。 相对于InnoDB索引，当出现行移动或页分离时，数据移动更少。由于MyISAM的主键和普通索引都是相同的存储机制，因此对于普通索引，没有回表现象的产生。 说明：页是MySQL的存储单元，默认大小为16k。对于InnoDB，逻辑存储结构是一个表空间，表空间包含段，区，页。页里面才是具体的行记录数据。 索引优化 本节讲解一些索引优化技巧，相关内容来源于《高性能MySQL》。这里的索引仅仅指InnoDB存储引擎的B+Tree索引。 1）对于普通索引查询，尽可能使用索引覆盖，避免回表。 2）避免多个范围查询条件。 对于范围查询条件，MySQL无法再使用范围列后面的其它索引列了。我们可以把它改成多个等值条件查询，等值查询没有这个限制。如下面的age条件可以改成IN等值查询。 SELECT id , name , age FROM ueser WHERE created_date >= \"2019-01-01\" and age BETWEEN 18 AND 25 ; 3）优化排序。索引可以用来排序，结合LIMIT限制提升性能。 4）由于最左匹配原则，对于多列索引，索引列的顺序很关键。因此，需要将选择性更高的列放在索引最前面。（为了避免随机IO和排序需要，可能这条就不适用了） 5）维护索引和表，整理数据碎片化（OPTIMIZE TABLE）。 非索引查询优化 1）避免查询不必要的记录。如返回所有的列，联表查询返回所有的列。 2）切分和分联关联查询。这条是为了上条避免查询不必要的记录。MySQL连接池作用，网络开销很小。避免磁盘IO应重于网络权重。 3）充分利用MySQL查询的优化器，关于优化器参考其他资料。 后述 参考资料： 《高性能MySQL》第五张和第六章","tags":"MySQL","url":"mysqlxi-lie-san.html","loc":"mysqlxi-lie-san.html"},{"title":"MySQL系列二","text":"前述 本篇只打算讲解一些事务和锁的基本概率，关于事务和锁的一些细节和扩展知识，会单独写相应的文章介绍，比如分布式事务，MCVV实现机制。下面是一些链接。 分布式事务 MCVV 事务特点 Atomicity（原子性）：一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中的一部分操作。 Consistency（一致性）：数据库总是从一个一致性状态转换到另一个一致状态。 Isolation（隔离性）：通常来说，一个事务所做的修改在最终提交以前，对其他事务是不可见的。注意这里的\"通常来说\"。 Durability（持久性）：一旦事务提交，则其所做的修改就会永久保存到数据库中。此时即使系统崩溃，修改的数据也不会丢失。 事务隔离级别 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据。 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)。 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读。 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。 锁的类型 共享锁，两个事务可以同时读。 排他锁，只要一个事务获取到锁，另一个事务读和写都需等待锁释放。 锁的粒度 行锁，InnoDB默认粒度。 页锁，行锁可以通过锁升级升级为行锁。 表锁，MyISAM默认的粒度。InnoDB的意向锁（意向共享锁和意向排它锁）也是表锁。 锁的一些问题 丢失更新 定义：事务T1读取了数据，并执行了一些操作，然后更新数据。事务T2也做相同的事，则T1和T2更新数据时可能会覆盖对方的更新，从而引起错误。 解决方法：将事务串行化，给事务加排它锁，等事务T1读取并更新数据库完成，事务T2在读取更新数据库。 脏读 定义：所谓脏读，就是一个事务可以读到另一个事务未提交的数据。当锁级别是READ UNCOMMIT（未提交读）时，就会产生脏读。 解决方法：将锁的隔离级别改成READ COMMIT即可防止脏读。 不可重复读 定义：在第一个事务两次读取同一数据之间，第二个事务对数据做了更新，使得第一个事务两次读到的数据不一致。不可重复读强调更新，幻读强调插入和删除。 解决方法：将第一个事务的两次读捆绑成一个整体的事务。将锁的隔离级别改成REPEATED READ。 幻读 所谓幻读，就是同一个事务，用同样的范围查询读取两次，得到的记录数不相同。 解决方法：利用范围锁RangeS RangeS_S模式，锁定检索范围为只读，这样就避免了幻读问题。或者直接将事务隔离级别改成Serializable。InnoDB通过多版本并发控制（MVCC）解决幻读。 死锁 定义 死锁发生在并发的情况。一个事务申请资源时，需要获得锁，如果锁已经被其他事务获取（排它锁），这时这个事务就将阻塞等待锁的释放。如果这两个事务互相等待，就造成死锁。 解决方法 锁检测和锁超时。如果获取锁超时，自动放弃获取锁，并将事务回滚，将已经获得的锁释放。 死锁产生的四个必要条件 1）互斥条件：对所需要获取的资源进行排他性控制； 2）不可剥夺条件：所需要的资源在锁未释放前，不可被其他事务夺走； 3）请求和保持条件：事务已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求事务被阻塞，但对自己已获得的资源保持不放。 4）循环等待链：存在一种事务资源的循环等待链，形成一个等待环。 多版本并发控制（MVCC） MVCC读不加锁，读写不冲突，提高系统并发性能。不同的数据库和存储引擎对MVCC实现都不同，下面以InnoDB的实现为例。 MySQL会给每一行增加两个隐藏列： DATA_TRX_ID 和 DATA_ROLL_PTR ，分别代表操作该行的最新事务id和undo指针。事务id在每次执行都会自动加1。 MVCC有下面几个特点（看起来有点乐观锁的味道）： 1）每行数据都存在一个版本。 2）每次数据更新时都更新该版本 修改时Copy出当前版本随意修改，个事务之间无干扰。 3）保存时比较版本号，如果成功（commit），则覆盖原记录；失败则放弃copy（rollback）。 对于SELECT操作，InnoDB只查找版本号必须小于等于事务版本的数据行。这确保当前事务读取的行都是事务之前已经存在的，或者是由当前事务创建或修改的行。 对于UPDATE操作，InnoDB会先加排它锁，把行原本记录拷贝到undo log。产生一个新的版本号（事务id加1）， DATA_TRX_ID 存储新的事务id， DATA_ROLL_PTR 指向原记录undo log，然后更新值。 对于INSERT操作，插入新记录， DATA_TRX_ID 存储最新的事务id。 对于DELETE操作， DATA_TRX_ID 记录删除该事务id。当然这里是软删除，真正删除在事务commit时。","tags":"MySQL","url":"mysqlxi-lie-er.html","loc":"mysqlxi-lie-er.html"},{"title":"MySQL系列一","text":"MySQL知识点很多，有人专门整理了 MySQL学习的书籍 体系结构 MySQL被设计成单进程多线程的数据库。 如上图，MySQL系统结构由八部分组成。 连接池组件 管理服务和工具组件 SQL接口组件 查询分析组件 优化器组件 缓冲组件 插件式存储引擎 存储文件 名词解释 OLTP：联机事务处理 OLAP：联机分析处理 页： InnoDB存储引擎的表空间由段（segment），区（extent）和页（page）组成，一页默认16K。 聚集索引：正文内容按照一个特定维度排序存储，这个特定的维度就是聚集索引。比如InnoDB存储引擎里的id主键。 非聚集索引：非聚集索引项顺序存储，但索引项对应的内容却是随机存储的；如自定义的普通索引。 存储引擎 MySQL存储引擎是插件式的，可以根据MySQL预定义的接口开发自己的存储引擎。MySQL的存储引擎是表维度的，而不是数据库维度。同一个库不同表可以有不一致的存储引擎。 InnoDB InnoDB主要用于OLTP，行锁设计，支持事务和外键，支持非锁定读。 InnoDB将数据存储在一个逻辑表空间，可以配置指定每张表存放在单独的ibd文件中。支持裸设备来建立表空间。 InnoDB通过多版本并发控制（MVCC）实现非锁定度及支持高并发。支持事务的四种隔离级别（READ UNCOMMITTED，READ COMMITTED，REPEATABLE READ，SERIALIZABLE） InnoDB提供了插入缓冲，二次写，自适应哈希索引，预读等高性能和高可用功能。 InnoDB数据采用聚集的存储方式，每张表的数据按照主键的顺序存放。这种存数据方式有回表的现象。可以通过建立适当的聚合索引包含需要查询的字段规避。 MyISAM 不支持事务和外键，表锁。支持全文索引。对于OLAP应用速度很快。 MyISAM存储引擎表有MYD和MYI组成。MYD存放数据，MYI存放索引。 NDB NDB存储引擎是一个集群存储引擎。数据存在内存。页面锁，但也支持表锁。 NDB存储引擎的连接查表操作是在数据库实例层面完成的，而不是引擎层面。因此复查的连表查询网络开销比较大，可能导致性能降低。 Memory Memory存储引擎数据存放内存，使用哈希索引。只支持表锁，不支持TEXT和BLOG类型。VARCHAR类型按CHAR类型存储，造成空间浪费。 Archive Archive存储引擎只支持SELECT和INSERT操作，使用压缩算法压缩数据行。支持行锁，但并不支持事务安全。主要用于高速的插入和压缩功能。 MySQL连接方式 TCP套接字 命名管道 共享内存 Unix域套接字 MySQL知识点很多，先简单记录上面的知识点。后期把开篇提到的MySQL相关书籍读完，再抽时间更新和完善MySQL知识点内容。","tags":"MySQL","url":"mysqlxi-lie-yi.html","loc":"mysqlxi-lie-yi.html"},{"title":"Docker系列（三）","text":"Docker的网络是可通过插件扩展的，默认已经存在五种 内置默认网络模型 bridge，默认网络模型，会在宿主主机创建一个虚拟网卡，多个容器的网络连接到上面。 host，适用于单个独立运行的容器，把网络隔离取消，和宿主主机共用网络。 overlay，可以让多个Docker Daemon之间网络互连，我觉得这需要分布式部署大型应用的时候很有用吧。 macvlan，可以分配MAC地址给容器，看名字应该是类似交换机vlan机制的网络模型。 none，对容器禁止所有网络模型。目的是为了使用自定义的网络驱动模型。 下面写写每个网络模型的机制及使用。 bridge bridge是docker默认的网络模型。它会在宿主主机上创建一个虚拟网卡bridge0，所有容器连接到这个虚拟网卡，他们共享一个私有网段，并将网关设置为bridge0。 创建一个bridge网络 # 创建 docker network create my-net # 查看 docker network ls 链接一个容器到创建到网络 docker create --name my-nginx \\ --network my-net \\ --publish 8080 :80 \\ nginx:latest 连接一个已经运行的容器到网络 docker network connect my-net my-nginx 断开容器和网络的链接 docker network disconnect my-net my-nginx overlay 后面再写这部分，目前没有环境测试多个Docker Daemon之间的通讯。查看官方文档 overlay host 这种模式容器的网络和宿主机共享，未被隔离，因此没有自己的IP地址。因此，端口映射不生效 -p, --publish, -P, 和 --publish-all 被忽略。 vlan 可以工作在OSI网络模型的第二层和第三层。 # macvlan模式，工作在第二层 docker network create -d macvlan \\ --subnet = 192 .168.50.0/24 \\ --gateway = 192 .168.50.1 \\ -o parent = eth0.50 macvlan50 # ipvlan模式，工作在第三层 docker network create -d ipvlan \\ --subnet = 192 .168.210.0/24 \\ --subnet = 192 .168.212.0/24 \\ --gateway = 192 .168.210.254 \\ --gateway = 192 .168.212.254 \\ -o ipvlan_mode = l2 ipvlan210 Docker其他知识点 先记录下，后期抽空单个知识点深入写一篇文章。 swarm","tags":"Docker","url":"dockerxi-lie-san.html","loc":"dockerxi-lie-san.html"},{"title":"Kubernetes系列一","text":"Kubernetes 是一个跨主机集群的，开源的容器调度平台。它可以自动化应用容器的部署、扩展和操作，提供以容器为中心的基础架构。 使用 Kubernetes，您可以快速高效地响应客户需求。 Kubernetes 特点 便携式，可扩展，自修复 服务发现和负载均衡 方便挂载外部存储 支持自检和调试 应用健康检测 Kubernetes 组成结构 Master Master 节点是整个集群控制的中心。负责集群的调度和 Pod 添加等事件的处理。Master 可以运行在集群中的任何一台机器上，但通常做法只在同一台机器启动 Master，而且这台机器专职运行 Master，而不运行用户容器。 kube-apiserver，是控制中心开放的 API，Kubernetes 里资源操控和集群控制的入口进程。 etcd，是 Kubernetes 的后端存储系统，所有数据都存储在这里。 kube-scheduler 负责基于各种软硬件资源需求调度 Pod。 cloud-controller-manager，用于与底层云提供商交互的控制器。 Node Node 节点维护运行的 Pod 并提供 Kubernetes 运行时环境。 kubelet，Node 节点的代理，负责容器创建、暂停等任务。提供各种机制保证容器运行和健康检测。 kube-proxy，Kubernetes service 的通信与负载均衡机制的重要组件。 Kubernetes业务概念 Pods 最小部署单元，可包含多个容器，是连接在一起的容器组合并共享 Volume。它们是最小的部署单元，由 Kubernetes 统一创建、调度、管理。Pods是可以直接创建的，但推荐的做法是使用 Replication Controller，即使是创建一个 Pod。 Labels Label 以 key/value 形式附加到 Pos、Service、RC、Node 等上面，每个对象可以定义多个 label，以提供 Label Selector 来选择对象。 Replication Controller 管理 Pods 的生命周期。它们确保指定数量的 Pods 会一直运行，还有实现资源伸缩。 Deployment 1.2引入，为了更好地解决 pod 的编排问题，内部使用了 Replica Set 实现；它相对于RC的最大的升级是可以随时知道当前Pod部署的进度。 Horizontal Pod Autocaler(HPA) Pod 横向自动扩容，通过追踪分析 RC 控制的所有目标 Pod 的负载变化情况，确定是否需要针对性地调整目标 Pod 的副本数。 Services 抽象服务出口。它就像一个基础版本的负载均衡器。 Volume Pod 中能够被多个容器访问的共享目录，其生命周期与Pod相同跟容器无关。 Annotation 与 Lable 类似，也使用 key/value 键值对的形式定义，不同于 Lable 定义 Kubernetes 的元数据，它是用户任意定义的附加信息，以便于外部工具进行查找。","tags":"Kubernetes","url":"kubernetesxi-lie-yi.html","loc":"kubernetesxi-lie-yi.html"},{"title":"Docker系列（二）","text":"Docker是时下很流行的容器技术，它用到的技术主要是Cgroup，Namespace，UnionFS。 Cgroup为​​​系​​​统​​​中​​​所​​​运​​​行​​​任​​​务​​​（进​​​程​​​）的​​​用​​​户​​​定​​​义​​​组​​​群​​​分​​​配​​​资​​​源​​，比​​​如​​​ CPU 时​​​间​​​、​​​系​​​统​​​内​​​存​​​、​​​网​​​络​​​带​​​宽​​​或​​​者​​​这​​​些​​​资​​​源​​​的​​​组​​​合​​​​。 Namespace进行进程隔离，使容器拥有自己的rootfs和hostname。同时使IPC、网络和其他进程隔离。 UnionFS打包容器运行时的各种依赖和库，发布成镜像。在容器启动时挂载成/目录，保证了容器运行的环境的统一，方便部署和管理。 Namespace Linux Namespace是Linux提供的一种内核级别环境隔离的方法。Namespace提供如下功能。 把自身pid映射为0，并看不到其他任何的pid，这样自身的pid成为系统内唯一存在pid，看起来就像新启动了系统 用户名隔离，可以把用户名设置为\"root\" hostname隔离，可以另取一个hostname，成为新启动进程的hostname IPC隔离，隔离掉进程之间的互相通信 网络隔离，隔离掉进程和主机之间的网络 可以自定义rootfs，比如我们把整个ubuntu发行版的可执行文件以及其他文件系统都放在目录/home/admin/ubuntu/下，当我们重定义rootfs = /home/admin/ubuntu后，则该文件地址被印射为\"/\" 如何基于Linux Namespace创建一个隔离的进程，可以参考 DOCKER基础技术：LINUX NAMESPACE Cgroup Cgroups 是 Linux 内核提供的一种机制，这种机制可以根据特定的行为，把一系列系统任务及其子任务整合（或分隔）到按资源划分等级的不同组内，从而为系统资源管理提供一个统一的框架。 通俗的来说，cgroups 可以限制、记录、隔离进程组所使用的物理资源（包括：CPU、memory、IO 等），为容器实现虚拟化提供了基本保证，是构建 Docker 等一系列虚拟化管理工具的基石。Cgoup的详细知识，可以查看陈皓的博客 DOCKER基础技术：LINUX CGROUP UnionFS UnionFS是Union File System的简写。它可以把多个目录联和挂载到同一个目录下。而目录的物理位置是分开的。UnionFS允许只读和可读写目录并存，就是说可同时删除和增加内容。 UnionFS应用的地方很多，比如在多个磁盘分区上合并不同文件系统的主目录，或把几张CD光盘合并成一个统一的光盘目录(归档)。另外，具有写时复制(copy-on-write)功能UnionFS 可以把只读和可读写文件系统合并在一起，虚拟上允许只读文件系统的修改可以保存到可写文件系统当中。 例如把一张CD/DVD和一个硬盘目录给联合mount在一起，然后，你就可以对这个只读的 CD/DVD上的文件进行修改（当然，修改的文件存于硬盘上的目录里）。 关于UnionFS的操作示例，可以查看 AUFS 。 Docker最开始采用AUFS作为文件系统，但由于AUFS未并入Linux内核，考虑到兼容性问题，在Docker 0.7版本中引入了存储驱动， 目前，Docker支持AUFS、Btrfs、Device mapper、OverlayFS、ZFS五种存储驱动。可以使用 Docker info 查看。 xufan in ~ λ docker info Client: Debug Mode: false Server: Containers: 40 Running: 39 Paused: 0 Stopped: 1 Images: 16 Server Version: 19 .03.5 Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs 上面是我MacOS系统的输出，使用的overlay2。Backing FIlesystem表明操作系统层面的文件系统使用的是extfs。 关于五种驱动的介绍和对比，可参考 Docker五种存储驱动原理及应用场景和性能测试对比 常见UnionFS AUFS overlay AUFS和Overlay都是联合文件系统，但AUFS有多层，而Overlay只有两层，所以在做写时复制操作时，如果文件比较大且存在比较低的层，则AUSF可能会慢一些。而且Overlay并入了linux kernel mainline，AUFS没有，所以可能会比AUFS快。 overlay和overlay2 overlay共享数据方式是通过硬连接，而overlay2是通过每层的lower文件。 docker的镜像rootfs，和layer的设计 为了让容器运行时一致，docker将依赖的操作系统、各种lib依赖整合打包在一起（即镜像），然后容器启动时，作为它的根目录（根文件系统rootfs），使得容器进程的各种依赖调用都在这个根目录里，这样就做到了环境的一致性。 Docker镜像的设计中，引入了层（layer）的概念，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量rootfs（一个目录）。下层作为上层的依赖，提供只读的环境。上层需要修改下层文件时，先复制一份到本层，修改发布后作为镜像成为其他容器的依赖。","tags":"Docker","url":"dockerxi-lie-er.html","loc":"dockerxi-lie-er.html"},{"title":"Docker系列（一）","text":"Docker使用Google公司推出的Go语言进行开发实现，基于Linux内核的 cgroup，namespace，以及AUFS类的UnionFS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。 Docker和VM 虚拟机本质是模拟出一台计算机，再在模拟的机器上运行其他系统。而容器只是对进程做了隔离和资源控制，直接运行于宿主的内核。下面表格简单对比了Docker和VM。 对比项 Docker VM 是否需要模拟硬件 不需要 需要 是否拥有自己的内核 Docker容器没有自己OS系统内核，运行于宿主系统内核之上 VM上运行的系统独立于宿主OS系统，拥有自己的内核 是否可以运行不同于宿主的OS系统 Docker的镜像准确的说不是OS，只是一个容器运行依赖的集合，即rootfs，依赖于宿主内核运行 VM可以运行不同于宿主的OS系统，比如在MacOS上运行Ubuntu 启动是否需要完整的OS引导流程 不需要，宿主OS已经完成 需要，每个Guest OS都需要经MBR启动 下面的两幅图，很好的展示了传统虚拟机和Docker与宿主机的关系。 Docker特点 轻小。由于不需要模拟硬件，相当于传统虚拟机小很多。 资源耗费小。容器只是利用Linux隔离技术，单机可以运行几千个容器。 部署快速方便。所有容器共享宿主系统内核，部署只需要打包依赖的库和应用本身。当需要迁移部署的时候，也只需要转发很小的文件。 采用分层机构。容器运行于镜像之上，镜像给容器运行提供只读的依赖资源，容器对文件的修改只会体现在本层，不影响下层的镜像。 C/S结构，分为客服端和服务端。即Docker CLI和Docker daemon。它们之间基于REST API沟通。 采用数据卷（data volumes）。数据卷让容器运行的应用程序和数据分离，即静动分离。不依赖于数据的容器方便发布成镜像给其它需要的容器。 模块化和分布式。容器之间可以创建网络通信，因此可以把应用本身，存储，缓存，消息队列分开部署。 术语解释 镜像 提供容器运行时所需的程序、库、资源、配置。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 采用分层构建模式，上层依赖的下层做修改。基于UnionFS技术。 容器 容器可以理解成镜像的实例，它是一个操作系统的进程。多个容器基于Cgroup和Namespace技术隔离。利用虚拟的网络接口（veth pair）进行通信。 数据卷 Docker的哲学是应用和动态数据分离。数据卷让容器可以挂载容器外部的目录或者文件到容器目录。这样应用程序写入数据的时候，实际上就是写入外部对应的目录或文件。这样做的好处是方便分发，而且基于现有容器生成镜像时，其上的层不需要关心数据。 仓库 仓库是镜像的托管站。官方仓库是Docker Hub，可以很方便的复用已经构建好的镜像启动一个容器。比如 docker run ubuntu:18.04 /bin/echo 'Hello world' 就是从官方仓库克隆镜像ubuntu:18.04启动一个容器。 Docker Engine Docker Engine是一个C/S结构的应用，它由Docker CLI、Docker Daemon和一个REST API组成。 Docker Engine结构图 Dockerfile Dockerfile是Docker构建镜像的一个文件，里面包含了构建镜像的一些列Docker指令。Dockerfile保证了镜像构建的透明和可重复，而且避免Docker commit构建时写入容易数据。下面是一个简单Dockerfile例子。 FROM nginx RUN echo '<h1>Hello, Docker!</h1>' > /usr/share/nginx/html/index.html FROM指令指定已经存在的Docker镜像。RUN指令用来执行shell命令，可以用来安装依赖包等。 镜像构建上下文（Context） 上面的Dockerfile写好后，可以执行 docker build -t nginx:v3 . 构建镜像。-t参数给构建的镜像打标签，\".\"就是构建时的上下文。Docker采用C/S模式，构建镜像时Docker指令是运行在Docker Daemon（Docker守护进程）。引入上下文，使得ADD，COPY等需要复制文件的指令有了参考位置。构建镜像时，上下文会通过Docker Remote API打包传给Docker Daemon，通过这种保证了一些列文件的依赖，让Docker Daemon共享本地文件。 COPY ./package.json /app/ 上面的COPY指令，复制的是上下文的package.json到构建镜像的/app目录，而不是Dockerfile文件目录。 简单使用 下面通过一些基本例子，演示Docker容器创建，数据卷创建和使用及容器之间的网络通信。 运行一个容器 首先我们启动一个容器 docker run -d -it --name nginx_test nginx -d：后台运行 -it：启动终端 执行 docker ps 查看运行中进程 可以看到我们的容器已经在运行，容器名ngix_test 执行 docker stop nginx_test 停止刚才的容器。执行 docker rm nginx_test 删除刚才的容器。 访问本地目录 执行下面的命令挂载本地的~/nginx_test到容器的/data目录。容器的/data目录会自动创建，本地机器的必须存在命令才能执行成功。 docker run -d --name nginx_test --mount type = bind,source = /Users/xufan/nginx_data,target = /data nginx 执行命令 docker exec -it nginx_test bash 进入容器，可以看到/data目录以及存在，重新打开一个终端，看看本地的~/nginx_data目录也多了一些文件。 root@01818c8eb399:/# ls bin boot data dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root@01818c8eb399:/# cd data/ root@01818c8eb399:/data# ls root@01818c8eb399:/data# echo \"helo docker\" > test.txt 同样，在本地的~/nginx_data新建文件，容器的/data也会相应的更新。 访问网络 运行容器的时候，可以通过-p参数指定本地端口到容器端口的映射。。 docker run -d -it -p 8080 :80 --name nginx_test2 nginx 上面命令将本地端口8080端口映射到容器80端口，浏览器访问http:127.0.0.1:8080就能看到Nginx的欢迎界面。 容器之间通信 docker network create -d bridge my-net docker run -it --rm --name busybox1 --network my-net busybox sh docker run -it --rm --name busybox2 --network my-net busybox sh 去busybox1 ping busybox2验证网络的互通。 技术原理 对于Docker使用的Namespace，Cgroup，UnionFS技术，放到下篇再写。（ 技术原理 ）","tags":"Docker","url":"dockerxi-lie-yi.html","loc":"dockerxi-lie-yi.html"},{"title":"RabbitMQ系列第三篇","text":"集群特点 RabbitMQ节点不完全拷贝。所以其他非所有者节点只知道队列的元数据，和指向该队列节点的指针。 集群节点类型 内存节点 磁盘节点 如果集群只有一个磁盘节点，当该节点宕机时，集群仍然运行，但是不能创建Queue，Exchange，Binding， 也不能增加用户，更改权限，集群节点删除和增加也不行。因此为了集群的健壮，应两个磁盘节点。 基于Docker测试集群部署 Docker是现在很流行的容器化技术，它部署方便，资源消耗小。Docker的学习可以查看 Docker从入门到实践 首先获取RabbitMQ镜像 docker pull rabbitmq:3-management 利用刚刚获取的镜像启动三个RabbitMQ容器。用 docker ps 查看是否启动成功。 docker run -d --hostname rabbit1 --name rabbitmq-cluster1 -p 15672 :15672 -p 5672 :5672 -e RABBITMQ_ERLANG_COOKIE = 'rabbitcookie' rabbitmq:3-management docker run -d --hostname rabbit2 --name rabbitmq-cluster2 -p 15673 :15672 -p 5673 :5672 -e RABBITMQ_ERLANG_COOKIE = 'rabbitcookie' rabbitmq:3-management docker run -d --hostname rabbit3 --name rabbitmq-cluster3 -p 15674 :15672 -p 5674 :5672 -e RABBITMQ_ERLANG_COOKIE = 'rabbitcookie' rabbitmq:3-management 创建bridge网络模型 xufan in ~ λ docker network create my-net da548bf4ff7d59a9b5bea3ca1b15a54ec4eb6474cf13c7023617ee505632c7db xufan in ~ λ docker network ls NETWORK ID NAME DRIVER SCOPE a537e2bf0f6e allspark_default bridge local be294ecd2c06 bridge bridge local 13a3502ca0b7 host host local da548bf4ff7d my-net bridge local 74271d3b1ef4 none null local 将上面创建的三个容器连接到自定义的网络my-net上。 docker network connect my-net rabbitmq-cluster1 docker network connect my-net rabbitmq-cluster2 docker network connect my-net rabbitmq-cluster3 执行 docker exec -it rabbitmq-cluster1 bash 进入第1个容器，ping其他两台容器看看是否网络正常联通。如果没有ping命令，可安装 iputils-ping 在第2，3个节点执行下面命令加入集群 rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl join_cluster rabbit@rabbit1 rabbitmqctl start_app 有时会执行失败，后面再抽时间分析下具体原因和解决思路。 镜像队列 默认，RabbitMQ集群的队列和消息只存储在一个单一的节点（宣布它的节点）。如果这个节点挂掉，它的Queue和Message都将丢失（Exchange和Binding三个节点都有，因此不会丢失）。因此，RabbitMQ支持镜像队列。每个镜像队列高可用有一个主队列，然后一个或多个从队列。所有的操作先传给主队列，主队列再分发给从队列。如Publisher分发一个消息，只有消息成功分发给所有从队列，才会得到确认。Customer消费消息，不管它连接的是哪个节点，都会转到主节点。镜像队列提升了高可用，但是没有负载均衡的效果（所有节点做相同的工作）","tags":"RabbitMQ","url":"rabbitmqxi-lie-di-san-pian.html","loc":"rabbitmqxi-lie-di-san-pian.html"},{"title":"RabbitMQ系列第二篇","text":"在RabbitMQ使用中，如果一个任务分发给一个Worker，而Worker执行到一半就退出了，这时如何保证消息不丢失呢？下面一起看看RabbitMQ保证消息可靠传输机制。 可靠传输机制 消息持久化 消息确认（Consumer Acknowledgements and Publisher Confirms） 集群和高可用模式 消息补偿机制（确认及重传） 消息持久化 RabbitMQ消息默认存储在内存，如果重启，或者宕机，那样消息就丢失了。消息持久化之后，消息会被写入硬盘，在服务恢复的时候再加载回来。 消息持久化需要同时持久化Exchange，Queue，Message。下面是Golang简单的例子。 func ( ch * Channel ) ExchangeDeclare ( name , kind string , durable , autoDelete , internal , noWait bool , args Table ) error func ( ch * Channel ) QueueDeclare ( name string , durable , autoDelete , exclusive , noWait bool , args Table ) ( Queue , error ) func ( ch * Channel ) Publish ( exchange , key string , mandatory , immediate bool , msg Publishing ) error type Publishing struct { // Application or exchange specific fields, // the headers exchange will inspect this field. Headers Table // Properties ContentType string // MIME content type ContentEncoding string // MIME content encoding DeliveryMode uint8 // Transient (0 or 1) or Persistent (2) Priority uint8 // 0 to 9 CorrelationId string // correlation identifier ReplyTo string // address to to reply to (ex: RPC) Expiration string // message expiration spec MessageId string // message identifier Timestamp time . Time // message timestamp Type string // message type name UserId string // creating user id - ex: \"guest\" AppId string // creating application id // The application specific payload of the message Body [] byte } ExchangeDeclare 和 QueueDeclare 的 durable 设为 true ，将创建的Exchange和Queue持久化。发送消息时，将 Publishing 的 DeliveryMode 模式设置为2，将对应的消息持久化。下面是Golang发送消息持久化的简单示例。 err = ch . Publish ( \"\" , // exchange q . Name , // routing key false , // mandatory false , amqp . Publishing { DeliveryMode : amqp . Persistent , ContentType : \"text/plain\" , Body : [] byte ( body ), }) if err != nil { log . Fatalf ( \"%s: %s\" , msg , err ) } 消息确认 消息持久化到硬盘需要一个过程，如果在小段时间中发生异常，消息扔将丢失。如果设置消息分发即删除，像开篇提到的场景，Worker异常退出的情况，消息也会丢失。 RabbitMQ通过 Consumer Acknowledgements and Publisher Confirms 确保消息被成功分发和处理。 默认情况下，RabbitMQ将自动确认，这样无法保证消息被Work处理成功。需要将自动确认设置为 false ，处理完相应消息时手动确认。下面是Go手动确认相关API。 func ( ch * Channel ) Consume ( queue , consumer string , autoAck , exclusive , noLocal , noWait bool , args Table ) ( <- chan Delivery , error ) // Delivery是Consumer收到消息的结构体定义 func ( d Delivery ) Ack ( multiple bool ) error func ( d Delivery ) Nack ( multiple , requeue bool ) error func ( d Delivery ) Reject ( requeue bool ) error 将 Consumer 的 autoAck 设置成 false 关闭自动确认。 Ack 手动给一个肯定的确认， multiple 设置为 true 表示批量确认。 Nack和Reject 手动给一个否定的确认， requeue 设置为 true 消息将被分发给其他Consumer。下面是一个Go手动确认的示例。 msgs , err := ch . Consume ( q . Name , // queue \"\" , // consumer false , // auto-ack false , // exclusive false , // no-local false , // no-wait nil , // args ) failOnError ( err , \"Failed to register a consumer\" ) forever := make ( chan bool ) go func () { for d := range msgs { log . Printf ( \"Received a message: %s\" , d . Body ) dot_count := bytes . Count ( d . Body , [] byte ( \".\" )) t := time . Duration ( dot_count ) time . Sleep ( t * time . Second ) log . Printf ( \"Done\" ) d . Ack ( false ) } }() log . Printf ( \" [*] Waiting for messages. To exit press CTRL+C\" ) <- forever Publisher Confirms 和 Consumer Acknowledgements 机制差不多，当消息被成功发送到Queue，如果需要持久化，成功持久化到硬盘， 此时Broker将给Publisher确认。 保证Publisher发送消息成功的方式还有事务（tx transaction）。事务是AMQP支持的标准。不过事务过重，影响了MQ吞吐量。 集群和高可用模式 后面的篇章将会基于Docker验证RabbitMQ的集群和高可用，也会讲解基本配置和常用的运维命令或工具，这里就先略过。 消息补偿机制 生产环境和实际网络实际情况是复杂的，不可能保证100%消息不丢失。因此Publisher需要确保在消息丢失下的重传机制。","tags":"RabbitMQ","url":"rabbitmqxi-lie-di-er-pian.html","loc":"rabbitmqxi-lie-di-er-pian.html"},{"title":"RabbitMQ系列第一篇","text":"RabbitMQ特性 支持多种消息协议（Multi-protocols） 支持AMQP，STOMP，MQTT，HTTP和WebSockets 灵活的路由，多种交换类型（Flexible routing, multi-Exchange） 后面的 工作模式 小节会详细阐述RabbitMQ几种常见的模式 消息队列发送确认 多语言，跨语言编程（Go，Python，Java） RabbitMQ支持多种协议，只要实现特定协议的生产者和消费者，都能和RabbitMQ通信，对语言没有限制 集群及分布式部署 RabbitMQ支持集群和高可用，而且通过插件支持Federation特性。所谓Federation特性，是指有不同的用户和 vhosts的broker，而且各broker所属RabbitMQ版本可以不一致。名词含义见 RabbitMQ基本概念 丰富的工具和插件 提供基于HTTP的管理和监控界面API RabbitMQ基本概念 Message 消息，消息是不具名的，它由消息头和消息体组成。 消息体是不透明的，而消息头则由一系列的可选属性组成， 这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。 Publisher 消息的生产者，也是一个向交换器发布消息的客户端应用程序。 Exchange 交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。Exchange有四种类型：direct，fanout，topic，headers。 后面的 工作模式 小节会针对四种类型单独分析。 Binding 绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。 Queue 消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。 Connection 网络连接，比如一个TCP连接。 Channel 信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP命令都是通过信道发出去的， 不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。 Consumer 消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。 Virtual Host 虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。 每个vhost本质上就是一个mini版的RabbitMQ服务器，拥有自己的队列、交换器、绑定和权限机制。vhost是AMQP概念的基础，必须在连接时指定，RabbitMQ默认的vhost是/。 Broker 表示消息队列服务器实体。 RabbitMQ工作模式 1, simple模式 创建队列时，需要指定一个Queue name（队列名），Publisher通过Queue name和Queue绑定。 2, work模式 比模式1多了几个Consumer。需要指定队列名。其实模式1，2是一种特例，它们Exchange为\"\"（默认的匿名Exchange） 3, publish/subscribe发布订阅(共享资源) 上面的 X 指Exchange。Exchange type是fanout，Routing key是\"\"。 通常不需要指定Queue name（匿名队列），由Exchange 根据Routing key确认分发到哪个Queue。 由于Routing key为空，所以这种模式消息会被分发到所有的Queue。通常由Consumer创建相应的Queue，并绑定到相应的Exchange。 4, routing模式 Exchange type为direct，Routing key不为空。和第3种模式相比，Routing key会指定一个字符串。 Exchange根据Routing key精确匹配，和对应Routing key绑定的Queue会收到相应消息。 如果一个消息的Routing key和任何Binding都不匹配，就会被丢弃，避免了Queue的拥塞。这也是提倡Consumer创建Binding的原因， 因为Consumer最清楚自己需要哪一种类的消息。 5, topic模式 Exchange type为topic，Routing key支持模式匹配, 匹配规则为\"*\"匹配单个单词，\"#\"匹配多个单词。 Routing key以点分割单词，如\"stock.usd.nyse\"。 结合上图，Routing key被设置为\"quick.orange.rabbit\"的消息将被发到两个Queue。\"quick.orange.fox\"消息 将仅仅发送到第一个Queue，而\"lazy.brown.fox\"仅仅发送到第二个Queue。\"lazy.pink.rabbit\"虽然匹配第二个Queue 两次绑定，但是第二个Queue仍然只会收到一次。 6, headers模式 headers模式很像topic模式，只是基于headers代替Routing key来匹配Binding。如上图，x-match字段是必须的，它有 all和any两个值。all标识headers的其它字段都得匹配，any标识headers的其它字段至少匹配一个。header能基于integer或者hash构造， 而不仅仅是string。 7, rpc模式 rpc模式严格说只是其他模式的应用。如上图，C端利用模式2（当然也可以是其他模式）发起一个rpc调用，并通过设置replay_to参数， 告诉S端Response时的Queue name，然后S端就能通过模式2返回Response了。 基于RabbitMQ实现rpc调用需要解决如下问题： S端执行过慢，或者负载过大时，支不支持扩展。利用模式2显然是能支持多S端工作的。 确保Request和Response仅仅一个消息。如图使用唯一Queue传递消息，能保证，但是代码层面扔需要做相应检查。 C端需要处理没有S运行情形。可以使用Publisher Confirm保证消息是否被正常分发。 C端需要处理调用超时无应答问题。 如果S端执行挤过异常，如何和C端确认传输的消息。 消息非法的检测。 综上，第1，2种模式可归为一类，它们使用未命名Exchange（默认\"\"），Publisher直接将消息发送到Queue。他们分发消息的路由方式，是Publisher通过Queue name（队列名） 直接绑定Queue。这两种方式有很明显的缺点。首先它们Queue只有一个，不好扩展。其次消息分发不够灵活，如不能根据消息的主题决定分发方式。 第3，4，5模式可以归为一类，他们通过Exchange分发消息，不同的是Exchange type不同。这很好的解决了1，2种模式的缺点。 rpc模式严格上只是RabbitMQ其他模式的应用，下面的表对比了前5种模式。 模式名 Exchange Routing key 特点 simple模式 \"\" 使用Queue name 单一Queue，单一P，C worker模式 \"\" 使用Queue name 多个worker publish/subscribe模式 type值为fanout \"\" 需要绑定Exchange和Queue，即创建Binding。多个Queue都会收到消息 routing模式 type值为direct 需要指定 精确匹配, 需要绑定Exchange和Queue，即创建Binding topic模式 type值为topic 需要指定 模式匹配, 需要绑定Exchange和Queue，即创建Binding RabbitMQ和Kafka对比 Kafka支持消息回溯，RabbitMQ不支持。 RabbitMQ支持消费者推，而Kafka不支持。 Kafka消息被有序的追加到每个主题消息分区。 Kafka消费者通过维护分区的偏移（或者说索引）来顺序的读出消息，然后消费消息。 rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作。 kafka具有高的吞吐量，内部采用消息的批量处理，zero-copy机制，数据的存储和获取是本地磁盘顺序批量操作，具有O(1)的复杂度，消息处理的效率很高。","tags":"RabbitMQ","url":"rabbitmqxi-lie-di-yi-pian.html","loc":"rabbitmqxi-lie-di-yi-pian.html"},{"title":"《MySQL技术内幕:InnoDB存储引擎》读书笔记","text":"第一章：MySQL体系结构和存储引擎 1，MySQL组成 连接池组件 管理服务和工具组件 SQL接口组件 查询分析组件 优化器组件 缓冲组件 插件式存储引擎 存储文件 2，MySQL存储引擎 InnoDB MyISAM NDB Memory Archive Federated Maria 第二章：InnoDB存储引擎 1，InnoDB体系结构 1），后台线程 默认情况下，InnoDB有七个后台线程。1个master thread，4个IO thread，1个锁线程，1个监控线程。 4个IO thread分别是insert buffer thread，log thread，read thread，write thread。 2），内存 InnoDB存储引擎内存由以下几部分组成 缓冲池（buffer pool） 重做日志缓冲池（redo log pool） 额外内存吃（additional memory pool） buffer pool： buffer pool占内存最大块，用来存放各种数据的缓存（按每页16K操作）。 buffer pool数据页类型有如下几种，其中data page和index page占很大一部分。 data page（数据页） index page（索引页） insert buffer（插入缓冲） adaptive hash index（自适应哈希索引） lock info（InnoDB存储的锁信息） data dictionary（数据字典信息） 2，master thread InnoDB主要工作由master thread完成，master thread有以下几个loop（循环）组成。master thread会根据数据库运行 情况在几个循环之间切换。 main loop（主循环） background loop（后台循环） flush loop（刷新循环） suspend loop（暂停循环） master thread潜在问题： InnoDB对IO有限制，在硬盘性能飞速发展的今天，不能很好的利用硬盘性能。最新的版本中增加了几个对master thread的可配置参数。 3，关键特性 插入缓冲（针对非聚集索引插入的优化） 两次写 自适应哈希索引 第三章：文件 1，表结构定义文件 MySQL自身的文件，以frm后缀结尾，每个表都拥有单独的表结构定义文件。 2，InnoDB存储引擎文件 1），表空间文件 可以所有表放到一个表空间文件里，也可以通过参数配置一个表一个表空间文件。默认的表空间文件是多个表共用的ibdata1文件。 2），重做日志文件 ib_logfile0 ib_logfile1 第四章：表 InnoDB的表是索引组织的，聚簇索引的叶子节点存储的即为行记录（数据）。 1，InnoDB逻辑存储结构 从InnoDB逻辑上看，所有数据都被存储在一个空间中（表空间）。表空间由以下几部分组成，其中上面的层包含下面层。 段（segment） 区（extent），默认大小为1M，即64页。 页（page），默认每页大小为16k。 行（row） 2，InnoDB行记录格式 Compact（默认） Redundant（为兼容之前版本保留） 1），Compact格式 | 变长字段长度列表 | NULL标志位 | 记录头信息 | 列1数据 | 列2数据 | ...... | 2)，Redundant格式 | 字段长度偏移列表 | 记录台信息 | 列1数据 | 列2数据 | ...... | 3，InnoDB数据页结构 File Header（文件头） Page Header（页头） Infimun和Supremum Records User Records Free Space Page Directory File Trailer 4，分区表 分区功能不是在存储引擎功能完成的。MySQL支持水平分区（按行分区），而不支持垂直分区（按列分区）。 MySQL支持的分区为局部分区（一个分区即存放了数据，又存放了索引），而不支持全局分区（数据存放在各个分区中，但索引全部存放在一个对象中）。 MySQL数据库支持以下几种类型的分区： Range分区：根据分区列连续区间分区。 List分区：相对于Range分区，List分区是离散的。 Hash分区：根据用户自定义表达式的返回值来分区。 Key分区：根据MySQL数据库提供的哈希函数来分区。 第五章：索引和算法 1，InnoDB支持的索引类型 B+树索引 Hash索引 全文索引 关于B树和B+树的详细讲解，可以查看 B+树 2，B+树索引类型 1），聚集索引 叶子节点存储了整行的记录数据。通常一个表的聚簇索引就是主键索引。一个表只能有一个聚簇索引。 2），辅助索引（普通索引） 叶子节点存储键和行记录的主键，因此查询数据可能产生回表，可以通过索引覆盖解决。 关于聚簇索引和索引覆盖，查看我的另一篇博客 聚簇索引 3）索引管理 创建索引：create index 删除索引： drop index 查看索引信息： show index from table 4）一些索引信息 联合索引 索引覆盖 优化器（未索引覆盖的情况下，优化器可能选择走聚簇索引） 第六章：锁 锁是数据库区别于文件系统的一个关键特性。锁用于管理共享资源的并发访问。不同的数据库和存储引擎有不同的锁实现机制。 1，锁的类型 共享锁 排它锁 2，锁的机制 3，锁的算法 Record Lock：单个行记录上锁 Gap Lock：间隙锁，锁定一个范围，但不包括行记录本身 Next-Key Lock：上两种锁的结合 4，锁问题 脏读：可以读取到脏数据（一个事物可以读取到另一个事务未提交的数据） 丢失更新：一个事务在另一个事务在读取的过程中做了修改，导致两次读取的数据集不一致 不可重复度：一个事务的更新操作会被另一个事务的更新操作所覆盖（数据库锁并不会有这个问题，但是用户层面可能产生这个问题） 5，死锁 死锁是两个以上的事务在执行过程中，因争夺资源而造成互相等待的现象。 解决方法： 超时回滚重做 wait-for Graph（等待图） 第七章：事务 1，事务特性 原子性（atomicity) 一致性（consistency） 隔离性（isolation） 持久性（durability） 2，事务隔离级别 READ UNCOMMITTED READ COMMITTED REPEATABLE READ SERIALIZABLE 3，分布式锁 分布式事务指的是允许多个独立的事务资源参与到一个全局的事务中。全局事务要求在其中的所有参与的事务，要么都提交，要么都回滚。分布式事务允许不同数据库之间的分布式事务，常见于银行系统的转账业务。 第八章：备份与恢复 热备 冷备 温呗 1，冷备 对于InnoDB，需要备份表结构frm文件，共享表空间文件，独立表空间文件.ibd，重做日志。 2，热备 ibbackup XtraBackup 3，快照备份 MySQL本身不支持快照备份，但是可以基于操作系统实现。比如Linux的LVM对数据文件进行管理。 4，逻辑备份 mysqldump SELECT INTO...OUTFILE 5，主从复制 主从复制是MySQL的一种高可用解决方案，主要有如下三个步骤。 master节点将数据更改记录到bin-log日志中。 slave节点把主服务的bin-log日志复制到自己relay-log日志里。 slave节点从做relay-log日志，把数据更改更新到自己的数据库上，以到达数据和master节点最终一致。","tags":"读书笔记","url":"mysqlji-zhu-nei-mu-innodbcun-chu-yin-qing-du-shu-bi-ji.html","loc":"mysqlji-zhu-nei-mu-innodbcun-chu-yin-qing-du-shu-bi-ji.html"},{"title":"MySQL高可用方案","text":"常见MySQL集群方案 一，MHA高可用架构 简介 MHA（Master High Availability）目前在MySQL高可用方面是一个相对成熟的解决方案，它由日本DeNA公司的youshimaton（现就职于Facebook公司）开发，是一套优秀的作为MySQL高可用性环境下故障切换和主从提升的高可用软件。 优点 方案成熟，基于MySQL现有的主从复制技术，配置不需要更改太多。 能做到在0~30秒之内自动完成数据库的故障切换操作，并最大程度上保证数据的一致性。 适用于大部分MySQL存储引擎。 缺点 依靠MySQL原生主从复制技术，而MySQL主从复制是异步同步的，理论上仍然会有数据丢失。 发生故障后排查问题，定位问题更加困难。 已经停止维护，存在对MySQL更高版本的兼容问题。 二，Orchestrator高可用架构 特点 强大的可视化管理界面。 自身可以多节点部署，防止单节点问题。 支持跨数据中心管理。 三，官方版MGR架构 MySQL5.7新增功能 四，其他高可用架构 MySQL NDB Cluster(官方) MariaDB Galera Cluster Percona XtraDB Cluster(PXC)","tags":"MySQL","url":"mysqlgao-ke-yong-fang-an.html","loc":"mysqlgao-ke-yong-fang-an.html"},{"title":"消息队列基础","text":"什么是消息队列 采取百度百科的定义： \"消息队列\"是在消息的传输过程中保存消息的容器。 常见的消息队列有Kafka、ActiveMQ、RabbitMQ、RocketMQ。 关于消息队列，可以查看敖丙的 消息队列基础 常见消息队列的对比，借用敖丙的图。 MQ的作用 异步 解耦 削峰 MQ问题 增加了系统复杂性，需要考虑重复消费，消息丢失，顺序消费的问题。 一致性问题，这不仅仅是MQ的问题，分布式系统都需要考虑这个问题。 可用性。 Kafka基础 网上找了一张Kafka的体系结构体图 Broker: 一个单独的Kafka服务就是一个Broker。 Zookeeper：为集群提供一致性服务。 下图是更详细的Kafka结构。 Topic： 逻辑概念，对应消息队列中queue的概念，Kafka一个topic可以分布在多个broker里。 Partition：物理概念，每个topic可以分成多个partition，每个partition就是一个append log文件。利用partition分布在不同broker的机制，kafka保证消息的高可用。 Offset：每条消息在partition中的位置。Consumer基于offset实现顺序消费。 Consumer Group（CG）：消费者组。每个Topic的Message可以被分发到不同的CG里面，但是每个CG里只有一个Consumer可以消费相应的Message。 Kafka特点： 拥有消息发布和订阅的功能; 能存储消息流，并具备容错性； 能够实时的处理数据流，使用Streams API，可以对输入的数据处理。 Kafka常见问题： 问：Kafka如何实现一条消息分发给多个消费者？ 答：可以看到，Kafka基于消费者组实现一对多分发消息。要分发给不同的消费者，需要分到到不同的消费者组。 问：Kafka如何保证消息顺序？ 答：Kafka将消息写入Partition，而单个Partition是有序的。如果需要保证全局有序，那只能有一个Partition。如果消费也得有顺序，那只能有一个消费者。 问：为什么会出现重复消费消息？ 答：网络抖动，可能导致判断某条消息消费失败，导致重复消费。 问：Kafka如何提供一致性 答：基于Zookeeper服务 问：Kafka如何做到生产者发送越早的消息越早被添加到Topic中（如果有网络延迟呢）？ 答：这里可以保证的是同一个生产者产生的消息，先发送的消息偏移量比后发送的小。当然，前提是发送的消息是同一主题，同一分区。 问：Kafka是如何备份，确保N-1失效还能不丢失数据？ 创建主题的时候，可以通过 --replication-factor 参数指定partition备份数，备份的partition和leader partition位于不同的broker。写消息的时候，只有所有备份成功才返回成功。只要不是所有的broker失效，数据就不会丢失。 问：Kafka如何保证高效的记录消息日志？ 答：Kafka只允许消息append log的方式追加日志，利用操作系统缓冲区，批量追加，避免了随机写磁盘，提高了IO效率。而且Kafka消息还支持压缩。 问：Kafka费时如何确保数据传输快熟。 传统的文件传输都是先将内容从内核空间拷贝到用户空间，再从用户空间拷贝的socket的内核空间。而sendfile函数支持从内核到内核拷贝，提升了IO效率。而且压缩方式传输也减少了网络开销。 问：Kafka如何删除消息，删除消息带来的影响？","tags":"MQ","url":"xiao-xi-dui-lie-ji-chu.html","loc":"xiao-xi-dui-lie-ji-chu.html"},{"title":"RPC知识和常见框架对比","text":"前述 本篇先讲解RPC的基本概念和简单原理，然后对比常见的RPC框架。本篇知识点都是简单罗列，有些直接摘抄至官网，后期会针对比如HTTP2，gRPC等知识点深入写相应的章节。 什么是RPC RPC，即远程过程调用。它的目的是让调用远程服务向调用本地服务一样，屏蔽传输方式，序列化方式和通信细节。 关于RPC，参考 RPC架构简单详解 和 RPC框架选择 一个典型的RPC框架，需要解决如下通电。 1）call id映射。调用方如何把需要调用的方法名告诉远程服务。 2）序列号和反序列化。调用的方法参数，如何传输到远程服务。 3）如何传输。如何将call id和序列化的参数传送到远程服务。 不同的RPC框架对上面三点的解决方法不同，不过对于第一点，无外乎都是维护一个方法名的映射，因此区别主要第二点和第三点。下面讲常用RPC框架会具体谈到。 常见RPC框架 常见的RPC框架包括bRPC，Dubbo，Thrift，gRPC，JSON-RPC，下面主要介绍Thrift、gRPC、Dubbo。 Thirft Thirft原理和使用 Apache Thrift Thirft传输层支持多种协议，支持文本和二进制传输。服务端支持多种模型（单线程，多线程，阻塞和非阻塞）。 gRPC 对于gRPC，它使用的传输协议是HTTP2，序列化和反序列化协议是protobuf。gRPC有一下特点。 支持流式链接（不是TCP流，指数据流，比如一次请求发送多个包）。服务端端和客户端都支持面向流的数据。这是HTTP2特性决定的。 支持同步和异步。 支持截止时间超时机制。 支持流控。 支持AUTH2和SSL等多种安全认证机制。 这里简单列举gRPC知识，后期单独写相应的章节。 参考 深入了解gRPC Protobuf 语法指南 gRPC中文官方文档 Dubbo Dubbo是阿里开源的RPC框架。 Dubbo官方文档 HTTP2 HTTP2是二进制协议，支持流控，支持数据流等特性。 http2 http2详解 gRPC VS Thirft gRPC vs Thrift 后述 本篇简单罗列了RPC概念和常见的RPC框架，后期会针对某些知识点深入写相应文章。","tags":"RPC","url":"rpczhi-shi-he-chang-jian-kuang-jia-dui-bi.html","loc":"rpczhi-shi-he-chang-jian-kuang-jia-dui-bi.html"},{"title":"MySQL资料和问题汇总","text":"常见MySQL自省命令 1）查看索引信息 show index from table ; 2）查看当前用户占用的连接数 show processlist ; show full processlist ; 3）查看哪些事务正在执行 # 运行中的事务 SELECT * FROM INFORMATION_SCHEMA . INNODB_TRX ; # 锁定的事务 SELECT * FROM INFORMATION_SCHEMA . INNODB_LOCKS ; # 正等待的事务 SELECT * FROM INFORMATION_SCHEMA . INNODB_LOCK_WAITS ; 4）查看当前连接数 SHOW STATUS LIKE 'Thread_%' ; MySQL问题汇总 1）MySQL8用户创建和授权 之所以特意提及这点，是因为MySQL8对于不存在的用户是不允许的，必须先创建。而MySQL5.6之前的版本 grant 授权会自动创建用户。 2）\"caching_sha2_password\"认证插件不允许远程登录 MySQL8默认的认证插件是\"caching_sha2_password\"，需要改成\"mysql_native_password\"才能远程连接登录。修改方法如下。 ALTER USER 'root' @ '%' IDENTIFIED WITH mysql_native_password BY '123456' ; 或者修改配置文件 [ mysqld ] default_authentication_plugin = mysql_native_password 参考资料 MySQL监控命令","tags":"MySQL","url":"mysqlzi-liao-he-wen-ti-hui-zong.html","loc":"mysqlzi-liao-he-wen-ti-hui-zong.html"},{"title":"HTTP2基础知识","text":"前述 最近在研究gRPC相关知识时，知道gRPC是基于HTTP2传输的。于是就有了这篇HTTP2的文章。文章只对HTTP2的基本原理和工作机制做介绍，详细的知识请参考文中的参考资料。 HTTP1.1的缺点 1，TCP连接数限制。对于同一个域名，浏览器最多只能同时创建 6~8 个 TCP 连接 (不同浏览器不一样)。 2，线头阻塞问题。每个 TCP 连接同时只能处理一个请求 - 响应，浏览器按 FIFO 原则处理请求，如果上一个响应没返回，后续请求 - 响应都会受阻。 3，Header头部多，冗余大，而且为压缩。 HTTP2的特点 1，二进制帧传输。二进制传输相对于HTTP1文本传输更高效，且更安全。 2，多路复用。基于流的概念复用，一个TCP链接上可以交叉的发送多个流。 3，服务端推送。 4，采用HPACK对Header压缩。 5，应用层连接重置。可以发送 RST_STREAM 类型的帧终止流，而不用关闭TCP连接。 6，请求优先级设置。 7，流量控制。 基本实现 帧类型 HEADERS，报头帧，用于打开流或携带首部字段。 DATA，数据帧，用于返回相应body。 PRIORITY，优先级帧，用于调整流优先级。 RST_STREAM，重置帧，用来取消一个流。 SETTINGS，设置帧，设置连接参数。 PUSH_PROMISE，推送帧，用于服务器主动推送。 PING，Ping帧，判断连接是否有效。 GOAWAY，关闭连接。 WINDOW_UPDATE，窗口更新帧，用于流量控制。 CONTINUATION，延续帧，用于继续传送首部块片段序列。 流 流只是一个逻辑上的概念，代表 HTTP/2 连接中在客户端和服务器之间交换的独立双向帧序列，每个帧的 Stream Identifier 字段指明了它属于哪个流。 客户端流标识是一个奇数，服务端流标识是一个偶数。 后述 本篇内容会不断完善更新。","tags":"HTTP","url":"http2ji-chu-zhi-shi.html","loc":"http2ji-chu-zhi-shi.html"},{"title":"Django项目部署实践一","text":"从本篇开始，我会花三篇左右的文章去写写Django项目部署的演变及过程中的一些思考。在这个过程中，遇到了很多问题，我也会把相关问题和解决方法记录下来，以求更加完善Django架构解决方案。当然，架构没有最好，只有更适合。某些实现记录，我们也没这样做，这里写下只是为了做一下探索。探索中，难免遇到很多新理论和技术方案，我后面也会抽时间写相应的文章记录下来。 最基本的Django部署方案 Django作为Python最流行的Web框架，有很成熟的解决方案。作为MVT框架，它和数据库有很好的集成，类置ORM。下面是最基本的部署方案。 最基本的部署方案中，Nginx通过WSGI和Django通信，Django直接访问数据库。 缺点 高并发情况下有Django应用和数据库都会成为性能瓶颈； 数据库只有一台，没有备份。如果服务器出问题，容易导致数据丢失； 整个服务单点，出现故障就导致无法提供正常的访问。 MySQL主从和负载均衡调度方案 基于基本部署方案并发性能低，无高可用。所以可以考虑Nginx负责均衡和MySQL主从读写分离。方案如下图。 上面的图MySQL只是一个基本的主从，当然实际情况可能还需要集群来解决数据不一致性问题。不过我们先一步步来，以最基本的两台数据库，一主一从，读写分离，展示下Django负载均衡调度的配置方案。下面的示例中展示忽略缓存，后面再讨论。 Django负载均衡配置 1, 创建两个Django APP示例 为了展示负载均衡调度成功，我们创建两个Django应用，他们的/home路由对应下面的index view。第二个Django APP index view可以返回\"this is the second home\"，以便和第一个区别。 from django.http import HttpResponse def index ( request ): return HttpResponse ( \"this is the first home\" ) 目前只是验证，所以Django APP直接 python manage.py runserver 启动。 假设两个Django APP的地址分别为192.168.10.10：8000和192.168.10.11 2, 配置Nginx负载均衡调度 upstream django-server { #least_conn; server 192.168.10.10 : 8000 weight=2 ; server 192.168.10.11 : 8000 ; } server { listen 80 ; server_name localhost ; location / { proxy_pass http://django-server ; } } Nginx内置支持的负载均衡有round-robin（轮询，默认，可以指定权重），least-connected（最少链接数），ip-hash。为了验证结果，我们这里使用默认的round-robin, 两天服务器的访问权重是2:1。 3, 配置MySQL主从 假设MySQL主服务器ip为192.168.10.20，从服务器ip为192.168.10.21 MySQL主服务器配置文件增加下面配置 [ mysqld ] server - id = 1 log - bin = mysql - bin MySQL从服务器配置文件增加下面配置 [ mysqld ] server - id = 2 relay_log = edu - mysql - relay - bin 其他配置项目不再列出，注意以下几点 - 主从配置项在[mysqld]，而不是[mysql_safe] - server-id必须唯一 - 确保数据目录auto.cnf文件server-uuid也唯一，通常server-uuid会自动生成，但是有时拷贝数据会复制到，所以需要注意下。 在MySQL主服务器上新建主从复制专用用户 CREATE USER 'slave'@'%' IDENTIFIED BY '123456'; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%'; PS： MySQL8必须先创建用户才能授权，MySQL5.7以前版本可以直接grant创建用户并授权。后面会整理一篇MySQL8的文章。 在从服务器执行下面的命令 change master to master_host = '192.168.10.20' , master_user = 'slave' , master_password = '123456' , master_port = 3306 , master_log_file = 'mysql-bin.000001' , master_log_pos = 2830 , master_connect_retry = 30 ; master_host为主服务器ip，master_log_file和master_log_pos为主服务器 show master status 显示的File和Position值。 在从服务器开启主从复制 mysql > start slave ; 4, 配置Django支持读写分离 更新配置文件，指定多个数据库信息 DATABASES = { 'default': { 'NAME': 'write_db', 'ENGINE': 'django.db.backends.mysql', 'USER': 'root', 'PASSWORD': '123456' }, 'users': { 'NAME': 'read_db', 'ENGINE': 'django.db.backends.mysql', 'USER': 'root', 'PASSWORD': '123456' } } 指定读写分离路由 class WriteReadRoute : def db_for_read ( self , model , ** hints ): return read_db def db_for_write ( self , model , ** hints ): return write_db 更新配置文件指定路由 DATABASE_ROUTERS = [ 'writeReadRoute' ] 读写分离的缺陷 1, 不能保证数据强一致性 MySQL主从复制采取异步的方式。主服务器先生存bin-log日志，然后传输给从服务器生存中继日志。中继日志生成后，MySQL从服务器会单独生成一个线程，用来更新数据库。由于是异步，MySQL主从复制存在一个数据不一致的时间差。 2, 写只在主服务器，读只在从服务器，不能充分利用多数据库的并发性能。 3, 不稳定，容易造成数据丢失。 4，可扩展性差。当需要增加主从服务器时，需要手动更新相关数据和配置。 结语 MySQL主从复制，读写分离搭建简单，对于小型应用，这样方案足够。但是当数据库增加时，管理及扩张及其不方便，而且数据也不能保证实时一致性。后面的文章会写写集群的解决方案。","tags":"Redis","url":"djangoxiang-mu-bu-shu-shi-jian-yi.html","loc":"djangoxiang-mu-bu-shu-shi-jian-yi.html"},{"title":"Python进程、线程和协程","text":"前述 本篇会先讲解进程、线程和协成概念，并分别对比进程和线程、线程和协程的区别。然后会讲解进程的通信方式。最后，我们回到Python，讲解Python对协程、线程、进程的支持。以及Python对线程同步和进程同步的支持。 进程和线程 进程是程序运行时的一个实例，对Linux或其他类Unix系统来说，通过 ps 命令查看到的就是一些进程信息。 进程是系统资源分配的最小单位。对于每一个进程，操作系统都会维护一个进程控制块的结构（PCB）。在PCB中，维护着对应进程的标识、状态、调度标识、所拥有的资源、父子关系、进程间通信相关信息以及一些定时器信息。 由于每个进程拥有独立的PCB，因此一个进程是不能直接获取到另一个进程数据信息。如果多个进程需要交互数据信息，只能通过IPC（进程间通信）。常见的IPC方式有管道pipe、消息队列、共享存储、信号量、信号、套接字。 线程是操作系统的调度和运行的最小单位，它属于某一个具体的进程，是进程的实际执行单元。 如果一个进程开启了多个线程，那么这些线程共享所在进程资源信息，如地址空间，文件描述符，全局的变量。同一个进程的线程，可以通过操作共享的数据实现通信，但这样会导致数据的不一致。为了确保数据安全和避免不一致性，线程需要同步。常见的线程同步方式有互斥锁、条件变量、读写锁、信号量。 基于上面进程和线程的特点描述，进程和线程有如下几个对比特点。 进程是资源集合，线程是上下文执行单元。线程比较轻，进程比较重。 同一个进程的线程可以直接通信，但是多个进程之间通信只能通过IPC机制。 对主线程的修改可能影响其他线程，但是对父进程的修改（删除例外）不会影响其他子进程。 一个线程可以操作同一进程的其他线程，但是进程只能有限操作其子进程（这条特性待详细核定）。 参考资料： Linux PCB属性 linux线程剖析 线程和协程 协程，顾名思义，就是一些协同运行的程序或者对象。线程是操作系统的概念，而协程是用户编程层面的概念。线程的调度由操作系统控制，而协程由用户自己实现的事件循环调度。 协程强调的是异步，而线程（或者进程）强调的是并发 。对于Python来说，协程只是一种语法糖，一种异步任务的包装，让程序员写同步代码的方式来写异步任务代码。 线程安全 线程安全指多线程环境下，通过一定的机制确保共享内存数据的安全，避免数据污染。常见的线程安全方式有： 局部变量：局部变量属于线程独有，其它线程不能访问，因此不会受其它线程影响。 针对全局变量，每个线程各复制一份，线程只修改自己的一份。比如Java里的ThreadLocal机制。这种机制变量逻辑上属于某个线程，但实际存储在线程共享内存区。 将全局变量设置为只读。只读变量不能修改，因此多个线程不存在互相影响，数据污染的问题。 线程同步，常见的方式有互斥锁、条件变量、读写锁、信号量。线程同步的基本思想就是把不可预测的线程调度变成有序的执行，从而让数据的改变可以预测。 CAS（check-and-set），也叫乐观锁。准确的说这种方式不能确保数据安全，只是假设数据不会被其它线程修改。线程执行的时候先检查，没被其它线程修改继续执行，被修改了就重头开始。 进程间通信方式 1）管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 2）命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 3）消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 4）共享存储SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量配合使用，来实现进程间的同步和通信。 5）信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 6）套接字Socket：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。 7）信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 参考资料： 进程间通信方式 Python的协程 Python的协程是异步任务的包装，让程序员可以用写同步代码的方式写异步代码，而协程的调度需要事件循环的支持。Python标准库内置了事件循环库 asyncio 。 在Python中，实现协成有两种方式：Python3.5之前的生成器协成，Python3.5及以后的 async 和 await 关键字。 生成器协程 @asyncio . coroutine def old_style_coroutine (): print ( \"hello\" ) yield from asyncio . sleep ( 1 ) print ( \"world\" ) loop = asyncio . get_event_loop () loop . run_until_complete ( old_style_coroutine ()) 基于 async 、 await 的原生协程 import asyncio import time async def say_after ( delay , what ): await asyncio . sleep ( delay ) print ( what ) async def main (): print ( f \"started at {time.strftime(' %X ')}\" ) await say_after ( 1 , 'hello' ) await say_after ( 2 , 'world' ) print ( f \"finished at {time.strftime(' %X ')}\" ) asyncio . run ( main ()) Python3.7及以后的版本中加入了run来运行协成，会自动获取事件。Python3.7之前的版本则需要手动获取事件，然后调用 run_until_complete 等函数执行协程。 asyncio 运行协程时，协程对象被包装成一个 asyncio.Task 对象（waitable对象）， Task 对象管理协程的状态和结果，协程运行结束可以通过 Task 对象的 result 方法获取结果。 协程的更多信息可以参考官方文档和下面的资料 asyncio async/await Python的线程 Python线程有两种实现方式：通过threading模块直接启动，或者继承Thread类实现线程。 通过treading模块直接启动 # 创建两个线程 import threading import time def task ( name , delay ): print ( f \" {name} started at {time.strftime(' %X ')}\" ) time . sleep ( delay ) print ( f \" {name} finished at {time.strftime(' %X ')}\" ) t1 = threading . Thread ( target = task , args = ( \"t1\" , 2 )) t2 = threading . Thread ( target = task , args = ( \"t2\" , 1 )) t1 . start () t2 . start () 下面是运行结果，可以看出同时启动，但是t2在t1前面结束，因为它只阻塞了疫苗。 t1 started at 16 :56:43 t2 started at 16 :56:43 t2 finished at 16 :56:44 t1 finished at 16 :56:45 继承 Thread 类实现线程 import threading import time class MyThread ( threading . Thread ): def __init__ ( self , name ): super () . __init__ () # 重构run函数必须要写 self . name = name def run ( self ): print ( f \" {self.name} started at {time.strftime(' %X ')}\" ) time . sleep ( 1 ) print ( f \" {self.name} finished at {time.strftime(' %X ')}\" ) if __name__ == \"__main__\" : t1 = MyThread ( \"t1\" ) t2 = MyThread ( \"t2\" ) t1 . start () t2 . start () 下面是上面代码的运行结果 t1 started at 17 :03:00 t2 started at 17 :03:00 t1 finished at 17 :03:01 t2 finished at 17 :03:01 我们看到开始结束时间都是一致的，这每个人的显示可能不一致，取决于你的机器和系统。如果单核，阻塞时间很长，那结束时间可能不一致。 关于Python线程及它们的同步, 参考 搞定Python进程和线程 我们知道线程同步可以通过互斥锁，条件变量，信号量。 threading 库对它们支持的对象分别为 Lock 、 Condition 、 Semaphore 。除了这些， threading 库还支持其他同步对象，如 Even , Barrier 。 Python的进程 Python进程由三种实现方式：基于multiprocessing、继承Process类和进程池Pool。 通过multiprocessing直接启动 from multiprocessing import Process import time def f ( name ): time . sleep ( 2 ) print ( 'hello' , name ) if __name__ == '__main__' : p = Process ( target = f , args = ( 'bob' ,)) p . start () p . join () 继承Process类 class SubProcess ( Process ): def __init__ ( self , interval , name = None ): super () . __init__ () self . interval = interval if is not None : self . name = name def run ( self ): print ( \"子进程( %s )开始执行，父进程为( %s ) \" % ( os . getpid (), os . getppid ())) t_start = time . time () time . sleep ( self . interval ) t_stop = time . time () print ( \"子进程( %s )执行结束，耗时 %0 .2f 秒\" % ( os . getpid (), t_stop - t_start )) 进程池Pool rom multiprocessing import Process , Pool import time def Foo ( i ): time . sleep ( 2 ) return i + 100 def Bar ( arg ): print ( '-->exec done:' , arg ) pool = Pool ( 5 ) #允许进程池同时放入5个进程 for i in range ( 10 ): #func子进程执行完后，才会执行callback，否则callback不执行（而且callback是由父进程来执行了） pool . apply_async ( func = Foo , args = ( i ,), callback = Bar ) #pool.apply(func=Foo, args=(i,)) print ( 'end' ) pool . close () pool . join () #主进程等待所有子进程执行完毕。必须在close()或terminate()之后 Python的multiprocessing库提供了如下对象支持进程间通信： Queue 、 Pipe 、 Manager 、共享内存（Value, Array）等，也支持如线程同步的 Lock 等同步对象。 更多Python进程信息，可以参考资料： Python进程和线程 后述 协程是Python3.4以后的一个概念，也是异步编程的一种趋势。网上很多关于协程和线程的对比的文章，什么协程更轻更快啥的，我觉得都只是看表象说理，没有体会协程的哲理。 线程和协程的区别，面试的时候经常问。我总结的协程和线程区别，也许并不全面，如果你有很好的看法，欢迎在 issue 留言。 下面是一些资料： Linux进程控制块 进程的调度策略 Linux线程同步方式 线程安全","tags":"Python","url":"pythonjin-cheng-xian-cheng-he-xie-cheng.html","loc":"pythonjin-cheng-xian-cheng-he-xie-cheng.html"},{"title":"Django Model源码解析（二）","text":"上篇 django Model源码解析一 简单分析了 models.Model 对象是怎么通过它的元类 models.ModelBase 管理的。 今天分析下 Model 对象中定义的相关 Field 代码，也就是相应的表字段是怎么管理的。还是昨天基本示例代码。 from django.db import models class Student ( models . Model ): name = models . CharField ( max_length = 20 ) age = models . SmallIntegerField () 我们查看 CharField 的源码，发现它继承自 Field 对象。继续追踪 Field 代码，发现它继承自混合类 RegisterLookupMixin 。 @total_ordering class Field ( RegisterLookupMixin ): \"\"\"Base class for all field types\"\"\" # Designates whether empty strings fundamentally are allowed at the # database level. empty_strings_allowed = True empty_values = list ( validators . EMPTY_VALUES ) # These track each time a Field instance is created. Used to retain order. # The auto_creation_counter is used for fields that Django implicitly # creates, creation_counter is used for all user-specified fields. creation_counter = 0 auto_creation_counter = - 1 default_validators = [] # Default set of validators default_error_messages = { 'invalid_choice' : _ ( 'Value %(value)r is not a valid choice.' ), 'null' : _ ( 'This field cannot be null.' ), 'blank' : _ ( 'This field cannot be blank.' ), 'unique' : _ ( ' %(model_name)s with this %(field_label)s ' 'already exists.' ), # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'. # Eg: \"Title must be unique for pub_date year\" 'unique_for_date' : _ ( \" %(field_label)s must be unique for \" \" %(date_field_label)s %(lookup_type)s .\" ), } system_check_deprecated_details = None system_check_removed_details = None # Field flags hidden = False many_to_many = None many_to_one = None one_to_many = None one_to_one = None related_model = None descriptor_class = DeferredAttribute # Generic field type description, usually overridden by subclasses def _description ( self ): return _ ( 'Field of type: %(field_type)s ' ) % { 'field_type' : self . __class__ . __name__ } description = property ( _description ) Field 自身定义比较简单，通过装饰器 total_ordering 确保所有比较运算的特殊方法都定义（ __gt__ ， __ge__ ， __lt__ ， __le__ ) Field 的 __init__ 方法就是将传进来的值简单初始化，这里不再展示代码。 下面看看混合类 RegisterLookupMixin 的代码 class RegisterLookupMixin : @classmethod def _get_lookup ( cls , lookup_name ): return cls . get_lookups () . get ( lookup_name , None ) @classmethod @functools . lru_cache ( maxsize = None ) def get_lookups ( cls ): class_lookups = [ parent . __dict__ . get ( 'class_lookups' , {}) for parent in inspect . getmro ( cls )] return cls . merge_dicts ( class_lookups ) def get_lookup ( self , lookup_name ): from django.db.models.lookups import Lookup found = self . _get_lookup ( lookup_name ) if found is None and hasattr ( self , 'output_field' ): return self . output_field . get_lookup ( lookup_name ) if found is not None and not issubclass ( found , Lookup ): return None return found def get_transform ( self , lookup_name ): from django.db.models.lookups import Transform found = self . _get_lookup ( lookup_name ) if found is None and hasattr ( self , 'output_field' ): return self . output_field . get_transform ( lookup_name ) if found is not None and not issubclass ( found , Transform ): return None return found @staticmethod def merge_dicts ( dicts ): \"\"\" Merge dicts in reverse to preference the order of the original list. e.g., merge_dicts([a, b]) will preference the keys in 'a' over those in 'b'. \"\"\" merged = {} for d in reversed ( dicts ): merged . update ( d ) return merged @classmethod def _clear_cached_lookups ( cls ): for subclass in subclasses ( cls ): subclass . get_lookups . cache_clear () @classmethod def register_lookup ( cls , lookup , lookup_name = None ): if lookup_name is None : lookup_name = lookup . lookup_name if 'class_lookups' not in cls . __dict__ : cls . class_lookups = {} cls . class_lookups [ lookup_name ] = lookup cls . _clear_cached_lookups () return lookup @classmethod def _unregister_lookup ( cls , lookup , lookup_name = None ): \"\"\" Remove given lookup from cls lookups. For use in tests only as it's not thread-safe. \"\"\" if lookup_name is None : lookup_name = lookup . lookup_name del cls . class_lookups [ lookup_name ] 可以看出， RegisterLoolupMixin 主要用来管理Lookups，而Lookups负责将对应的域和SQL语句关联起来。Lookups调用 Field.register_lookup 关联 Field ，这样避免了 Field 和 Lookup 的强关联。 通过 Model 定义表的基本例子，我们看到 Model 使用 Field 的方式是组合方式，这样显然比继承更灵活。组合相对于继承并不破坏封装性，而且能在运行的时候动态替换成其他对象。 因此，除非要强调子类和父类的从属关系，而且子类只是简单扩展父类行为时用继承。其他情况都应该尽量使用组合。 上图是Django Model的UML简图。 Field 组合与 Model ，而 Lookup 和 Field 关联。Django Model源码分析就到这里了，抽时间会总结下Django认证和中间件的相关知识。","tags":"Python","url":"django-modelyuan-ma-jie-xi-er.html","loc":"django-modelyuan-ma-jie-xi-er.html"},{"title":"Django Model源码解析（一）","text":"Django是Python最流行的Web框架，功能强大。虽然学习入门门槛较高，但是后期使用起来，避免了很多不必要的造轮子。 其中ORM是Django最主要的特点之一，它将数据库表定义映射为Python对象，避免了SQL语句的字符串编码，使代码变得清晰且易于维护。 Django的ORM代码，是Python元类编程的很好应用，下面一起看看。 from django.db import models class Student ( models . Model ): name = models . CharField ( max_length = 20 ) age = models . SmallIntegerField () 上面代码是定义表的基本例子。我们继承 models.Model 对象， models.Model 对象部分源码如下 class Model ( metaclass = ModelBase ): def __init__ ( self , * args , ** kwargs ): # Alias some things as locals to avoid repeat global lookups cls = self . __class__ opts = self . _meta _setattr = setattr _DEFERRED = DEFERRED pre_init . send ( sender = cls , args = args , kwargs = kwargs ) # Set up the storage for instance state self . _state = ModelState () # There is a rather weird disparity here; if kwargs, it's set, then args # overrides it. It should be one or the other; don't duplicate the work # The reason for the kwargs check is that standard iterator passes in by # args, and instantiation for iteration is 33% faster. if len ( args ) > len ( opts . concrete_fields ): # Daft, but matches old exception sans the err msg. raise IndexError ( \"Number of args exceeds number of fields\" ) if not kwargs : fields_iter = iter ( opts . concrete_fields ) # The ordering of the zip calls matter - zip throws StopIteration # when an iter throws it. So if the first iter throws it, the second # is *not* consumed. We rely on this, so don't change the order # without changing the logic. for val , field in zip ( args , fields_iter ): if val is _DEFERRED : continue _setattr ( self , field . attname , val ) else : # Slower, kwargs-ready version. fields_iter = iter(opts.fields) for val , field in zip ( args , fields_iter ): if val is _DEFERRED : continue _setattr ( self , field . attname , val ) kwargs . pop ( field . name , None ) 可以看到 Model 的定义使用了元类 ModelBase 。 ModelBase 主要处理表映射的Fields字段，具体怎么处理，后面再具体分析。所谓元类，就是普通类的类，也就是普通类是元类的实例。 可以用 类名.__class__ 查看普通类的元类，默认元类是 type 。《流畅的Python》第21章很透彻的分析了元类，下面这幅图是里面的一张插图，很好的表示了元类与普通类的关系。 我们回来，继续看 models.Model 源码。 我们看到 __init__ 初始化方法第二行 opts=self._meta 。这个 _meta 属性，也是通过元类 ModelBase 附加给 Model 类的。它是一个 options.Options 对象，是管理ORM的核心。 __init__ 方法剩余的代码主要是处理域和值的映射关系，也是依赖 _meta 属性管理。完整的代码这里就不粘贴了。 Model 对象除了 __init__ 方法外，还有负责验证的 clean_fields , clean , validate_unique 以及负责保存对象到库的 save_base 方法，也都依赖 _meta 属性。 下面是 save_base 的代码，它通过 _meta 处理proxy，parents，auto_created，db_name然后创建或更新数据库表。 def save_base ( self , raw = False , force_insert = False , force_update = False , using = None , update_fields = None ): \"\"\" Handle the parts of saving which should be done only once per save, yet need to be done in raw saves, too. This includes some sanity checks and signal sending. The 'raw' argument is telling save_base not to save any parent models and not to do any changes to the values before save. This is used by fixture loading. \"\"\" using = using or router . db_for_write ( self . __class__ , instance = self ) assert not ( force_insert and ( force_update or update_fields )) assert update_fields is None or update_fields cls = origin = self . __class__ # Skip proxies, but keep the origin as the proxy model. if cls . _meta . proxy : cls = cls . _meta . concrete_model meta = cls . _meta if not meta . auto_created : pre_save . send ( sender = origin , instance = self , raw = raw , using = using , update_fields = update_fields , ) # A transaction isn't needed if one query is issued. if meta . parents : context_manager = transaction . atomic ( using = using , savepoint = False ) else : context_manager = transaction . mark_for_rollback_on_error ( using = using ) with context_manager : parent_inserted = False if not raw : parent_inserted = self . _save_parents ( cls , using , update_fields ) updated = self . _save_table ( raw , cls , force_insert or parent_inserted , force_update , using , update_fields , ) # Store the database on which the object was saved self . _state . db = using # Once saved, this is no longer a to-be-added instance. self . _state . adding = False # Signal that the save is complete if not meta . auto_created : post_save . send ( sender = origin , instance = self , created = ( not updated ), update_fields = update_fields , raw = raw , using = using , ) 简单看了 models.Model 的源码后，我们接下来简单分析下 ModelBase 代码。 class ModelBase ( type ): \"\"\"Metaclass for all models.\"\"\" def __new__ ( cls , name , bases , attrs , ** kwargs ): super_new = super () . __new__ # Also ensure initialization is only performed for subclasses of Model # (excluding Model class itself). parents = [ b for b in bases if isinstance ( b , ModelBase )] if not parents : return super_new ( cls , name , bases , attrs ) # Create the class. module = attrs . pop ( '__module__' ) new_attrs = { '__module__' : module } classcell = attrs . pop ( '__classcell__' , None ) if classcell is not None : new_attrs [ '__classcell__' ] = classcell attr_meta = attrs . pop ( 'Meta' , None ) # Pass all attrs without a (Django-specific) contribute_to_class() # method to type.__new__() so that they're properly initialized # (i.e. __set_name__()). contributable_attrs = {} for obj_name , obj in list ( attrs . items ()): if _has_contribute_to_class ( obj ): contributable_attrs [ obj_name ] = obj else : new_attrs [ obj_name ] = obj new_class = super_new ( cls , name , bases , new_attrs , ** kwargs ) abstract = getattr ( attr_meta , 'abstract' , False ) meta = attr_meta or getattr ( new_class , 'Meta' , None ) base_meta = getattr ( new_class , '_meta' , None ) app_label = None # Look for an application configuration to attach the model to. app_config = apps . get_containing_app_config ( module ) if getattr ( meta , 'app_label' , None ) is None : if app_config is None : if not abstract : raise RuntimeError ( \"Model class %s . %s doesn't declare an explicit \" \"app_label and isn't in an application in \" \"INSTALLED_APPS.\" % ( module , name ) ) else : app_label = app_config . label new_class . add_to_class ( '_meta' , Options ( meta , app_label )) if not abstract : new_class . add_to_class ( 'DoesNotExist' , subclass_exception ( 'DoesNotExist' , tuple ( x . DoesNotExist for x in parents if hasattr ( x , '_meta' ) and not x . _meta . abstract ) or ( ObjectDoesNotExist ,), module , attached_to = new_class )) new_class . add_to_class ( 'MultipleObjectsReturned' , subclass_exception ( 'MultipleObjectsReturned' , tuple ( x . MultipleObjectsReturned for x in parents if hasattr ( x , '_meta' ) and not x . _meta . abstract ) or ( MultipleObjectsReturned ,), module , attached_to = new_class )) if base_meta and not base_meta . abstract : # Non-abstract child classes inherit some attributes from their # non-abstract parent (unless an ABC comes before it in the # method resolution order). if not hasattr ( meta , 'ordering' ): new_class . _meta . ordering = base_meta . ordering if not hasattr ( meta , 'get_latest_by' ): new_class . _meta . get_latest_by = base_meta . get_latest_by is_proxy = new_class . _meta . proxy 首先 ModelBase 继承 type ，所有的元类都继承 type 。接下来 __new__ 方法，它才是Python真正的构造函数。由于普通类是元类的实例，当定义 Model 对象时， ModelBase 的 __new__ 方法将被调用。 注意是定义时，而不是调用时。就是类体本身属性和方法的初始化，都会有对应元类的 __new__ 方法构建。 __new__ 是一个类方法，接受的三个位置参数分别是要创建的类类名，继承的基类对象元组，以及类所属属性的映射。 下面是 __new__ 部分代码注释。 # Meta属性会再赋值给__meta attr_meta = attrs . pop ( 'Meta' , None ) # 调用父类的__new__创建类对象，也就是Model对象 new_class = super_new ( cls , name , bases , new_attrs , ** kwargs ) # 给Model增加_meta属性, 转化成了Options对象 new_class . add_to_class ( '_meta' , Options ( meta , app_label )) # 处理抽象父Model对应的域 for base in reversed ([ new_class ] + parents ): # Conceptually equivalent to `if base is Model`. if not hasattr ( base , '_meta' ): continue # Skip concrete parent classes. if base != new_class and not base . _meta . abstract : continue # Locate OneToOneField instances. for field in base . _meta . local_fields : if isinstance ( field , OneToOneField ): related = resolve_relation ( new_class , field . remote_field . model ) parent_links [ make_model_tuple ( related )] = field # 给Model对象追加objects作为manager if not opts . managers : if any ( f . name == 'objects' for f in opts . fields ): raise ValueError ( \"Model %s must specify a custom Manager, because it has a \" \"field named 'objects'.\" % cls . __name__ ) manager = Manager () manager . auto_created = True cls . add_to_class ( 'objects' , manager ) 可以看到 ModelBase 主要是给 Model 对象追加 _meta 属性及objects manager，并利用 Options 对象校验Model和父Model域定义。 Options 代码这里不再分析，明天写写 Model 的 Field 对象。","tags":"Python","url":"django-modelyuan-ma-jie-xi-yi.html","loc":"django-modelyuan-ma-jie-xi-yi.html"},{"title":"HTTPS详解","text":"前述 介绍HTTPS相关知识原理和工作流程。","tags":"HTTP","url":"httpsxiang-jie.html","loc":"httpsxiang-jie.html"},{"title":"Docker常见问题汇总","text":"docker容器没有ping命令 解决方法 sudo apt-get update && apt-get install iputils-ping docker容器没有netstat，ifconfig命令 解决方法 sudo apt-get update && apt-get install net-tools docker如何ping两个容器 ... Docker 拷贝容器文件到宿主机 使用 docker cp 命令，详情查看 docker help cp docker cp [ OPTIONS ] CONTAINER:SRC_PATH DEST_PATH | - CMD和ENTRYPOINT的区别 ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给ENTRYPOINT指定指定的程序。 Docker如何访问宿主机端口 假设一个Docker容器运行Nginx，而它想反向代理主机的Django应用，这种情况容器如何访问主机端口呢。第一种方式是把网络模式设置为hosts，这样主机和容器共享网络，但是打破了容器的隔离性。第二种方式：docker 18.03 加入了一个 feature，在容器中可以通过 host.docker.internal 来访问主机。 怎么查看容器IP docker inspect --format = '{{.NetworkSettings.IPAddress}}' 容器名称 | 容器id docker inspect --format = '{{.NetworkSettings.IPAddress}}' 容器名称 | grep IPAddress","tags":"Docker","url":"dockerchang-jian-wen-ti-hui-zong.html","loc":"dockerchang-jian-wen-ti-hui-zong.html"},{"title":"Python异步编程详解","text":"前述 本篇会先讲解异步编程的实现方式，然后讲解操作系统的多路复用机制。最好讲讲Python对异步编程的支持和最新的Python协程方案。 本篇假设你已经理解下面的概念： 阻塞、非阻塞 同步、异步的概念。 并行和并发 进程和线程 异步编程 要实现异步编程，除了多进程和多线程，我们还可以基于操作系统的多路复用机制。 异步编程最大的困难：异步任务何时执行完毕？接下来要对异步调用的返回结果做什么操作？ 上面的问题可以通过 事件循环 + 回调 方式解决。 回调会有一个回调地狱的问题。 除了回调地狱的问题，回调最大的问题是栈撕裂和状态管理困难。 那为了解决回调的问题，协程就产生了。协程底层其实还是事件和回调，只不过做了一定的封装，让用户可以用写同步代码的方式写异步代码。 协程 回调有状态管理的问题，那如果程序（例程）知道自己干了什么，正在干什么，将来干什么呢？换言之，程序得知道当前所处的状态，而且要将这个状态在不同的回调之间延续下去。 上面的问题，就引出协程实现核心思想，它得自己维护自己状态，而且可以通知其他协程。 协程，即协作式的例程。 它是非抢占式的多任务子例程的概括，可以允许有多个入口点在例程中确定的位置来控制程序的暂停与恢复执行。 例程是什么？编程语言定义的可被调用的代码段，为了完成某个特定功能而封装在一起的一系列指令。一般编程语言都用函数或方法来体现。 EPoll 操作系统支持多路复用。所谓多路复用，就是同时监听很多文件描述符，只要其中某个文件描述符状态改变就给予通知。多路复用的好处就是一次等待多个时间就绪，合理利用CPU性能。 常用的多路复用机制有 Select 、 Poll 、 EPoll 。 Select int select ( int n , fd_set * readfds , fd_set * writefds , fd_set * exceptfds , struct timeval * timeout ); select调用会阻塞，某个文件描述符就绪或者超时才返回。select由于每次都需要将文件描述符拷贝到内核空间遍历一遍，所以性能不高。而且支持的文件描述符数量有限制（通常是1024）。 Poll int poll ( struct pollfd * fds , unsigned int nfds , int timeout ); poll和select差不多，只是文件描述符实现不同。虽然poll没有文件描述符数量的限制，但是数量太多仍然有select一样的性能问题。 EPoll int epoll_create ( int size ) ； //创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大 int epoll_ctl ( int epfd , int op , int fd , struct epoll_event * event ) ； int epoll_wait ( int epfd , struct epoll_event * events , int maxevents , int timeout ); epoll有三个函数，它等待的函数是 epoll_wait ，而注册监听描述符的是 epoll_ctl ，因此避免了重复将文件描述符拷贝到内核空间。epoll也没有文件限制。 epoll优点： 1）避免了每次等待调用都将文件描述符拷贝到内核空间，只需要拷贝一次。 2）当文件描述符就绪时，会被加入相应的事件等待队列，wait函数只需扫描对应事件的文件描述符，避免了像select一样每次都扫描所有的文件描述符。 3）没有文件描述符数量限制。 参考资料： Linux多了复用区别 Linux多路复用 后述 参考 深入理解Python异步编程（上）","tags":"Python","url":"pythonyi-bu-bian-cheng-xiang-jie.html","loc":"pythonyi-bu-bian-cheng-xiang-jie.html"},{"title":"后端服务性能调优","text":"一个好的网站，不仅仅是实现了功能，还应该有良好的性能。包括高可用，极端情况断电，自然灾害，部分服务器挂掉的情况不影响正常提供服务。还包括大并发的支持，面对上千万的访问量还能还能正常提供服务。当然，很多网站不会面对这样大的访问量，但是追求大并发，高流量下的性能，应该成为每个开发人员努力的方向。 性能参考 单机性能 CPU：有的应用需要大量计算，他们会长时间、不间断地占用 CPU 资源，导致其他资源无法争夺到 CPU 而响应缓慢，从而带来系统性能问题。例如，代码递归导致的无限循环，正则表达式引起的回溯，以及多线程编程造成的大量上下文切换等，这些都有可能导致 CPU 资源繁忙。 内存：读写速度很快，但是成本过高。内存泄露，过多的全局变量等内存开销，可能耗尽内存，从而影响服务正常运行。 磁盘IO：磁盘存储空间比内存大，但是速度比内存慢。过多的IO操作会降级服务的性能。 网络：网络是互联网的经脉，是否畅通高效直接影响服务性能。 数据库：大部分系统都会用到数据库，而数据库的操作往往是涉及到磁盘 I/O 的读写。大量的数据库读写操作，会导致磁盘 I/O 性能瓶颈，进而导致数据库操作的延迟性。对于有大量数据库读写操作的系统来说，数据库的性能优化是整个系统的核心。 代码实现的强壮型：如果代码在边际条件出现异常，将影响服务的正常服务。 算法及锁。高效的算法，对大运算程序影响很显著。并发编程共享读写同一资源会用到锁，锁的使用可能会带来上下文切换，从而给系统带来性能开销。 集群性能 我们上面提到单机的性能标准，无外乎CPU，内存，IO的平均负载情况。当有上千万的并发访问量时，一台主机无能如何是扛不住的，因此就会用到集群。集群利用负载均衡，有效的减轻了单机负载压力。集群应该考虑好高可用和数据同步的问题。 高可用：当有部分服务器出现问题，不应该影响提供完整功能服务。常见的高可用方案有Nginx，HaProxy。 数据同步：集群方案中，数据库不是存储在一台主机上。这样可以保证数据的安全，当一台数据库主机出现故障时，可以利用另一台恢复。数据库同步可以主从同步，但这个情况会出现从服务器和主服务器数据不一致的时间延迟。可以用写同步解决主从同步的问题，但是写同步要多台数据库写完才返回，造成数据库吞吐率下降。 认证和授权：如何保证集群的服务一个认证入口。一次授权，所有的集群主机都能授权。而且保证独立访问单机时，认证授权不被绕过。 网络安全：集群主机之间通信的安全。这个单机也需要考虑。 性能测试指标 响应时间：响应时间分数据库响应时间，服务端响应时间，网络响应时间，客户端响应时间（JS执行逻辑，渲染等） 吞吐量：在测试中，我们往往会比较注重系统接口的 TPS（每秒事务处理量）。TPS分为磁盘TPS和网络TPS。网络TPS不仅仅跟带宽有关系，还跟 CPU 的处理能力、网卡、防火墙、外部接口以及 I/O 等等紧密关联。 计算机资源分配使用率：通常由 CPU 占用率、内存使用率、磁盘 I/O、网络 I/O 来表示资源使用率。这几个参数好比一个木桶，如果其中任何一块木板出现短板，任何一项分配不合理，对整个系统性能的影响都是毁灭性的。 负载承受能力：当系统压力上升时，你可以观察，系统响应时间的上升曲线是否平缓。这项指标能直观地反馈给你，系统所能承受的负载压力极限。例如，当你对系统进行压测时，系统的响应时间会随着系统并发数的增加而延长，直到系统无法处理这么多请求，抛出大量错误时，就到了极限。 一些检测手段 1，查看系统平均负载 在Linux和类Unix系统中，我们可以通过 w 或 uptime 查看系统平均负载，下面是MacOS执行 uptime 命令的结果，后面三个数表示系统1分钟，5分钟，10分钟的平均负载。 16 :45 up 7 :26, 2 users, load averages: 2 .07 1 .94 2 .06 2，查看CPU和内存情况。 可用用 cat /proc/cpuinfo 查看单机的CPU信息，用 free -m 查看内存使用情况。 top 命令是Linux监控命令，可以看到CPU，内存，虚拟内存，网络吞吐量，磁盘IO，进程调度情况。 3，硬盘及IO监控 通过 df -hl 查看磁盘使用情况， du 命令查看目录占用磁盘情况。 iostat 可以监控IO负载情况。下面是MacOS下 iostat 输出。 disk0 disk2 cpu load average KB/t tps MB/s KB/t tps MB/s us sy id 1m 5m 15m 89 .54 183 15 .98 26 .48 0 0 .00 14 7 79 2 .12 2 .21 2 .17 4，网络响应时间 可以通过工具 speedtest 测试。 curl 命令加 -w 可以查看很详细的响应时间。 ( .venv ) xufan in ~/CatsAction on master ● ● ● λ curl -w \"%{time_namelookup}::%{time_connect}::%{time_starttransfer}::%{time_total}::%{speed_download}\" www.baidu.com ...... ...... 0 .012914::0.020047::0.026661::0.026903::91576.000% 一些思路 不要过早优化，前期应该从软件工程的角度去开发。有性能拼劲的时候才着手优化。 不要想着简单扩容内存提升性能，也有很多IO操作设计到磁盘和网络，具体情况具体分析。 性能分析过早分析底层。应该着眼全局，从应用层，网络，IO，然后才是一些核心参数和算法。","tags":"性能优化","url":"hou-duan-fu-wu-xing-neng-diao-you.html","loc":"hou-duan-fu-wu-xing-neng-diao-you.html"},{"title":"HTTP头部知识","text":"前述 本篇文章对HTTP头部选项做一个归类，并对常见的字段做一下介绍。 分类 通用头部 请求头部 相应头部 实体头部 下面按每个分类介绍一些主要的头部。 通用头部 Date Connection Cache-Control 请求头部 1，标识类 Host User-Agent 2，Accept类 Accept Accept-Encodeing Accept-Language Accept-Charset 3，缓存相关类 If-Match If-Modified-Sine If-Range 4，认证相关类 Authorization 5，其他 Range Referer 相应头部 1，标识相关 Allow Refresh Server 2，缓存相关 Age 其他在实体头部分类 3，认证相关 Proxy-Authenticate WWW-Authenticate 4，代理相关 Location 5，其他 Set-Cookie 实体请求头 请求和实体都可以包含。 1，内容相关类 Content-Type Content-Length Content-Location 2，缓存相关 多用于响应头部。 Expire Etag Last-Modified","tags":"HTTP","url":"httptou-bu-zhi-shi.html","loc":"httptou-bu-zhi-shi.html"},{"title":"常见网络安全之","text":"常见网络安全 跨站脚本攻击（XSS） Cross-Site Scripting（跨站脚本攻击）简称 XSS，是一种代码注入攻击。攻击者通过在目标网站上注入恶意脚本，使之在用户的浏览器上运行。利用这些恶意脚本，攻击者可获取用户的敏感信息如 Cookie、SessionID 等，进而危害数据安全。 < input type = \"text\" value = \"<%= getParameter(\" keyword \") % > \"> < button > 搜索 </ button > < div > 您搜索的关键词是： < %= getParameter(\"keyword\") %> </ div > 如上的代码，如果输入的url是 http://xxx/search?keyword=\"><script>alert('XSS');</script> 将执行js脚本，浏览器将抛出 XSS 对话框。详细介绍和前端一些解决思路，可以查看美团技术团队的文章 前端安全系列（一）：如何防止XSS攻击？ 跨站请求伪造（CSRF） CSRF（Cross-site request forgery）跨站请求伪造：攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求。利用受害者在被攻击网站已经获取的注册凭证，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的。 一个典型的CSRF攻击有着如下的流程： 受害者登录a.com，并保留了登录凭证（Cookie）。 攻击者引诱受害者访问了b.com。 b.com 向 a.com 发送了一个请求：a.com/act=xx。浏览器会默认携带- a.com的Cookie。 a.com接收到请求后，对请求进行验证，并确认是受害者的凭证，误以为是受害者自己发送的请求。 a.com以受害者的名义执行了act=xx。 攻击完成，攻击者在受害者不知情的情况下，冒充受害者，让a.com执行了自己定义的操作 关注CSRF的详细介绍，参考美团技术团队文章 前端安全系列之二：如何防止CSRF攻击？ 对于CSRF的预防，可以禁止跨域访问，或者追加一个Token（由AES/CBC/PKCS5Padding模式加密用户id，时间戳和一个随机字符串生成。短信验证码也能起到这样的功能。） SQL注入 SQL注入是攻击者利用网站漏铜，输入特殊的SQL字符，从而执行数据库达到获取敏感信息或破坏数据库的目的。具体的SQL注入，可参考 SQL注入演练 点击劫持 点击劫持是指在一个Web页面下隐藏了一个透明的iframe（opacity：0），用外层假页面诱导用户点击，实际上是在隐藏的frame上触发了点击事件进行一些用户不知情的操作。详情请看 浅析解析劫持攻击 Django解决方案 XSS Django模板提供了自动对用户输入的转义。 XSRF Django利用附加随机Token解决，Django模板引擎可以通过csrf_token打卡。 HTTPS支持 设置 SECURE_SSL_REDIRECT 等于 True 打卡对HTTPS的支持。。 详情查看 Django 安全","tags":"网络安全","url":"chang-jian-wang-luo-an-quan-zhi.html","loc":"chang-jian-wang-luo-an-quan-zhi.html"},{"title":"Redis随笔","text":"Redis主从复制的高可用解决方案 Redis-Sentinel是Redis官方推荐的高可用性(HA)解决方案，当用Redis做Master-slave的高可用方案时，如果master宕机，Redis自身并不能实现自动进行主备切换。 sentinel可以监控复制节点的状态，当主节点宕机后，它能根据选举方式选出后端的一个从节点作为新的master，sentinel还能监控多个master-slave集群，发现master宕机后能进行自动切换。 同时，sentinel本身也存在单点问题，通常sentinel也是一个集群。 sentinel集群工作原理 sentinel集群通过给定的配置文件发现master，启动时会监控master。通过向master发送info信息获得该服务器下面的所有从服务器。 sentinel集群通过流言协议与其他sentinel通信，以此来发现监视同一个主服务器的其他sentinel；集群之间会互相创建命令连接用于通信。 sentinel集群使用ping命令来检测实例的状态，如果在指定的时间内（down-after-milliseconds）没有回复或则返回错误的回复，sentinel会认为主节点宕机，但是并不会立即提升一个从节点为新的master，因为会存在误判的情况，此时为主观宕机。此时当sentinel集群中有一半以上的节点通告master为宕机状态时，此时为客观宕机，sentinel基于选举协议选举提升从节点为新的master，从节点之间根据优先级来决策谁会成为新的master，修复的节点重新上线后作为从节点工作。 更多Redis-sentinel，可以参考 运维那些破事 和我的 Redis Sentinel模式","tags":"Cached","url":"redissui-bi.html","loc":"redissui-bi.html"},{"title":"Celery原理和使用","text":"前述 本篇讲述Celery的原理和基本使用 基本原理 Celery基于Broker传递执行任务，当tasks调用被调用时，先序列化，然后传递到Broker，worker取出来执行。 下面是celery基本的架构。 Broker通常是RabbitMQ和Redis 序列化 Celery通过Python的pickle模块或json序列化。 通过下面的例子简单看看Celery如何序列化Python对象的。 有两个Python模块，task和app。 ## task.py from celery import Celery app = Celery ( 'demo' , broker = 'redis://:@127.0.0.1:6379/1' , backend = 'redis://:@127.0.0.1:6379/1' ) @app . task def add ( x , y ): return x + y # app.py from task import add if __name__ == '__main__' : print ( 'start task' ) result = add . delay ( 2 , 18 ) 我们在终端执行 python app.py ，连接Redis我们可以看到多了一个celery key，它是Redis的list类型，后加入的放到最前面。查看某一项内容是这样的。 { \\ \"body\\\": \\\"W1syLCAxOF0sIHt9LCB7ImNhbGxiYWNrcyI6IG51bGwsICJlcnJiYWNrcyI6IG51bGwsICJjaGFpbiI6IG51bGwsICJjaG9yZCI6IG51bGx9XQ==\\\", \\\"content-encoding\\\": \\\"utf-8\\\", \\\"content-type\\\": \\\"application/json\\\", \\\"headers\\\": {\\\"lang\\\": \\\"py\\\", \\\"task\\\": \\\"test.add\\\", \\\"id\\\": \\\"fd93e14c-984b-4931-87f6-8547eb8f91e7\\\", \\\"shadow\\\": null, \\\"eta\\\": null, \\\"expires\\\": null, \\\"group\\\": null, \\\"retries\\\": 0, \\\"timelimit\\\": [null, null], \\\"root_id\\\": \\\"fd93e14c-984b-4931-87f6-8547eb8f91e7\\\", \\\"parent_id\\\": null, \\\"argsrepr\\\": \\\"(2, 18)\\\", \\\"kwargsrepr\\\": \\\"{}\\\", \\\"origin\\\": \\\"gen11663@localhost\\\"}, \\\"properties\\\": {\\\"correlation_id\\\": \\\"fd93e14c-984b-4931-87f6-8547eb8f91e7\\\", \\\"reply_to\\\": \\\"b99f0911-fce8-3812-8c71-26f80016b102\\\", \\\"delivery_mode\\\": 2, \\\"delivery_info\\\": {\\\"exchange\\\": \\\"\\\", \\\"routing_key\\\": \\\"celery\\\"}, \\\"priority\\\": 0, \\\"body_encoding\\\": \\\"base64\\\", \\\"delivery_tag\\\": \\\"d48c84e6-68d5-4403-9aaa-c40849c1d515\\\"}}\" 启动一个worker celery work - A task - l info 可以看到结果被执行，查看Redis会看到有一个celery-task-meta-taskid的key，它是一个string，里面存放了task执行的结果和状态。 更多Celery的工作流程，查看 celery消息的编码和序列化 和 Python之Celery使用详解 命令 实现机制","tags":"redis","url":"celeryyuan-li-he-shi-yong.html","loc":"celeryyuan-li-he-shi-yong.html"},{"title":"Redis知识整理","text":"Geo使用 GeoHash详解","tags":"redis","url":"rediszhi-shi-zheng-li.html","loc":"rediszhi-shi-zheng-li.html"},{"title":"缓存问题及处理","text":"前述 本篇收集Redis一些常见问题及解决方法，最后面是一些Redis资料链接。 Memcached和Redis的区别 Memcached单进程多线程，而Redis单进程单线程。处理小数据时，Redis性能比Memcached高，而在100K以上的数据中，Memcached性能要高于Redis。 Memcached只支持key-value数据类型，而Redis支持丰富的数据类型。 Redis并不是将所有数据存储在内存中。当内存容量用完时，Redis会swap一部分数据到磁盘上，而且也支持数据持久化。 从内存利用率来讲，使用简单的key-value存储的话，Memcached的内存利用率更高。而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcached。 Memcached本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现Memcached的分布式存储。相较于Memcached只能采用客户端实现分布式存储，Redis更偏向于在服务器端构建分布式存储。 Redis支持服务端的数据操作，而Memcached需要将数据拿到客户端修改再set回去，增加了io操作。 关于Memcached和redis对比，可以参考： Memcached和Redis区别 缓存的一些问题 1，缓存穿透 定义: 所谓缓存穿透，就是访问根本不存在的数据。当访问一个数据时，缓存不存在，则会直接查询数据库。数据库也不存在，就返回空。 如果有恶意用户访问大量不存在的数据，则会给数据库造成很大压力。 解决方法: BloomFilter。类似于hash表的算法。把所有可能的查询生成一个bitmap。每次请求数据时，都通过BloomFilter查看数据是否存在。 缓存空值，并设置一个较短的过期时间。这样同个不存在的数据查询请求反复出现时，就能命中缓存。 2，缓存雪崩 定义: 缓存雪崩，就是缓存中大量数据同时失效。此时大量的数据请求就好转发到数据库，从而给数据库造成压力。 解决方法: 让失效时间不同。比如一定范围的随机时间，这样就避免了大量缓存同时失效。缺点是粒度不好把握。 可以限制并发量（比如利用锁和同步机制）。这样即使缓存大量失效，也不会有大量请求造成数据库压力。不过这种方法造成了服务性能的下降。 缓存击穿 定义: 缓存击穿是缓存雪崩的特例。当某些热点数据失效时，它的请求会被发往数据库。在数据库请求并更新缓存的这段时间，如果有大量的热量请求，就会给数据库造成很大的压力。 解决方法: 增加二级缓存，不同的缓存设置不同的失效时间。这个解决方案也适用于缓存雪崩。 基于LRU的缓存换出策略。 后述 一些资料： Redis技术集 收集了一些Redis的技术讲解和使用场景按理。 阿里云缓存架构 神奇的HyperLogLog算法 Redis HyperLogLog结构 Redis Bitmap结构 Redis Geo实战 GeoHash讲解 GeoHash简单代码展示 Redis命令参考","tags":"Cache","url":"huan-cun-wen-ti-ji-chu-li.html","loc":"huan-cun-wen-ti-ji-chu-li.html"},{"title":"关于TCP的一些问题","text":"TCP如何记录时间戳 TCP首部（不是头部）有一个选项字段。kind = 10时表示时间戳。此选项总共10字节。len表示的总长，包括kind和len本身。 \"时间戳值\"表示当前系统的时间戳，\"时间戳回显应答\"是需要确认的数据报对端的发送的时间戳，回传给对端计算数据报传送花费时间。 TCP三次握手超时重传次数 这个又系统自己实现决定。Unix默认是5次，可以通过修改TCP_SYNACK_RETRIES改变。 如何保证TCP的高并发 对于Linux，每次有链接进来时，会新开一个线程（当然可以是进程，但是没必要）。此外，Linux有一个呼入连接请求队列，当应用层来不及处理相应的链接，如果队列还有空间，Linux将同意建立链接，并把它加入请求队列。 RST包作用 正常关闭一个连接使用FIN包，RST包可以用来异常关闭一个连接。收到RST一方将终止改连接，并通知应用层连接复位（不需要给对端任何响应）。 连接到一个不存在的端口，也会收到RST报文。比如主动断开连接一段没有等待2MSL时间，被动关闭的一端重传FIN就会收到RST连接。（次数端口不存在）。 检测半打开连接。如果服务端异常挂掉，重启后会给客户端回送RST报文，客户端能知道连接也被服务端断开，处于半连接状态。 半打开连接和半关闭连接的区别 半打开连接指主动大开端收到被动打开端的ACK确认，而对方还没收到自己ACK确认，此时给对端直接发送数据，会被丢掉。 半关闭连接指一方发送FIN并收到了ACK，此时表示自己不再发送数据，但是还是可以正常对端发送过来的数据。","tags":"网络","url":"guan-yu-tcpde-yi-xie-wen-ti.html","loc":"guan-yu-tcpde-yi-xie-wen-ti.html"},{"title":"Redis在项目中的使用","text":"前述 本篇内容为草稿 。记录Redis在项目中的一些实际应用，不会具体写，只写写简单的思路。 医院距离排序 需求描述 根据用户的定位信息（经纬度）获取周围的医院，然后再通过医院获取医生。 解决思路 方案-： MySQL数据库直接存储经纬度，然后每次查询都计算距离并排序。缺点是每次计算会比较慢，而且不能缓存。 方案二： MySQL官方支持的GEO方案，但是目前不太完善，使用不是很方便。 方案三：基于MongoDB的GEO方案，MongoDB对GEO支持还是很好的，但是为了方便聚合其他信息和利用缓存，我们这里不使用。 方案四：基于Redis的GEO方案。 具体实现 医院数量有限，因此可以将所有医院的位置信息用Redis的GEO数据结构存储，借助Redis快速实现距离筛选。 为了能存储更多信息且只管一点，采用 id:name 作为key。 GEOADD hospitalGeo 123 89 美肤医院:1 Redis GEO参考 Redis Geo实战 利用 georadius 和 georadiusbymember 按距离返回key，可以排序。 拿到id后再去医院数据库过滤医生。 问题思考 Q：医院位置更新了怎么办？ A：采用同时更新Redis和数据库的办法同步。 Q: Redis重启了怎么办？ A：写一个脚本，数据预热。 Q：怎样集合搜索和医院位置排序 A：现在的做法是先查询出5km范围的医院，然后再带着这些id去数据库搜索（后面想通过redis集合） 和推荐排序搭配 见多种排序组合小节 缓存管理后台用户权限 需求场景描述 一家美容医院有多个门店，要求总部管理员可以看到门店的订单等信息，门店的医生只能看到自己信息。 解决方案 利用set存储每个用户对应可以访问医院门店（只存储医院管理员，可以访问所有门店数据）。基于一个医院管理员很多，但是实际经常登录查看数据的账号估计就几个，设置key过期时间。 更好方案：将每个用户的基本信息json_dump后存入对应key，如mb:user:1。使用的时候解锁对应数据。 实现医生和医院列表 基于zset，key为docter:following:userid。成员为关住医院或医生id，score为关注时间，方便利用关注时间排序。设置过期时间，如果过期从数据库取。为了节省内存空间，关注列表最多保留100条。如果用户特殊情况需要访问操过100条，从数据库读取。 医院医生列表排序 需求场景 根据search(项目名）搜索框，搜索医院信息，然后根据平均评分，好评率，位置信息排序。 医生也有类似的需求。 解决方案 方案以医院为例，医生也类似的解决方案。 1, 每家医院用一个hash结构存储医院基本信息，其中信息包括：医院名，平均评分，好评率，预约数，城市代码等。可以保存到硬盘，下次启动方便加载进来，不然预热太慢。 2，用三个sorted set（有序集合，后面写为zset）存储分别按平均评分，好评率，预约数为维度的医院排序信息，其中医院id为项，各维度为score。zset score自动从小到大排序。为了节约空间，只保留最多200条排序，通过定时任务清楚多余的排序。 3，用一个GEO存储所有医院的经纬度（因为列表和详情都需要展示距离，所以这个不打算设置过期时间，如果Redis重启，会执行数据预热脚本填充对应数据）。 4，每个医美项目用一个set（普通集合）存储包含的医院。大约有200多个项目。 5，利用对应的项目set和排序zset执行 ZINTERSTORE 命令（交集并存储），聚合方式为 MAX 。结果存储key为sort:hospital:userid。为了节约内存，这个结果不能存储太长时间，默认5分钟。 6，基于异步定时任务更新医生平均评分，好评率，预约数。每次更新，没必要所有医院（医生）的评论信息都更新，只有在预约数，或者评论更新时才需要更新。可以基于celery异步任务更新。 7，删除医院和医生时，同步删除缓存里医院和医生对应key，并且从排名有序集合中删除。再从项目对应关系中删除（难点，不知道那些项目包含医院或医生）。 下面是一些更新命令： zadd key score member 在key存在的情况下更新有序集合成员 zrem key member member 删除一个或多个有序集合成员 sadd, srem对应集合的添加删除 HDEL key field [field ...] HSET key field value 问题 Q: 有序集合多个member score相同，这时候根据字典排序，就会导致11的id排到1前面，这种情况如何解决？ 可以将现在时间-创建时间的差值加上score，这样相同的score，后面创建的数值比较小。 Q: 如何设置医院和医生的过期时间？需要避免频繁访问的过期时间短，同时避免同时失效。 A: 默认过期时间基数10天，然后获取最近访问时间，10天以内的，随机加上6-10的数字，10-20天以内的，随机加上1-5的天数，20-30不加。30-60随机见1-5天，60天以上随机减6-10天。 初始值8-15天随机。 然后访问的时候，列表自动更新3-5天，详情自动6-8天。但是不大于30天。 Q: 项目对应的医院和医生是否设置过期时间，如何更新它的值？如何根据访问频繁度来缓存。 A: 设置，如果访问了，就更新过期时间，随机延长一个范围值。 Q: 医院或医生删除，如何快速找到关联了哪些项目，并删除里面的对应关系。 暂未解决，只能暴力查找。 后述 敖丙面试宝典","tags":"Redis","url":"rediszai-xiang-mu-zhong-de-shi-yong.html","loc":"rediszai-xiang-mu-zhong-de-shi-yong.html"},{"title":"Python学习资料整理","text":"内存管理和垃圾回收 使用gc、objgraph干掉python内存泄露与循环引用！ Python内存管理机制及优化简析 程序员必知的Python陷阱与缺陷列表 协程 asyncio async/await 迭代器和生成器 相关资料 微服务架构 微服务","tags":"Python","url":"pythonxue-xi-zi-liao-zheng-li.html","loc":"pythonxue-xi-zi-liao-zheng-li.html"},{"title":"一些有用的git技巧","text":"将同一个文件的修改分多次添加到index暂存区 # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 git add -p # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [ file ] # 改名文件，并且将这个改名放入暂存区 $ git mv [ file-original ] [ file-renamed ] git commit 提交指定文件和回退上次提交 # 提交暂存区的指定文件到仓库区 $ git commit [ file1 ] [ file2 ] ... -m [ message ] # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [ message ] # 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [ file1 ] [ file2 ] ... git branch建立和跟踪远程分支 # 新建一个分支，指向指定commit $ git branch [ branch ] [ commit ] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [ branch ] [ remote-branch ] # 切换到上一个分支 $ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [ branch ] [ remote-branch ] # 选择一个commit，合并进当前分支 $ git cherry-pick [ commit ] # 删除远程分支 $ git push origin --delete [ branch-name ] $ git branch -dr [ remote/branch ] 查看git变更信息 # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [ keyword ] # 显示指定文件是什么人在什么时间修改过 $ git blame [ file ] # 显示某个文件的版本历史，包括文件改名 $ git log --follow [ file ] $ git whatchanged [ file ] # 显示两次提交之间的差异 $ git diff [ first-branch ] ... [ second-branch ] # 显示今天你写了多少行代码 $ git diff --shortstat \"@{0 day ago}\"","tags":"git","url":"yi-xie-you-yong-de-gitji-qiao.html","loc":"yi-xie-you-yong-de-gitji-qiao.html"},{"title":"git .gitignore不起作用的原因","text":"最近自己在折腾一个小项目时，先提交了几次commit，并且推到了上游。可是类似 pyc 这样的文件总是显示在 git status 中，看起来挺不爽的，所以添加了一个 .gitignore 过滤掉 pyc 文件。 但当我写好规则时，却发现 git status 仍然展示 pyc 文件。搜索了下，原来 gitignore 对已经跟踪的文件是没有效果的，我们需要先清空 git index。解决方法如下: git rm -r --cached . 这样再看的时候，.gitignore 就生效了，重新提交一次就可以了。","tags":"git","url":"git-gitignorebu-qi-zuo-yong-de-yuan-yin.html","loc":"git-gitignorebu-qi-zuo-yong-de-yuan-yin.html"},{"title":"tornado路由装饰器","text":"我们知道，tornado启动时通过Application类加载handler，并实现handler的对应关系，即所谓URL路由。 下面是 tornado入门里的一个简单示例 import tornado.httpserver import tornado.ioloop import tornado.options import tornado.web from tornado.options import define , options define ( \"port\" , default = 8000 , help = \"run on the given port\" , type = int ) class IndexHandler ( tornado . web . RequestHandler ): def get ( self ): greeting = self . get_argument ( 'greeting' , 'Hello' ) self . write ( greeting + ', friendly user!' ) if __name__ == \"__main__\" : tornado . options . parse_command_line () app = tornado . web . Application ( handlers = [( r \"/\" , IndexHandler )]) http_server = tornado . httpserver . HTTPServer ( app ) http_server . listen ( options . port ) tornado . ioloop . IOLoop . instance () . start () 这样写的缺点是：每次增加handler，都得在Application里增加hanlder和url的映射关系，如果项目很大，管理起来十分不便。 而且不符合软件工程高内聚低耦合的要求。下面装饰器将handler对应的url封装到handler类属性里，那么在主函数就可以写相应的代码自动加载路由了。 import inspect def route ( pattern , priority = 0 , override = False ): \"\"\" 装饰 Handler 用于 URL 路由，被装饰的 Handler 将在启动时装载 可以用 priority 指定优先级 override 用于覆盖掉之前的 route (用于继承复用某个 handler) \"\"\" def wrapper ( handler ): if not inspect . isclass ( handler ) or \\ not issubclass ( handler , RequestHandler ): raise ValueError ( \"Handler must be a subclass of\" \" tornado.web.RequestHandler\" ) if hasattr ( handler , \"__routes__\" ) and not override : handler . __routes__ . append (( pattern , priority )) else : handler . __routes__ = [( pattern , priority )] return handler return wrapper","tags":"python","url":"tornadolu-you-zhuang-shi-qi.html","loc":"tornadolu-you-zhuang-shi-qi.html"},{"title":"python 新式类和旧式类的一些理解","text":"下面是两个类,一个新式类，一个旧式类 class OldClass (): pass class NewClass ( object ): pass old_instance = OldClass () new_instance = NewClass () 下面是我在ipython运行测试的结果 In [ 15 ]: class OldClass (): ... : pass ... : In [ 16 ]: class NewClass (): ... : pass ... : In [ 17 ]: old_instance = OldClass () In [ 18 ]: new_instance = NewClass () In [ 19 ]: type ( old_instance ) Out [ 19 ]: instance In [ 23 ]: type ( new_instance ) Out [ 23 ]: __main__ . NewClass In [ 24 ]: print ( type ( old_instance )) < type 'instance' > In [ 25 ]: print ( type ( new_instance )) < class ' __main__ . NewClass '> In [ 26 ]: type ( 1 ) Out [ 26 ]: int In [ 27 ]: print ( type ( 1 )) < type 'int' > In [ 31 ]: type ( 1 ) == int Out [ 31 ]: True In [ 32 ]: type ( 1 ) is int Out [ 32 ]: True In [ 33 ]: type ( old_instance ) is OldClass Out [ 33 ]: False In [ 34 ]: type ( new_instance ) is NewClass Out [ 34 ]: True 通过上面，我们看到，旧式类，一切实例的类型均是 instance 。它和内置类型表现形式不一致，这样不能很好的体现实例和类之间的关系。 而新式类则使类和内置类型表现形式一致。为了判断一个实例是否属于一个类，旧式类最可靠的方式时 instance() 内置方法，新式类可以 通过 type 判断，和内置类型一致。 下面是类本身的特性 In [ 37 ]: print ( type ( 1 )) < type 'int' > In [ 38 ]: print ( type ( OldClass )) < type 'classobj' > In [ 39 ]: print ( type ( NewClass )) < type 'type' > In [ 40 ]: print ( type ( int )) < type 'type' > 新式类的的类型是 type ，这和内置类型一致。旧式类则不是。普通类是元类的实例，对于新式类，默认的元类是 type 。 注:最新的python版本将内置类型也统一成类的形式， print(type(int) 将打印 <class 'type'> 。以后我觉得更精准的称呼应该是内置类和自定义类","tags":"python","url":"python-xin-shi-lei-he-jiu-shi-lei-de-yi-xie-li-jie.html","loc":"python-xin-shi-lei-he-jiu-shi-lei-de-yi-xie-li-jie.html"},{"title":"跨域访问总结","text":"具体可以参考这里(https://github.com/wengjq/Blog/issues/2)","tags":"http","url":"kua-yu-fang-wen-zong-jie.html","loc":"kua-yu-fang-wen-zong-jie.html"},{"title":"vim 选项iskeyword","text":"之前在用ctags来辅助跳转到 python 定义处时，我已经生成相应的tags文件，可是在类似self.method_name的语句按 <C-T> 时却不能正常跳转。查看 tags文件里也有对应的tag，网上搜索了好久也未找寻到解决方法。一个偶然的机会，发现iskeyword选项，它很好的解决了我的烦恼。 iskeyword 设置作为单词整体的字符，可能是升级到vim8.0的原因，\".\"字符被当做单词的一部分，所以 viw 等操作时都会选中点， <C-T> 也不能正常识别，所以我做了如下修改 set iskeyword - = . 这样就好了，可以使用 set iskeyword? 查看当前值","tags":"vim","url":"vim-xuan-xiang-iskeyword.html","loc":"vim-xuan-xiang-iskeyword.html"},{"title":"使用fabric远程部署代码","text":"1：安装 pip install fabric 2：基本使用 在项目目录下新建fabfile.py文件，写入如下代码。fab的所有任务均写在fabfile.py文件或者fabfile包目录中（含有__init__.py） from fabric.api import * def uname (): local ( \"uname -s\" ) 3：在远程机器上执行 在远程机器上执行，需要把local换成run。 from fabric.api import * def uname (): run ( \"uname -s\" ) $ fab uname 运行这个命令，会让你输入远程机器的名字。然后在指定的机器上执行uname -s 4：指定主机 可以通过env.hosts指定。env是一个dict子类，可以像操作字典一样访问它，也可以想类一样直接访问它的属性。 from fabric.api import env , run env . hosts = [ 'host1' , 'host2' ] def mytask (): run ( 'ls /var/www' ) 可以通过命令行选项指定 $ fab -H host1,host2 mytask 注意：命令行指定的主机会被env.hosts覆盖。可以通过env.hosts.extend(['host3', 'host4'])追加 可以给具体的某个任务指定主机，这样会更灵活* $ fab mytask:hosts = \"host1;host2\" 在fabfile文件你直接通过hosts装饰器给某个任务指定主机 from fabric.api import hosts , run @hosts ( 'host1' , 'host2' ) def mytask (): run ( 'ls /var/www' ) 注意：以上主机的定义的优先顺序为：fab mytask:host=host1，@hosts('host1')，env.hosts = ['host1']，--hosts=host1 5：定义远程主机角色组 from fabric.api import env env . roledefs = { 'web' : [ 'www1' , 'www2' , 'www3' ], 'dns' : [ 'ns1' , 'ns2' ] } @roles ( 'web' ) def mytask (): run ( 'ls /var/www' ) 上面任务会在主机www1，www2，www3上执行 6：定义排除的主机 使用--exclude-hosts/-x排除不想执行的主机。","tags":"python","url":"shi-yong-fabricyuan-cheng-bu-shu-dai-ma.html","loc":"shi-yong-fabricyuan-cheng-bu-shu-dai-ma.html"},{"title":"禁止input输入框回车自动提交表单","text":"最近在做项目的时候，发现一个小bug。input输入框回车直接提交表单，导致页面直接展示后端返回的json数据，而未执行相应的js跳转页面。 { \"code\" : 200 , \"data\" : { \"xxxxx\" : \"xxxxxxx\" , \"yyyyyyy\" : \"yyyyyyyy\" }, \"success\" : \"true\" } 解决方法是为keydown事件指定返回值。如下： < form name = \"vehicle-selection\" action = \"/selection\" method = \"POST\" onkeydown = \"if(event.keyCode==13){return false}\" > < input type = \"text\" name = \"nature\" value = \"211\" > ...... </ form > 通过keyCode==13判断是否回车键","tags":"js","url":"jin-zhi-inputshu-ru-kuang-hui-che-zi-dong-ti-jiao-biao-dan.html","loc":"jin-zhi-inputshu-ru-kuang-hui-che-zi-dong-ti-jiao-biao-dan.html"},{"title":"Python 异常问题汇总","text":"问题一：TypeError: object() takes no parameters 最近在测试 Python 的 __new__ 方法时，我写了如下验证代码 class test ( object ): def __init__ ( self , a ): print ( \"this is a init method\" ) self . a = a def __new__ ( cls , * args , ** kwargs ): print ( \"this is a new method\" ) return super ( test , cls ) . __new__ ( cls , * args , ** kwargs ) t = test ( 12 ) print ( t . a ) 结果在 Python2 运行正常，在 Python3 却报如下异常 this is a new method Traceback ( most recent call last ) : File \"test.py\" , line 11 , in <module> t = test ( 12 ) File \"test.py\" , line 8 , in __new__ return super ( test, cls ) .__new__ ( cls, *args, **kwargs ) TypeError: object () takes no parameters 一开始是以为 __init__ 拼写错误，或者 tab，spec 混用导致，但是 t = test() 却提示需要传递参数 a this is a new method Traceback ( most recent call last ) : File \"test.py\" , line 11 , in <module> t = test () TypeError: __init__ () missing 1 required positional argument: 'a' 那这样就纳闷了，竟然可以找到自己的 __init__ 方法，那为什么还报 no parameters 呢。 这是分割线。后面我查询了很久，在 stackoverflow 找到了回答 https://stackoverflow.com/questions/34777773/typeerror-object-takes-no-parameters-after-defining-new` 下面是 @Blckknght 的回答 In Python 3.3 and later, if you're overriding both __new__ and __init__, you need to avoid passing any extra arguments to the object methods you're overriding. If you only override one of those methods, it's allowed to pass extra arguments to the other one (since that usually happens without your help). 将我的测试代码 __new__ 方法部分改成如下 def __new__ ( cls , * args , ** kwargs ): print ( \"this is a new method\" ) return super ( test , cls ) . __new__ ( cls ) # 不需要传递额外的参数 这样就可以运行成功了。 那我不禁要问，Python3.3+ 到底怎么调用 __init__ 方法的呢，上面的回答也答复了。 __init__ 调用是通过 type.__call__ ，那么 object.__new__ 自然不需要知道 __init__ 的额外参数 感谢 @Blckknght 的回答！！！","tags":"python","url":"python-yi-chang-wen-ti-hui-zong.html","loc":"python-yi-chang-wen-ti-hui-zong.html"},{"title":"weakref使用与理解","text":"python weakref模块的使用 python的垃圾回收器，最主要的一种方式是引用计数，就是当某个对象的引用为0时，该对象将被回收。不过引用计数最大的缺点就是无法解决循环引用的问题。 weakref可以实现弱引用，弱引用和普通引用的区别是：当某个对象只存在弱引用时，它会被垃圾回收器收回。 通常用来创建缓存对象和对大型对象的引用。 使用 import weakref class Object ( object ): pass o = Object () r = weakref . ref ( o ) o2 = r () if 02 is None : print ( \"object has been deleted\" ) else : print ( \"do something\" ) 由于弱引用会被删除，通常都需要判断它是否存在。当然，如果引用对象是一个类，你可以用hasattr检查它是否有某个属性。None当然没有对应的属性。 import weakref class WeakObject ( object ): pass r = weakref . proxy ( WeakObject ) if hasattr ( r , \"name\" ): r . name 这里r不是弱引用对象，而是相应对象的弱引用。","tags":"python","url":"weakrefshi-yong-yu-li-jie.html","loc":"weakrefshi-yong-yu-li-jie.html"},{"title":"python装饰器","text":"装饰器的定义就不冗述了，它可以是函数，也可以是类。可以带参数。接下来分别介绍： 1：不带参数的装饰器（函数） def decorate ( func ): def wrapper ( * args , ** kwargs ): print ( \"this is a decorate\" ) func ( * args , ** kwargs ) return wrapper @decorate def test (): print ( \"this is test\" ) test () 注意：调用方式是@decorate，后面不跟括号，加上括号就成调用带参数的生成器了。相当于 test = decorate(test) 。输出结果为： this is a decorate this is test 2：带参数的装饰器（函数） #!/usr/env/bin python def decorate ( parameter = None ): def dec ( func ): def wrapper ( * args , ** kwargs ): print ( parameter ) func ( * args , ** kwargs ) return wrapper return dec @decorate ( \"have parameter decorate\" ) def test (): print ( \"this is test\" ) test () python解释器会自动识别封装，将函数传递给dec。相当于 test = decorate(\"have parameter decorate\")(func) .输出结果为： have parameter decorate this is test 3：类装饰器 class decorate ( object ): def __init__ ( self , func ): print ( \"this is a class decorate\" ) self . _func = func func ( * args , ** kwargs ) def __call__ ( self , * args , ** kwargs ): self . _func ( * args , ** kwargs ) 调用方式为@decorate, 函数会被传递给__init__方法，返回一个类实例，当实例被调用时，也就是执行__call__方法 如果类装饰器初始化的时候想初始化一些变量，可以在__init__方法中完成，实例如下： class decorate ( object ): def __init__ ( self , name , date ): self . _name = name self . _date = date def __call__ ( self , func ): def wrap ( * args , ** kwargs ): print ( self . _name , self . _date ) func ( * args , ** kwargs ) return wrap 调用方式为@decorate(\"test\", \"2017-04-06\"), python解释器会先把参数传给__init__初始化实例，再调用__call__返回装饰后的函数。 {cat}fanxu","tags":"python","url":"pythonzhuang-shi-qi.html","loc":"pythonzhuang-shi-qi.html"},{"title":"Python 默认参数","text":"python 默认值的陷阱 def test ( a , l = []): for i in range ( a ): l . append ( i ) print ( l ) >>> test ( 2 ) >>> test ( 2 , [ 1 ]) >>> test ( 3 ) 输出结果 [ 0 , 1 ] [ 1 , 0 , 1 ] [ 0 , 1 , 0 , 1 , 2 ] 最后一行为什么是 [0, 1, 0, 1, 2] , 而不是期望中的 [0, 1, 2] ？ 官方文档是这样解释的 Default values are computed once, then re-used. 因为默认值在函数定义的时候被初始化，而且只初始化一次, 后面重复使用。又因为列表可变的，顾不指定默认值的时候会不断的追加到默认值列表中。","tags":"python","url":"python-mo-ren-can-shu.html","loc":"python-mo-ren-can-shu.html"},{"title":"Python 设计模式总结","text":"单例模式 class Singleton ( object ): def __new__ ( cls , * args , ** kwargs ): if not hasattr ( cls , '_insurance' ): cls . _insurance = super ( Singleton , cls ) . __new__ ( cls , * args , ** kwargs ) return cls . _insurance if __name__ == '__main__' : s1 = Singleton () s2 = Singleton () print ( s1 ) print ( s2 ) 输出结果 <__main__.Singleton object at 0x1019f6320> <__main__.Singleton object at 0x1019f6320> 每个人的输出结果可能不一样，但他们应当相等","tags":"python","url":"python-she-ji-mo-shi-zong-jie.html","loc":"python-she-ji-mo-shi-zong-jie.html"},{"title":"Python super 函数的理解","text":"super 是一个类 当我们调用 super() 的时候，实际上是实例化了一个 super 类。你没看错， super 是个类，既不是关键字也不是函数等其他数据结构: In [ 1 ]: class Test ( object ): ... : pass ... : In [ 2 ]: s = super ( Test ) In [ 3 ]: type ( s ) Out [ 3 ]: super 在大多数情况下， super 包含了两个非常重要的信息: 一个 MRO 以及 MRO 中的一个类。当以如下方式调用 super 时: super ( a_type , obj ) MRO 指的是 type(obj) 的 MRO, MRO 中的那个类就是 a_type , 同时 isinstance(obj, a_type) == True 。 当这样调用时: super ( type1 , type2 ) MRO 指的是 type2 的 MRO, MRO 中的那个类就是 type1 ，同时 issubclass(type2, type1) == True 。 super 具体怎么工作 如上面所说，super 包含一个 MRO 和 MRO 中的一个类，假如 MRO 如下： [ A , B , C , D , E , object ] 那么 super(C, A).method() 将从 D，E，object 中查找 method 方法。并将 method 方法调用时的 self 设置为 A。 如下的多继承例子： class A : def __init__ ( self ): self . n = 2 def add ( self , m ): print ( 'self is {0} @A.add' . format ( self )) self . n += m class B ( A ): def __init__ ( self ): self . n = 3 def add ( self , m ): print ( 'self is {0} @B.add' . format ( self )) super () . add ( m ) self . n += 3 class C ( A ): def __init__ ( self ): self . n = 4 def add ( self , m ): print ( 'self is {0} @C.add' . format ( self )) super () . add ( m ) # 相当于 super(D, self).add(m) self . n += 4 class D ( B , C ): def __init__ ( self ): self . n = 5 def add ( self , m ): print ( 'self is {0} @D.add' . format ( self )) super ( C , D ) . add ( self , m ) # super 第二个参数为类对象时，需要显示传递self self . n += 5 if __name__ == '__main__' : d1 = D () d2 = D () d1 . add1 ( 2 ) print ( d1 . n , '=================' ) d2 . add2 ( 2 ) print ( d2 . n , '=================' ) print ( D . __mro__ ) # D 的 MRO 输出结果如下： self is <__main__.D object at 0x10e15e320> @D.add1 self is <__main__.D object at 0x10e15e320> @B.add self is <__main__.D object at 0x10e15e320> @C.add self is <__main__.D object at 0x10e15e320> @A.add 19 ================= self is <__main__.D object at 0x10e15e6a0> @D.add2 self is <__main__.D object at 0x10e15e6a0> @A.add 12 ================= ( <class '__main__.D' >, <class '__main__.B' >, <class '__main__.C' >, <class '__main__.A' >, <class 'object' > ) 说明： 从输出结果可以看到，super 可以避免重复调用一个方法的问题。 super().add(m) 等于 super(D, self).add(m)，前者是后者的简写形式。 当 super() 的第二个参数是一个类对象时，需要显示的将实例对象传递给父类的方法。这也是 add1 和 add2 的主要区别。 这其实很好理解，因为第二个参数为类对象时，super 返回的是一个非绑定方法，因此需要显示的指定self。 d2.add2(2) 输出结果为12，为什么不是19？因为我们显示的将 super 第一个参数传递为 C，那么将只从 A, object 查找 add 方法，从输出 结果可以看出来这点。 一些思考 如果把 B 中的 super().add(m) 删除， d1.add1(2) 调用后的 d1.n 值是多少呢？ 答案： self is <__main__.D object at 0x10714b8d0> @D.add1 self is <__main__.D object at 0x10714b8d0> @B.add 13 ================= 从这个问题看出，要让 super 按正常的 MRO 顺序炒作某个方法，父类的方法都必须通过 super 正确关联。 如果把 B 中的 super().add(m) 删除， d1.add2(2) 调用后的 d2.n 值是多少呢？ 答案： self is <__main__.D object at 0x10714b668> @D.add2 self is <__main__.D object at 0x10714b668> @A.add 12 ================= 从这个问题看出，某个父类的 super 查找中断，并不影响从其后开始正常查找。所谓正常查找，就是其后的父类方法都通过 super 正确 关联了。 在 __new__ 方法中调用无参数 super() 会有什么结果 答案: 会抛出异常 TypeError: object.__new__(): not enough arguments 。这是因为__new__是一个类方法，还不存在对应的实例对象。如果 在 classmethod 装饰器修饰的类方法上调用 super , 则抛出异常 TypeError: add() missing 1 required positional argument: 'm' 。 原因和这个差不多。","tags":"python","url":"python-super-han-shu-de-li-jie.html","loc":"python-super-han-shu-de-li-jie.html"},{"title":"Go 的方法申明总结","text":"下面的代码均省略包导入和主函数，只列出说明代码 1：不能为非本地类型申明方法 func ( i int ) add ( j int ) int { return i + j } 如果运行上面的代码，会报错 cannot define new methods on non-local type int ，正确的写法是先将 int 类型申明为本地类型 type LocalInt int func ( i * LocalInt ) add ( j LocalInt ) LocalInt { return * i + j } 之所以申明为指针类型接受者，是为了方便后面讲解 2：类型字面量，不能直接调用指针接受者方法，必须先申明变量 LocalInt ( 12 ). add ( LocalInt ( 12 )) 运行上面的代码，会如下错 # command-line-arguments ./test.go:28:17: cannot call pointer method on LocalInt ( 12 ) ./test.go:28:17: cannot take the address of LocalInt ( 12 ) 应先申明变量 i := LocalInt ( 12 ) i . add ( LocalInt ( 12 )) 3：go为强类型，相关类型不能混用 i := 12 i . add ( LocalInt ( 12 )) 虽然 LocalInt 和 int 类型表现一致，但它们仍不是同一种类型，因此会报错 i.add undefined (type int has no field or method add)","tags":"golang","url":"go-de-fang-fa-shen-ming-zong-jie.html","loc":"go-de-fang-fa-shen-ming-zong-jie.html"},{"title":"Go 相关特性总结","text":"GO语言特点 类C语言，语法简单，关键字很少, 只有25个，学习入门很快。 编码风格强制性检测，让GO代码保持一致，易于阅读。 静态语言，但是有动态语言的感觉。比如var定义。 语言层面支持并发。 内置丰富的工具。比如gofmt格式化代码等。 跨平台编译，如果你写的Go代码不包含cgo，那么就可以做到window系统编译linux的应用，如何做到的呢？Go引用了plan9的代码，这就是不依赖系统的信息。 没有类，没有继承。 接口风格是鸭子风格，结构体实现了相关方法就实现了接口，不需要关键字来绑定。 内置垃圾回收机制。 方法申明显示的指定接收者。 GO垃圾回收机制 go垃圾回收机制采用三色标记法https://juejin.im/post/5d56b47a5188250541792ede 接口风格 下面的file结构体实现了stream接口，可以将file实例赋值给stream接口变量。 // 接口申明 type stream interface { write ( s string ) int } type file struct { name string } func ( f file ) write ( s string ) int { fmt . Printf ( \"write data stream: %s\" , s ) return len ( s ) } var st stream st = file { name : \"test\" } 1：不能为结构体字面量直接赋值 type Point struct { x int y int } // 错误 Point { 1 , 2 }. x = 12 // 正确 var p = Point { 1 , 2 } p . x = 12 fmt . Println ( p ) 查看相关文档，总结出来的规律是不能为不能取地址的字面量赋值，因为还没赋值给变量，不能获取相关地址，指向不明确 2：map 类型的元素不能直接取地址 官方的解释是元素可能因为 map 大小的改变重新映射，导致地址改变 type Point struct { x int y int } var l = map [ string ] Point { \"member\" : Point { 1 , 2 }, } // 错误 l [ \"member\" ]. x = 10 // 正确 p = l [ \"member\" ] p . x = 12 l [ \"member\" ] = p fmt . Println ( l ) 因为 struct 类型的获取，总是会隐式转化为指针访问，随意直接通过 map 元素访问会报错，赋值给变量明确指向","tags":"golang","url":"go-xiang-guan-te-xing-zong-jie.html","loc":"go-xiang-guan-te-xing-zong-jie.html"},{"title":"Shell编程一些知识点","text":"1，$@的作用 $@ 传递给脚本的所以参数 $* 传递给脚本的所以参数 $# 传递给脚本的参数个数 $0 脚本本身 $n 传给脚本的第n个参数 $? 上个脚本或命令的退出状态 $$ 当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。 PS: 上面的脚本也适合函数。 $ 和 $@ 区别： $ 和 $@ 都表示传递给函数或脚本的所有参数，不被双引号\" \"包含时，都以\"$1\" \"$2\"…\"$n\" 的形式输出所有参数，被双引号\" \"包含时，\"$*\" 会将所有的参数作为一个整体；\"@\" 会将各个参数分开，以换行形式输出所有参数。 2，case用法 case $变量名 in \"值 1\" ) ;; # 如果变量的值等于值 1，则执行程序1，值 2 \") # 如果变量的值等于2，则执行程序2 # …省略其他分支… ;; *) # 如果变量的值都不是以上的值，则执行此程序 ;; esac 3，shift用途 将位置参数左移，如shift 2将$3变成$1。可以用来访问多余9的位置参数。 4，read用途 读取用户输入","tags":"Linux","url":"shellbian-cheng-yi-xie-zhi-shi-dian.html","loc":"shellbian-cheng-yi-xie-zhi-shi-dian.html"},{"title":"工作中遇到的一些js问题整理","text":"问题一：浏览器回退到上一个页面，表单里输入的内容无法记录。 描述：最近在使用bootstrap的过程中，发现某个页面浏览器历史记录返回，无法记录表单里的输入内容，选中的复选框又恢复到初始状态。 解决：在某次偶然的机会，看到该页面禁用了表单autocomplete功能(大部分浏览器都是打开的)。去掉就好了。 问题二：bootstrap模态框确认按钮向后端发送多次请求。 描述：当同一个模态框有多个触发源，弹出多次时，最后点击确认按钮，对应的事件处理函数会被调用多次。 解决: 绑定事件处理函数之前，先调用jquery off方法解绑先前绑定的事件处理函数。我先前用unbind方法效果不明显。 问题三：javascript:void() 报错 某些浏览器不支持，正确的写法是javascript.void(0)","tags":"js","url":"gong-zuo-zhong-yu-dao-de-yi-xie-jswen-ti-zheng-li.html","loc":"gong-zuo-zhong-yu-dao-de-yi-xie-jswen-ti-zheng-li.html"},{"title":"python类特殊方法","text":"__init__ __init__方法在定义实例的时候会被调用 class test ( object ); def __init__ ( self , x ): self . x = x class test1 ( test ): pass t = test1 ( 10 ) print ( t . x ) 执行上面的代码，会打印出10。说明在子类没有显示定义__init__方法时，在定义子类实例时，父类的__init__方法会自动被调用。 不过如果子类定义__init__方法，定义子类实例时不会自动调用父类的__init__方法 class test ( object ); def __init__ ( self , x ): self . test_x = x class test1 ( test ): def __init__ ( self , x ): self . test1_x = x t = test1 ( 10 ) print ( t . test_x ) 执行上面的代码，会产生如下异常，说明父类的__init__方法在定义实例时（准确的说是定义子类实例）未被调用。 AttributeError: tesst1 instance has no attribute 'test_x' __new__ __new__ 才是 Python 事实上的构造方法，而 __init__ 更确切的说是初始化方法。 __new__ 会产生一个实例对象，再把这个实例对象传给 __init__ 绑定一些属性。 因此 __new__ 是一个类方法，虽然它没有加 classsmethod 装饰器。不过我们大部分时间都不要实现__new__ 方法，因为 Python 解释器会调用 object 对象的 __new__ 给我们返回一个实例对象。 class test ( object ): def __new__ ( cls , * args , ** kwargs ): return super ( test , cls ) . __new__ ( cls , * args , ** kwargs ) __call__ 当一个类实现了__call__方法时，它的实例就是可调用的。即像函数一样使用。 class CallTest ( object ): def __init__ ( self , name ): print ( name ) def __call__ ( self , x , y ): print ( \"sum:\" , x + y ) t = CallTest ( \"test\" ) t ( 1 ,2 ) 上面将会输出: test sum: 3 从输出结果我们可以看到，__init__在创建实例的时候被调用，用来初始化一些属性。而__call__在实例被像函数一样调用时被调用。 python3中，类是type的实例，用dir(type)查看type的方法时，可以看见type实现了__call__方法，因此在定义类的时候会调用对应的__call__方法，这也是 元类的工作方式。关于元类，可以查看我的其他文章。同样，函数也实现了__call__方法 __getitem__ __getattribute__ __getattr__ 这里把三个属性放在一起讨论，方便区别 __getitem__ 在a['a'] 时被调用 __getattr__ 在某个实例属性不存在的时候被调用 __getattribute__ 是无条件被调用.对任何对象的属性访问时,都会隐式的调用__getattribute__方法","tags":"python","url":"pythonlei-te-shu-fang-fa.html","loc":"pythonlei-te-shu-fang-fa.html"},{"title":"pycurl安装的问题","text":"最近在安装pycurl的时候, pip install pycurl 显示已经成功安装，不过在导入的时候去出现如下错误 In [ 1 ]: import pycurl --------------------------------------------------------------------------- ImportError Traceback ( most recent call last ) < ipython - input - 1 - 141165 d68a5f > in < module > () ----> 1 import pycurl ImportError : pycurl : libcurl link - time ssl backend ( openssl ) is different from compile - time ssl backend ( none / other ) In [ 2 ]: 这个原因是pycurl需要知道ssl是哪一个具体的库， stackoverflow 上有很详细的讨论，我试了其中很多人的回答，只有下面这种方式对我的环境有效 pip uninstall pycurl export PYCURL_SSL_LIBRARY = openssl # --no-cache-dir --compile 不能省 pip install pycurl --compile pycurl --no-cache-dir 不过这样只是解决了全局环境下，对虚拟环境还是不行。暂时我没找到根本的解决方法，只能采取下面比较暴力的方式 cp /usr/local/Cellar/python3/3.6.4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pycurl.cpython-36m-darwin.so .tox/py36/lib/site-packages 如果大家有更好的解决方式，欢迎在https://github.com/boyaziqi/CatsAction/issues 给我提issue","tags":"python","url":"pycurlan-zhuang-de-wen-ti.html","loc":"pycurlan-zhuang-de-wen-ti.html"},{"title":"zsh打开vi模式up向上箭头不能按子模式搜索解决方法","text":"由于我习惯在终端下用vim下写代码，因此最近把zsh的模式也改成了vi模式，这样就可以在终端 里使用很多vi快捷键。但是却发现一个问题： 按方向键的上下键，zsh不能根据输入的字符匹配最近输入的历史命令 在网上搜索了下解决方法，如下 # 插件应该写成如下 plugins =( ... vi-mode history-substring-search ... ) # 而不应该写成如下 plugins =( ... history-substring-search vi-mode ... ) 具体就是history-substring-search插件需要放在vi-mode插件前面，请参考 here","tags":"Linux","url":"zshda-kai-vimo-shi-upxiang-shang-jian-tou-bu-neng-an-zi-mo-shi-sou-suo-jie-jue-fang-fa.html","loc":"zshda-kai-vimo-shi-upxiang-shang-jian-tou-bu-neng-an-zi-mo-shi-sou-suo-jie-jue-fang-fa.html"},{"title":"关于sublime text3使用中的一些记录","text":"1. 最新安装 Package Control 现在sublime text首次使用 Package Control，会自动安装。不用再调用 console 执行命令 2. 安装主题 可直接通过Cackage Control 安装 - Soda - Flatland 3. 自定义设置 添加自定义设置 (Preference -> Settings) 语法自定义设置 (Preference -> Settings -> Syntax Specific) 4. 安装代码自动补全扩展 我比较喜欢 SublimeCodeIntel 。主要是因为它比较轻量，而且支持多种语言，不需要在单独安装相关依赖库 可以参考 将Sublime Text 3设置为Python全栈开发环境","tags":"vim","url":"guan-yu-sublime-text3shi-yong-zhong-de-yi-xie-ji-lu.html","loc":"guan-yu-sublime-text3shi-yong-zhong-de-yi-xie-ji-lu.html"},{"title":"关于pelican 主题gum bug的处理","text":"最近在用pelican搭建个人静态博客时，在安装主题时，发现官方提供的主题gum不能正常渲染出tags和pages，下面简单记录处理过程。想了解pelican的安装，可以查看我的 pelican安装与部署 1：安装pelican主题 下面以安装gum为例 git clone https://github.com/getpelican/pelican-themes.git cp -r ~/pelican-themes/gum /you-blog-directory 接下来在配置文件pelicanconf.py中指定主题 theme = gum 。其实可以不用把主题复制到你的博客目录，你只需在theme后指定主题所在目录，让pelican正确解析到就行。不过为了修改和git版本跟踪，这里把它复制到博客目录。 2：gum主题tags和pages的渲染问题。 找到gum模板文件sidebar.html。发现它把pages写成PAGES了，导致侧边栏Pages总未展示。官方主题有好几个都有这个问题，我估计是仿照一个主题写的缘故。 <h4> Tags </h4> {% if tags %} <ul class= \"blank\" > {% for tag in tag_cloud %} <li class= \"tag- {{ tag.1 }} \" ><a href= \" {{ SITEURL }} / {{ tag.0.url }} \" > {{ tag.0 | e }} </a></li> {% endfor %} </ul> {% endif %} 上面是gum对于tags的渲染，需要修改成如下 <a href= \" {{ SITEURL }} /tags.html\" ><h4> Tags </h4></a> {% if tags %} <ul class= \"blank\" > {% for tag , _ in tags %} <li class= \"tag- {{ tag }} \" ><a href= \" {{ SITEURL }} / {{ tag.url }} \" > {{ tag | e }} </a></li> {% endfor %} </ul> {% endif %} 至于为何修改成这样，请参考官方文档 Creating themes 3: 对tags和categories界面展示的优化 tags.html和categories.html模板展示博客的tags列表和分类列表。gum原来的模板并未展示每个tag或category对应的文章，于是我做了如下修改 {% extends \"base.html\" %} {% block title %}{{ SITENAME }} - Tags {% endblock %} {% block content %} <h4><i class= \"icon-tags icon-large\" ></i> Tags for {{ SITENAME }} </h4> <ul> {% for tag , articles in tags %} <li class= \"tag- {{ tag }} \" > <a href= \" {{ SITEURL }} / {{ tag.url }} \" > <i class= \"icon-tag icon-large\" ></i> {{ tag | e }} </a> <ul> {% for article in articles %} <li><a href= \" {{ SITEURL }} / {{ article.url }} \" > {{ article.title }} </a></li> {% endfor %} </ul> </li> {% endfor %} </ul> {% endblock %} gum主题原来的模板 {% extends \"base.html\" %} {% block content %} <ul> <li class= \"nav-header\" ><h4><i class= \"icon-tags icon-large\" ></i> Tags </h4></li> {% for tag in tag_cloud %} <li class= \"tag- {{ tag.1 }} \" > <a href= \" {{ SITEURL }} / {{ tag.0.url }} \" > <i class= \"icon-tag icon-large\" ></i> {{ tag.0 | e }} </a> </li> {% endfor %} </ul> {% endblock %} categories.html我就不粘贴代码了，思路都一样。并且原模板对于categories.html也没有bug。 由于附图不方便文章布局，对于上面修改后的页面效果，可以自行修改预览。","tags":"python","url":"guan-yu-pelican-zhu-ti-gum-bugde-chu-li.html","loc":"guan-yu-pelican-zhu-ti-gum-bugde-chu-li.html"},{"title":"pelican安装与部署","text":"pelican是python编写的一个静态博客生成系统。如果有一定的python基础，部署起来很方便 1：安装 virtualenv ~/virtualenvs/pelican cd ~/virtualenvs/pelican source bin/activate pip install pelican 也可以通过源码安装： git clone https://github.com/getpelican/pelican.git cd pelican python setup.py install 2：生成博客站点 pelican-quickstart 回车回答相应的问题，就会为你生成一个博客目录和默认的配置文件。现在你已经可以通过reStructuredText和Markdown格式写文章了，使用的是pelican内置的主题。 3：写文章 在content目录下新建文件写自己的文章。我比较喜欢Markdown，下面是一个例子 Title: about me Date: 2015-01-02 categoty: me tags: introduction Here is my personal introduction 完成之后保存为md后缀结尾的文件就行了，比如保存为About.md 4：生成博客站点 cd you-blog-path pelican content/ -s pelicanconf.py content是文章所在目录，-s指定配置文件，不指定默认就为pelicanconf.py。也可以通过make生成： make html pelican-quickstart 已经为我们生成所需的Makefile文件，可以make help查看相关命令帮助 5：预览博客文章 cd output python -m http.server output是第四步生成站点的默认目录，打开浏览器输入http://localhost:8000/就可以预览了。为了方便调试，可以通过自带脚本启动服务器预览： ./develop_server.sh 通过这个脚本启动，当你更新文章时，它会自动重新生成站点并加载。 6: 部署到github page 现在我们可以把生成的站点部署到github page或者结合Nginx部署到公有云。下面讲讲部署到github page (1) 在github上创建自己的user page。比如我的是boyaziqi.github.io。 (2) ghp-import output 生成gh-pages分支。如果没有ghp-import命令，需要通过pip安装。 (3) 将ph-pages分支推送到自己的user page远端源： git remote add user-page git@github.com:elemoine/elemoine.github.io.git git push user-page gh-pages:master","tags":"python","url":"pelicanan-zhuang-yu-bu-shu.html","loc":"pelicanan-zhuang-yu-bu-shu.html"}]};